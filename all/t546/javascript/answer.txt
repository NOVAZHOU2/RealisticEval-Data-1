Sure! Below is the equivalent JavaScript code that replicates the functionality of the provided Python script. The JavaScript version uses Node.js to read from standard input and processes the TSV data similarly.

```javascript
const csvParser = require('csv-parser');
const process = require('process');

function readTSVFromStdin() {
    // Create a stream to read from standard input
    const stdinStream = process.stdin;
    let data = [];

    // Set up the CSV parser with tab as the delimiter
    stdinStream
        .setEncoding('utf8')
        .on('data', chunk => {
            const rows = chunk.split('\n').map(row => row.split('\t'));
            data = data.concat(rows);
        })
        .on('end', () => {
            // Process the data after reading is complete
            const processedData = processPaddedData(data);
            console.log(processedData);
        });
}

function processPaddedData(data) {
    // Find the maximum number of columns in the input data
    const maxColumns = data.length > 0 ? Math.max(...data.map(row => row.length)) : 0;

    // Pad all rows to ensure they have the same length
    const paddedData = data.map(row => {
        return row.concat(Array(maxColumns - row.length).fill(''));
    });

    return paddedData;
}

// Call the function to start reading from stdin
readTSVFromStdin();
```

### Explanation:
1. **Reading from Standard Input**: We use `process.stdin` to read from standard input.
2. **Splitting Rows**: Each chunk of data received from standard input is split by newline (`\n`) and then each row is split by tabs (`\t`).
3. **Padding Rows**: After collecting all rows, we calculate the maximum number of columns and pad each row to match this length.
4. **Output**: The padded data is logged to the console.

Make sure you have the necessary Node.js environment set up to run this script. You can test it by piping TSV data into your Node.js script. For example:
```sh
echo -e "col1\tcol2\nval1\t\nval2\tval3" | node your_script.js
```