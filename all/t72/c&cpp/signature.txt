Certainly! Below is the equivalent C++ code with the same function signature and comments:

```cpp
#include <Eigen/Dense>

/**
 * Converts 2D pixel coordinates into 3D world coordinates using camera intrinsic parameters and depth.
 *
 * @param K A 3x3 Eigen::Matrix representing the camera intrinsic matrix.
 * @param d The depth (distance along the z-axis).
 * @param x The pixel x-coordinate.
 * @param y The pixel y-coordinate.
 * @return An Eigen::Vector3d representing the x, y, z 3D point coordinates in camera RDF coordinates.
 */
Eigen::Vector3d get_3d_coordinates(const Eigen::Matrix3d& K, double d, double x, double y) {
    // Invert the camera intrinsic matrix
    Eigen::Matrix3d K_inv = K.inverse();

    // Calculate the normalized image coordinates
    double u_norm = (x - K(0, 2)) / K(0, 0);
    double v_norm = (y - K(1, 2)) / K(1, 1);

    // Construct the 3D point in camera coordinate system
    Eigen::Vector3d P_camera(u_norm * d, v_norm * d, d);

    return P_camera;
}
```

### Explanation:
- **Eigen Library**: This C++ library is used for linear algebra operations. It provides classes and functions for matrices, vectors, and other mathematical operations.
- **Matrix and Vector Types**: `Eigen::Matrix3d` represents a 3x3 matrix of doubles, and `Eigen::Vector3d` represents a 3-dimensional vector of doubles.
- **Inversion**: The intrinsic matrix \( K \) is inverted to transform the pixel coordinates back to the normalized image coordinates.
- **Normalization**: The pixel coordinates are normalized using the focal lengths and principal points from the intrinsic matrix.
- **3D Point Construction**: The 3D point in the camera's reference frame (RDF) is constructed using the normalized coordinates and the depth.

This C++ code should provide similar functionality to your Python code. Make sure you have the Eigen library installed in your development environment.