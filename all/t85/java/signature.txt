Sure! Here is the Java code signature for the given Python function, keeping the same comments:

```java
import org.apache.spark.sql.Dataset;
import org.apache.spark.sql.Row;
import org.apache.spark.sql.SparkSession;

/**
 * Fills missing values in the specified column of the DataFrame with the first valid value in that column.
 *
 * @param sparkSession The Spark session.
 * @param df           The DataFrame.
 * @param columnName   The name of the column to fill missing values.
 * @return The DataFrame with missing values filled.
 */
public Dataset<Row> fillMissingWithFirstValid(SparkSession sparkSession, Dataset<Row> df, String columnName) {
```

This Java method uses Apache Spark's `Dataset` and `Row` classes to handle DataFrames. Make sure you have Apache Spark set up in your environment to use these classes.