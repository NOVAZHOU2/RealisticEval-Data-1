{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# LLM回答校验"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def delete_files_in_directory():\n",
    "    # 定义要删除的文件类型\n",
    "    file_types = ['*.sh', '*.sql', '*.md','.txt','.cvs']\n",
    "\n",
    "    # 遍历每种文件类型\n",
    "    for file_type in file_types:\n",
    "        # 查找匹配的文件\n",
    "        files_to_delete = glob.glob(os.path.join(\"./\", file_type))\n",
    "\n",
    "        # 删除找到的文件\n",
    "        for file_path in files_to_delete:\n",
    "            try:\n",
    "                os.remove(file_path)\n",
    "                print(f\"Deleted: {file_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error deleting {file_path}: {e}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "TASK_LIST = [\n",
    "    # {\n",
    "    #     \"model\": \"chatglm-6b\",\n",
    "    #     \"language\": [\"c&cpp\"]\n",
    "    # }\n",
    "    # {\n",
    "    #     \"model\": \"codegeex4-all-9b\",\n",
    "    #     \"language\": [\"javascript\", \"typescript\", \"c&cpp\"]\n",
    "    # },\n",
    "    # {\n",
    "    #     \"model\": \"codegen25-7b-instruct_P\",\n",
    "    #     \"language\": [\"c&cpp\"]\n",
    "    # },\n",
    "    # {\n",
    "    #     \"model\": \"deepseek-coder-6.7b-instruct\",\n",
    "    #     \"language\": [\"python\", \"javascript\", \"typescript\", \"c&cpp\"]\n",
    "    # },\n",
    "    # {\n",
    "    #     \"model\": \"Meta-Llama-3.1-8B-Instruct\",\n",
    "    #     \"language\": [\"javascript\"]\n",
    "    # },\n",
    "    # {\n",
    "    #     \"model\": \"Mistral-7B-Instruct-v0.3\",\n",
    "    #     \"language\": [\"python\", \"javascript\", \"typescript\", \"c&cpp\"]\n",
    "    # },\n",
    "    # {\n",
    "    #     \"model\": \"Phi-3-small-8k-instruct\",\n",
    "    #     \"language\": [\"typescript\"]\n",
    "    # },\n",
    "    # {\n",
    "    #     \"model\": \"CodeLlama-7b-hf\",\n",
    "    #     \"language\": [\"python\", \"javascript\", \"typescript\", \"c&cpp\"]\n",
    "    # },\n",
    "    # {\n",
    "    #     \"model\": \"starcoder2-7b\",\n",
    "    #     \"language\": [\"python\", \"javascript\", \"typescript\", \"c&cpp\"]\n",
    "    # },\n",
    "    {\n",
    "        \"model\": \"gpt-3.5-turbo\",\n",
    "        \"language\": [\"python\"]\n",
    "    }\n",
    "]\n",
    "ANSWER_PATH = \"E:\\code\\code_back\\python_project\\llm\\qa\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/215 [00:00<00:22,  9.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 4/215 [00:00<00:20, 10.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "...\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "6\n",
      "\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 2\n",
      "    \"\"\"\n",
      "    ^\n",
      "SyntaxError: (unicode error) 'unicodeescape' codec can't decode bytes in position 92-93: truncated \\UXXXXXXXX escape\n",
      "\n",
      "Process completed with return code: 1\n",
      "7\n",
      "\n",
      "2024-10-04 15:30:17,337 - test_logger - CRITICAL - This is a critical message\n",
      "F2024-10-04 15:30:17,339 - test_logger - DEBUG - This is a debug message\n",
      "2024-10-04 15:30:17,339 - test_logger - DEBUG - This is a debug message\n",
      "F2024-10-04 15:30:17,339 - test_logger - ERROR - This is an error message\n",
      "2024-10-04 15:30:17,339 - test_logger - ERROR - This is an error message\n",
      "2024-10-04 15:30:17,339 - test_logger - ERROR - This is an error message\n",
      "F2024-10-04 15:30:17,339 - test_logger - INFO - This is an info message\n",
      "2024-10-04 15:30:17,339 - test_logger - INFO - This is an info message\n",
      "2024-10-04 15:30:17,339 - test_logger - INFO - This is an info message\n",
      "2024-10-04 15:30:17,339 - test_logger - INFO - This is an info message\n",
      "F2024-10-04 15:30:17,339 - test_logger - WARNING - This is a warning message\n",
      "2024-10-04 15:30:17,339 - test_logger - WARNING - This is a warning message\n",
      "2024-10-04 15:30:17,339 - test_logger - WARNING - This is a warning message\n",
      "2024-10-04 15:30:17,339 - test_logger - WARNING - This is a warning message\n",
      "2024-10-04 15:30:17,339 - test_logger - WARNING - This is a warning message\n",
      "F\n",
      "======================================================================\n",
      "FAIL: test_critical_logging (__main__.TestLogger)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 1342, in patched\n",
      "    return func(*newargs, **newkeywargs)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 65, in test_critical_logging\n",
      "    mock_critical.assert_called_once_with(message)\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 918, in assert_called_once_with\n",
      "    raise AssertionError(msg)\n",
      "AssertionError: Expected 'critical' to be called once. Called 0 times.\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_debug_logging (__main__.TestLogger)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 1342, in patched\n",
      "    return func(*newargs, **newkeywargs)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 41, in test_debug_logging\n",
      "    mock_debug.assert_called_once_with(message)\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 918, in assert_called_once_with\n",
      "    raise AssertionError(msg)\n",
      "AssertionError: Expected 'debug' to be called once. Called 0 times.\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_error_logging (__main__.TestLogger)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 1342, in patched\n",
      "    return func(*newargs, **newkeywargs)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 59, in test_error_logging\n",
      "    mock_error.assert_called_once_with(message)\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 918, in assert_called_once_with\n",
      "    raise AssertionError(msg)\n",
      "AssertionError: Expected 'error' to be called once. Called 0 times.\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_info_logging (__main__.TestLogger)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 1342, in patched\n",
      "    return func(*newargs, **newkeywargs)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 47, in test_info_logging\n",
      "    mock_info.assert_called_once_with(message)\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 918, in assert_called_once_with\n",
      "    raise AssertionError(msg)\n",
      "AssertionError: Expected 'info' to be called once. Called 0 times.\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_warning_logging (__main__.TestLogger)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 1342, in patched\n",
      "    return func(*newargs, **newkeywargs)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 53, in test_warning_logging\n",
      "    mock_warning.assert_called_once_with(message)\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 918, in assert_called_once_with\n",
      "    raise AssertionError(msg)\n",
      "AssertionError: Expected 'warning' to be called once. Called 0 times.\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.002s\n",
      "\n",
      "FAILED (failures=5)\n",
      "\n",
      "Process completed with return code: 1\n",
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 6/215 [00:00<00:20, 10.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "9\n",
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "11\n",
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 8/215 [00:00<00:25,  8.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "13\n",
      "14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 10/215 [00:01<00:20, 10.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "..FF\n",
      "======================================================================\n",
      "FAIL: test_multiple_json_files (__main__.TestFindJsonFilesWithKeyword)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 1342, in patched\n",
      "    return func(*newargs, **newkeywargs)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 91, in test_multiple_json_files\n",
      "    self.assertEqual(result, expected)\n",
      "AssertionError: Lists differ: ['test.js.json'] != ['file1.json', 'file2.json']\n",
      "\n",
      "First differing element 0:\n",
      "'test.js.json'\n",
      "'file1.json'\n",
      "\n",
      "Second list contains 1 additional elements.\n",
      "First extra element 1:\n",
      "'file2.json'\n",
      "\n",
      "- ['test.js.json']\n",
      "+ ['file1.json', 'file2.json']\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_no_json_files_in_directory (__main__.TestFindJsonFilesWithKeyword)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 1342, in patched\n",
      "    return func(*newargs, **newkeywargs)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 73, in test_no_json_files_in_directory\n",
      "    self.assertEqual(result, expected)\n",
      "AssertionError: Lists differ: ['test.js.json'] != []\n",
      "\n",
      "First list contains 1 additional elements.\n",
      "First extra element 0:\n",
      "'test.js.json'\n",
      "\n",
      "- ['test.js.json']\n",
      "+ []\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.016s\n",
      "\n",
      "FAILED (failures=2)\n",
      "\n",
      "Process completed with return code: 1\n",
      "17\n",
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "18\n",
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 12/215 [00:01<00:19, 10.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 15/215 [00:01<00:23,  8.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FFFFF\n",
      "======================================================================\n",
      "FAIL: test_asterisks_around_spaces (__main__.TestProcessMarkdown)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 38, in test_asterisks_around_spaces\n",
      "    self.assertEqual(process_markdown(content), expected)\n",
      "AssertionError: '* spaces *' != 'Asterisks around * spaces * are tricky.'\n",
      "- * spaces *\n",
      "+ Asterisks around * spaces * are tricky.\n",
      "\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_asterisks_with_no_text (__main__.TestProcessMarkdown)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 33, in test_asterisks_with_no_text\n",
      "    self.assertEqual(process_markdown(content), expected)\n",
      "AssertionError: '**' != 'Asterisks with ** no text.'\n",
      "- **\n",
      "+ Asterisks with ** no text.\n",
      "\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_multiple_asterisk_pairs (__main__.TestProcessMarkdown)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 28, in test_multiple_asterisk_pairs\n",
      "    self.assertEqual(process_markdown(content), expected)\n",
      "AssertionError: '*Multiple pairs of asterisks in one*' != '*Multiple pairs of asterisks in one* sentence.'\n",
      "- *Multiple pairs of asterisks in one*\n",
      "+ *Multiple pairs of asterisks in one* sentence.\n",
      "?                                     ++++++++++\n",
      "\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_nested_asterisks (__main__.TestProcessMarkdown)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 23, in test_nested_asterisks\n",
      "    self.assertEqual(process_markdown(content), expected)\n",
      "AssertionError: '*nested asterisks*' != 'Example of *nested asterisks*.'\n",
      "- *nested asterisks*\n",
      "+ Example of *nested asterisks*.\n",
      "? +++++++++++                  +\n",
      "\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_single_asterisk_pair (__main__.TestProcessMarkdown)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 18, in test_single_asterisk_pair\n",
      "    self.assertEqual(process_markdown(content), expected)\n",
      "AssertionError: '*test.js*' != 'This is a *test.js* string.'\n",
      "- *test.js*\n",
      "+ This is a *test.js* string.\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.001s\n",
      "\n",
      "FAILED (failures=5)\n",
      "\n",
      "Process completed with return code: 1\n",
      "21\n",
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.007s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 17/215 [00:01<00:24,  8.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.001s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "23\n",
      "\n",
      "FFF.F\n",
      "======================================================================\n",
      "FAIL: test_identical_segments (__main__.TestLineSegmentIntersection)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 72, in test_identical_segments\n",
      "    self.assertIsNone(\n",
      "AssertionError: (1, 1) is not None : Should return None for identical segments\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_intersecting_lines (__main__.TestLineSegmentIntersection)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 47, in test_intersecting_lines\n",
      "    self.assertEqual(\n",
      "AssertionError: None != (2.5, 2.5) : Should find intersection at (2.5, 2.5)\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_intersection_in_middle (__main__.TestLineSegmentIntersection)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 67, in test_intersection_in_middle\n",
      "    self.assertIsNotNone(result, \"Should find an intersection at the middle (2, 2)\")\n",
      "AssertionError: unexpectedly None : Should find an intersection at the middle (2, 2)\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_parallel_lines (__main__.TestLineSegmentIntersection)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 54, in test_parallel_lines\n",
      "    self.assertIsNone(\n",
      "AssertionError: (2, 2) is not None : Should return None for parallel lines\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "FAILED (failures=4)\n",
      "\n",
      "Process completed with return code: 1\n",
      "24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 19/215 [00:02<00:27,  7.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.029s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "25\n",
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.020s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 21/215 [00:02<00:25,  7.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "...F\n",
      "======================================================================\n",
      "FAIL: test_repeated_separators (__main__.TestConvertToCommaSeparated)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 30, in test_repeated_separators\n",
      "    self.assertEqual(convert_to_comma_separated(\"pear;;apple**banana//orange\"), \"pear,,apple,,banana,,orange\",\n",
      "AssertionError: 'pear,apple,banana,orange' != 'pear,,apple,,banana,,orange'\n",
      "- pear,apple,banana,orange\n",
      "+ pear,,apple,,banana,,orange\n",
      "?     +      +        +\n",
      " : Failed to handle repeated separators correctly.\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.001s\n",
      "\n",
      "FAILED (failures=1)\n",
      "\n",
      "Process completed with return code: 1\n",
      "27\n",
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.021s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 23/215 [00:02<00:23,  8.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "..F..\n",
      "======================================================================\n",
      "FAIL: test_mixed_bytes (__main__.TestPrintMemoryBits)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 62, in test_mixed_bytes\n",
      "    self.assertEqual(output, expected_output)\n",
      "AssertionError: '0 1 0 1 0 1 0 1\\n1 0 0 0 0 0 0 1' != '0 1 0 1 0 1 0 1 \\n1 0 0 0 0 0 0 1'\n",
      "- 0 1 0 1 0 1 0 1\n",
      "+ 0 1 0 1 0 1 0 1 \n",
      "?                +\n",
      "  1 0 0 0 0 0 0 1\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.001s\n",
      "\n",
      "FAILED (failures=1)\n",
      "\n",
      "Process completed with return code: 1\n",
      "31\n",
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 24/215 [00:02<00:22,  8.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EFF..\n",
      "======================================================================\n",
      "ERROR: test_crc64_compute_negative_integer (__main__.TestCRC64)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 64, in test_crc64_compute_negative_integer\n",
      "    result = CRC64.compute(-1234567890)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 31, in compute\n",
      "    for byte in input_integer.to_bytes((input_integer.bit_length() + 7) // 8, 'big'):\n",
      "OverflowError: can't convert negative int to unsigned\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_crc64_compute_positive_integer (__main__.TestCRC64)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 60, in test_crc64_compute_positive_integer\n",
      "    self.assertEqual(result, expected_result)\n",
      "AssertionError: 11321808249792132553 != 12752283312399622734\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_crc64_compute_zero (__main__.TestCRC64)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 73, in test_crc64_compute_zero\n",
      "    self.assertEqual(result, expected_result)\n",
      "AssertionError: 0 != 13333283586479230977\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.001s\n",
      "\n",
      "FAILED (failures=2, errors=1)\n",
      "\n",
      "Process completed with return code: 1\n",
      "33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 26/215 [00:03<00:32,  5.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.002s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "35\n",
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 29/215 [00:03<00:21,  8.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "37\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 1, in <module>\n",
      "    def lanczos(n: int, quadrature_rule: QuadratureRule) -> Tuple[np.ndarray, np.ndarray, np.ndarray, QuadratureRule]:\n",
      "NameError: name 'QuadratureRule' is not defined\n",
      "\n",
      "Process completed with return code: 1\n",
      "38\n",
      "\n",
      "..E.\n",
      "======================================================================\n",
      "ERROR: test_no_intermediates (__main__.TestRainbowHexGenerator)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 48, in test_no_intermediates\n",
      "    result = rainbowHexGenerator(0)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 23, in rainbowHexGenerator\n",
      "    colors.extend(interpolate(main_colors[i], main_colors[i + 1], num_intermediates))\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 15, in interpolate\n",
      "    return [\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 16, in <listcomp>\n",
      "    f\"#{int(r1 + (r2 - r1) * i / steps):02X}{int(g1 + (g2 - g1) * i / steps):02X}{int(b1 + (b2 - b1) * i / steps):02X}\"\n",
      "ZeroDivisionError: division by zero\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.000s\n",
      "\n",
      "FAILED (errors=1)\n",
      "\n",
      "Process completed with return code: 1\n",
      "40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 31/215 [00:04<00:34,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EE.E\n",
      "======================================================================\n",
      "ERROR: test_edge_case_near_c_major (__main__.TestAdjustToCMajor)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 38, in test_edge_case_near_c_major\n",
      "    self.assertEqual(adjust_to_c_major(\"B#3\"), \"C4\")\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 21, in adjust_to_c_major\n",
      "    return nearest_note + (note.octave if note.octave is not None else '')\n",
      "TypeError: can only concatenate str (not \"int\") to str\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_invalid_note_name (__main__.TestAdjustToCMajor)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 35, in test_invalid_note_name\n",
      "    self.assertEqual(adjust_to_c_major(\"H2\"), \"C4\")\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 14, in adjust_to_c_major\n",
      "    note = pitch.Pitch(note_name)\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\music21\\pitch.py\", line 1848, in __init__\n",
      "    self.name = name  # set based on string\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\music21\\pitch.py\", line 2675, in name\n",
      "    self.step = usrStr  # type: ignore\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\music21\\pitch.py\", line 2879, in step\n",
      "    raise PitchException(f'Cannot make a step out of {usrStr!r}')\n",
      "music21.pitch.PitchException: Cannot make a step out of 'H'\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_note_not_in_c_major (__main__.TestAdjustToCMajor)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 31, in test_note_not_in_c_major\n",
      "    self.assertEqual(adjust_to_c_major(\"C#4\"), \"D4\")\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 21, in adjust_to_c_major\n",
      "    return nearest_note + (note.octave if note.octave is not None else '')\n",
      "TypeError: can only concatenate str (not \"int\") to str\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.001s\n",
      "\n",
      "FAILED (errors=3)\n",
      "\n",
      "Process completed with return code: 1\n",
      "41\n",
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.002s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 33/215 [00:04<00:28,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FF.FF\n",
      "======================================================================\n",
      "FAIL: test_basic_number (__main__.TestReplacePhoneNumbers)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 22, in test_basic_number\n",
      "    self.assertEqual(replace_phone_numbers(msg), expected)\n",
      "AssertionError: 'Call me at[PHONE_NUM].' != 'Call me at [PHONE_NUM].'\n",
      "- Call me at[PHONE_NUM].\n",
      "+ Call me at [PHONE_NUM].\n",
      "?           +\n",
      "\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_international_number (__main__.TestReplacePhoneNumbers)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 27, in test_international_number\n",
      "    self.assertEqual(replace_phone_numbers(msg), expected)\n",
      "AssertionError: 'Contact us at[PHONE_NUM].' != 'Contact us at [PHONE_NUM].'\n",
      "- Contact us at[PHONE_NUM].\n",
      "+ Contact us at [PHONE_NUM].\n",
      "?              +\n",
      "\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_number_with_dots (__main__.TestReplacePhoneNumbers)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 37, in test_number_with_dots\n",
      "    self.assertEqual(replace_phone_numbers(msg), expected)\n",
      "AssertionError: 'Fax us at[PHONE_NUM].' != 'Fax us at [PHONE_NUM].'\n",
      "- Fax us at[PHONE_NUM].\n",
      "+ Fax us at [PHONE_NUM].\n",
      "?          +\n",
      "\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_number_with_parentheses (__main__.TestReplacePhoneNumbers)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 32, in test_number_with_parentheses\n",
      "    self.assertEqual(replace_phone_numbers(msg), expected)\n",
      "AssertionError: 'Our office number is[PHONE_NUM].' != 'Our office number is [PHONE_NUM].'\n",
      "- Our office number is[PHONE_NUM].\n",
      "+ Our office number is [PHONE_NUM].\n",
      "?                     +\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.001s\n",
      "\n",
      "FAILED (failures=4)\n",
      "\n",
      "Process completed with return code: 1\n",
      "43\n",
      "\n",
      ".FFFF\n",
      "======================================================================\n",
      "FAIL: test_rgb_to_hsv_blue (__main__.TestRGBtoHSV)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 50, in test_rgb_to_hsv_blue\n",
      "    self.assertEqual(result, expected_result)\n",
      "AssertionError: Tuples differ: (240, 100, 100) != (240, 1, 1)\n",
      "\n",
      "First differing element 1:\n",
      "100\n",
      "1\n",
      "\n",
      "- (240, 100, 100)\n",
      "?        --   --\n",
      "\n",
      "+ (240, 1, 1)\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_rgb_to_hsv_green (__main__.TestRGBtoHSV)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 43, in test_rgb_to_hsv_green\n",
      "    self.assertEqual(result, expected_result)\n",
      "AssertionError: Tuples differ: (120, 100, 100) != (120, 1, 1)\n",
      "\n",
      "First differing element 1:\n",
      "100\n",
      "1\n",
      "\n",
      "- (120, 100, 100)\n",
      "?        --   --\n",
      "\n",
      "+ (120, 1, 1)\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_rgb_to_hsv_red (__main__.TestRGBtoHSV)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 36, in test_rgb_to_hsv_red\n",
      "    self.assertEqual(result, expected_result)\n",
      "AssertionError: Tuples differ: (0, 100, 100) != (0, 1, 1)\n",
      "\n",
      "First differing element 1:\n",
      "100\n",
      "1\n",
      "\n",
      "- (0, 100, 100)\n",
      "?      --   --\n",
      "\n",
      "+ (0, 1, 1)\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_rgb_to_hsv_white (__main__.TestRGBtoHSV)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 57, in test_rgb_to_hsv_white\n",
      "    self.assertEqual(result, expected_result)\n",
      "AssertionError: Tuples differ: (0, 0, 100) != (0, 0, 1)\n",
      "\n",
      "First differing element 2:\n",
      "100\n",
      "1\n",
      "\n",
      "- (0, 0, 100)\n",
      "?         --\n",
      "\n",
      "+ (0, 0, 1)\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.001s\n",
      "\n",
      "FAILED (failures=4)\n",
      "\n",
      "Process completed with return code: 1\n",
      "44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 35/215 [00:04<00:23,  7.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FFFFF\n",
      "======================================================================\n",
      "FAIL: test_custom_column_width (__main__.TestStringSideBySide)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 50, in test_custom_column_width\n",
      "    self.assertEqual(result, expected)\n",
      "AssertionError: 'Hello     Python    \\nWorld     Code      ' != 'Hello      | Python    \\nWorld      | Code      '\n",
      "- Hello     Python    \n",
      "+ Hello      | Python    \n",
      "?          +++\n",
      "- World     Code      + World      | Code      ?           +++\n",
      "\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_empty_first_string (__main__.TestStringSideBySide)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 43, in test_empty_first_string\n",
      "    self.assertEqual(result, expected)\n",
      "AssertionError: '                    Python              \\n                   [17 chars]    ' != '                     | Python              \\n                [23 chars]    '\n",
      "-                     Python              \n",
      "+                      | Python              \n",
      "?                    +++\n",
      "-                     Code                +                      | Code                ?                    +++\n",
      "\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_equal_length_strings (__main__.TestStringSideBySide)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 22, in test_equal_length_strings\n",
      "    self.assertEqual(result, expected)\n",
      "AssertionError: 'Hello               Python              \\nWorld              [17 chars]    ' != 'Hello                | Python              \\nWorld           [23 chars]    '\n",
      "- Hello               Python              \n",
      "+ Hello                | Python              \n",
      "?                    +++\n",
      "- World               Code                + World                | Code                ?                     +++\n",
      "\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_first_string_longer (__main__.TestStringSideBySide)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 29, in test_first_string_longer\n",
      "    self.assertEqual(result, expected)\n",
      "AssertionError: 'Hello               Python              \\nWorld              [59 chars]    ' != 'Hello                | Python              \\nWorld           [68 chars]    '\n",
      "- Hello               Python              \n",
      "+ Hello                | Python              \n",
      "?                    +++\n",
      "- World               Code                \n",
      "+ World                | Code                \n",
      "?                     +++\n",
      "- Test                                    + Test                 |                     \n",
      "\n",
      "======================================================================\n",
      "FAIL: test_second_string_longer (__main__.TestStringSideBySide)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 36, in test_second_string_longer\n",
      "    self.assertEqual(result, expected)\n",
      "AssertionError: 'Hello               Python              \\nWorld              [59 chars]    ' != 'Hello                | Python              \\nWorld           [68 chars]    '\n",
      "- Hello               Python              \n",
      "+ Hello                | Python              \n",
      "?                    +++\n",
      "- World               Code                \n",
      "+ World                | Code                \n",
      "?                     +++\n",
      "-                     Test                +                      | Test                ?                    +++\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.001s\n",
      "\n",
      "FAILED (failures=5)\n",
      "\n",
      "Process completed with return code: 1\n",
      "45\n",
      "\n",
      "F...F\n",
      "======================================================================\n",
      "FAIL: test_beginning_of_month (__main__.TestGetCurrentDateInfo)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 44, in test_beginning_of_month\n",
      "    self.assertEqual(result, expected)\n",
      "AssertionError: {'yea[19 chars]'January', 'week_of_the_month': 2, 'day_of_the_week': 'Sunday'} != {'yea[19 chars]'January', 'week_of_the_month': 1, 'day_of_the_week': 'Sunday'}\n",
      "  {'day_of_the_week': 'Sunday',\n",
      "   'month': 'January',\n",
      "-  'week_of_the_month': 2,\n",
      "?                       ^\n",
      "\n",
      "+  'week_of_the_month': 1,\n",
      "?                       ^\n",
      "\n",
      "   'year': 2023}\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_middle_of_month (__main__.TestGetCurrentDateInfo)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 54, in test_middle_of_month\n",
      "    self.assertEqual(result, expected)\n",
      "AssertionError: {'yea[19 chars]'January', 'week_of_the_month': 4, 'day_of_the_week': 'Sunday'} != {'yea[19 chars]'January', 'week_of_the_month': 3, 'day_of_the_week': 'Sunday'}\n",
      "  {'day_of_the_week': 'Sunday',\n",
      "   'month': 'January',\n",
      "-  'week_of_the_month': 4,\n",
      "?                       ^\n",
      "\n",
      "+  'week_of_the_month': 3,\n",
      "?                       ^\n",
      "\n",
      "   'year': 2023}\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.001s\n",
      "\n",
      "FAILED (failures=2)\n",
      "\n",
      "Process completed with return code: 1\n",
      "46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 37/215 [00:04<00:21,  8.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "47\n",
      "\n",
      "EEEEE\n",
      "======================================================================\n",
      "ERROR: test_edge_year_transition (__main__.TestFindNthWeekdayOfSpecificYear)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 49, in test_edge_year_transition\n",
      "    result = find_nth_weekday_of_specific_year(2023, 12, 1, 4)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 4, in find_nth_weekday_of_specific_year\n",
      "    first_day = datetime.date(y, m, 1)\n",
      "TypeError: descriptor 'date' for 'datetime.datetime' objects doesn't apply to a 'int' object\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_first_day_is_weekday (__main__.TestFindNthWeekdayOfSpecificYear)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 43, in test_first_day_is_weekday\n",
      "    result = find_nth_weekday_of_specific_year(2023, 8, 1, 1)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 4, in find_nth_weekday_of_specific_year\n",
      "    first_day = datetime.date(y, m, 1)\n",
      "TypeError: descriptor 'date' for 'datetime.datetime' objects doesn't apply to a 'int' object\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_last_occurrence (__main__.TestFindNthWeekdayOfSpecificYear)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 31, in test_last_occurrence\n",
      "    result = find_nth_weekday_of_specific_year(2023, 5, 5, 0)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 4, in find_nth_weekday_of_specific_year\n",
      "    first_day = datetime.date(y, m, 1)\n",
      "TypeError: descriptor 'date' for 'datetime.datetime' objects doesn't apply to a 'int' object\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_out_of_range (__main__.TestFindNthWeekdayOfSpecificYear)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 37, in test_out_of_range\n",
      "    result = find_nth_weekday_of_specific_year(2023, 5, 10, 0)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 4, in find_nth_weekday_of_specific_year\n",
      "    first_day = datetime.date(y, m, 1)\n",
      "TypeError: descriptor 'date' for 'datetime.datetime' objects doesn't apply to a 'int' object\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_regular_occurrence (__main__.TestFindNthWeekdayOfSpecificYear)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 25, in test_regular_occurrence\n",
      "    result = find_nth_weekday_of_specific_year(2023, 5, 2, 0)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 4, in find_nth_weekday_of_specific_year\n",
      "    first_day = datetime.date(y, m, 1)\n",
      "TypeError: descriptor 'date' for 'datetime.datetime' objects doesn't apply to a 'int' object\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "FAILED (errors=5)\n",
      "\n",
      "Process completed with return code: 1\n",
      "51\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 1, in <module>\n",
      "    def change_reference_frame(point_cloud: np.array, ref_frame_points: List[np.array]) -> np.array:\n",
      "NameError: name 'np' is not defined\n",
      "\n",
      "Process completed with return code: 1\n",
      "52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 40/215 [00:05<00:18,  9.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "53\n",
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "54\n",
      "\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 4\n",
      "    return [s.replace('\n",
      "                      ^\n",
      "SyntaxError: EOL while scanning string literal\n",
      "\n",
      "Process completed with return code: 1\n",
      "55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 42/215 [00:05<00:17, 10.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "56\n",
      "\n",
      "...F.\n",
      "======================================================================\n",
      "FAIL: test_empty_input_handling (__main__.TestFindShiftJISNotGBK)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 46, in test_empty_input_handling\n",
      "    self.assertTrue(len(self.shiftjis_not_gbk) > 0)  # Expect non-zero length list, confirming function runs\n",
      "AssertionError: False is not true\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "FAILED (failures=1)\n",
      "\n",
      "Process completed with return code: 1\n",
      "57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 45/215 [00:05<00:20,  8.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.003s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "58\n",
      "\n",
      "...\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "59\n",
      "\n",
      ".E..E\n",
      "======================================================================\n",
      "ERROR: test_high_combinations (__main__.TestProbabilityRedBalls)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 31, in test_high_combinations\n",
      "    self.assertAlmostEqual(probability_red_balls(3, 20, 30), comb(20, 3) / comb(50, 3))\n",
      "NameError: name 'comb' is not defined\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_typical_case (__main__.TestProbabilityRedBalls)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 23, in test_typical_case\n",
      "    self.assertAlmostEqual(probability_red_balls(2, 10, 5), comb(10, 2) / comb(15, 2))\n",
      "NameError: name 'comb' is not defined\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "FAILED (errors=2)\n",
      "\n",
      "Process completed with return code: 1\n",
      "60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 48/215 [00:06<00:25,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.022s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "62\n",
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 50/215 [00:06<00:31,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EEEEE\n",
      "======================================================================\n",
      "ERROR: test_empty_dataframe (__main__.TestDataframeToMarkdown)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\pandas\\compat\\_optional.py\", line 142, in import_optional_dependency\n",
      "    module = importlib.import_module(name)\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1014, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 973, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tabulate'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 44, in test_empty_dataframe\n",
      "    result = dataframe_to_markdown(df_empty, 'dummy_path.md')\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 14, in dataframe_to_markdown\n",
      "    markdown_content = df.to_markdown(index=False)\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\pandas\\core\\frame.py\", line 2756, in to_markdown\n",
      "    tabulate = import_optional_dependency(\"tabulate\")\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\pandas\\compat\\_optional.py\", line 145, in import_optional_dependency\n",
      "    raise ImportError(msg)\n",
      "ImportError: Missing optional dependency 'tabulate'.  Use pip or conda to install tabulate.\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_non_string_columns (__main__.TestDataframeToMarkdown)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\pandas\\compat\\_optional.py\", line 142, in import_optional_dependency\n",
      "    module = importlib.import_module(name)\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1014, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 973, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tabulate'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 58, in test_non_string_columns\n",
      "    result = dataframe_to_markdown(df_non_string, 'dummy_path.md')\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 14, in dataframe_to_markdown\n",
      "    markdown_content = df.to_markdown(index=False)\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\pandas\\core\\frame.py\", line 2756, in to_markdown\n",
      "    tabulate = import_optional_dependency(\"tabulate\")\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\pandas\\compat\\_optional.py\", line 145, in import_optional_dependency\n",
      "    raise ImportError(msg)\n",
      "ImportError: Missing optional dependency 'tabulate'.  Use pip or conda to install tabulate.\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_single_row_dataframe (__main__.TestDataframeToMarkdown)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\pandas\\compat\\_optional.py\", line 142, in import_optional_dependency\n",
      "    module = importlib.import_module(name)\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1014, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 973, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tabulate'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 51, in test_single_row_dataframe\n",
      "    result = dataframe_to_markdown(df_single_row, 'dummy_path.md')\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 14, in dataframe_to_markdown\n",
      "    markdown_content = df.to_markdown(index=False)\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\pandas\\core\\frame.py\", line 2756, in to_markdown\n",
      "    tabulate = import_optional_dependency(\"tabulate\")\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\pandas\\compat\\_optional.py\", line 145, in import_optional_dependency\n",
      "    raise ImportError(msg)\n",
      "ImportError: Missing optional dependency 'tabulate'.  Use pip or conda to install tabulate.\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_special_characters (__main__.TestDataframeToMarkdown)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\pandas\\compat\\_optional.py\", line 142, in import_optional_dependency\n",
      "    module = importlib.import_module(name)\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1014, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 973, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tabulate'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 66, in test_special_characters\n",
      "    result = dataframe_to_markdown(df_special_chars, 'dummy_path.md')\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 14, in dataframe_to_markdown\n",
      "    markdown_content = df.to_markdown(index=False)\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\pandas\\core\\frame.py\", line 2756, in to_markdown\n",
      "    tabulate = import_optional_dependency(\"tabulate\")\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\pandas\\compat\\_optional.py\", line 145, in import_optional_dependency\n",
      "    raise ImportError(msg)\n",
      "ImportError: Missing optional dependency 'tabulate'.  Use pip or conda to install tabulate.\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_write_to_file (__main__.TestDataframeToMarkdown)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\pandas\\compat\\_optional.py\", line 142, in import_optional_dependency\n",
      "    module = importlib.import_module(name)\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1014, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 973, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tabulate'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 1342, in patched\n",
      "    return func(*newargs, **newkeywargs)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 36, in test_write_to_file\n",
      "    result = dataframe_to_markdown(self.df, 'dummy_path.md')\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 14, in dataframe_to_markdown\n",
      "    markdown_content = df.to_markdown(index=False)\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\pandas\\core\\frame.py\", line 2756, in to_markdown\n",
      "    tabulate = import_optional_dependency(\"tabulate\")\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\pandas\\compat\\_optional.py\", line 145, in import_optional_dependency\n",
      "    raise ImportError(msg)\n",
      "ImportError: Missing optional dependency 'tabulate'.  Use pip or conda to install tabulate.\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.009s\n",
      "\n",
      "FAILED (errors=5)\n",
      "\n",
      "Process completed with return code: 1\n",
      "64\n",
      "\n",
      "...F.\n",
      "======================================================================\n",
      "FAIL: test_quotes_in_csv (__main__.TestCsvToSqlInsert)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 78, in test_quotes_in_csv\n",
      "    self.assertEqual(result, expected_sql)\n",
      "AssertionError: 'INSE[48 chars]'It\\'s a beautiful day.\\');\\nINSERT INTO test5[54 chars]\\');' != 'INSE[48 chars]'It\\'\\'s a beautiful day.\\');\\nINSERT INTO tes[56 chars]\\');'\n",
      "- INSERT INTO test5 (quote_id, quote) VALUES ('1', 'It's a beautiful day.');\n",
      "+ INSERT INTO test5 (quote_id, quote) VALUES ('1', 'It''s a beautiful day.');\n",
      "?                                                      +\n",
      "  INSERT INTO test5 (quote_id, quote) VALUES ('2', 'She said, \"Hello!\"');\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.017s\n",
      "\n",
      "FAILED (failures=1)\n",
      "\n",
      "Process completed with return code: 1\n",
      "65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 53/215 [00:07<00:21,  7.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FFFEF\n",
      "======================================================================\n",
      "ERROR: test_non_existent_file (__main__.TestFindDuplicateIps)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 1342, in patched\n",
      "    return func(*newargs, **newkeywargs)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 48, in test_non_existent_file\n",
      "    result = find_duplicate_ips([\"nonexistent.txt\"], self.ignored_ips)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 8, in find_duplicate_ips\n",
      "    with open(file, 'r') as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'nonexistent.txt'\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_duplicates_with_ignored (__main__.TestFindDuplicateIps)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 1342, in patched\n",
      "    return func(*newargs, **newkeywargs)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 35, in test_duplicates_with_ignored\n",
      "    self.assertEqual(result, expected_result)\n",
      "AssertionError: {'192.168.0.1': ['file1.txt', 'file1.txt']} != {'192.168.0.1': ['file1.txt']}\n",
      "- {'192.168.0.1': ['file1.txt', 'file1.txt']}\n",
      "?                  -------------\n",
      "\n",
      "+ {'192.168.0.1': ['file1.txt']}\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_multiple_files_one_ignored (__main__.TestFindDuplicateIps)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 1342, in patched\n",
      "    return func(*newargs, **newkeywargs)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 57, in test_multiple_files_one_ignored\n",
      "    self.assertEqual(result, expected_result)\n",
      "AssertionError: {'192[25 chars]'file1.txt', 'file2.txt', 'file2.txt', 'file3.[67 chars]xt']} != {'192[25 chars]'file2.txt']}\n",
      "- {'10.0.0.1': ['file1.txt', 'file2.txt', 'file3.txt'],\n",
      "-  '192.168.0.1': ['file1.txt',\n",
      "? ^\n",
      "\n",
      "+ {'192.168.0.1': ['file1.txt', 'file2.txt']}\n",
      "? ^                            ++++++++++++++\n",
      "\n",
      "-                  'file1.txt',\n",
      "-                  'file2.txt',\n",
      "-                  'file2.txt',\n",
      "-                  'file3.txt',\n",
      "-                  'file3.txt']}\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_multiple_occurrences_single_file (__main__.TestFindDuplicateIps)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 1342, in patched\n",
      "    return func(*newargs, **newkeywargs)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 65, in test_multiple_occurrences_single_file\n",
      "    self.assertEqual(result, expected_result)\n",
      "AssertionError: {'192.168.0.1': ['file1.txt', 'file1.txt', 'file1.txt']} != {'192.168.0.1': ['file1.txt']}\n",
      "- {'192.168.0.1': ['file1.txt', 'file1.txt', 'file1.txt']}\n",
      "+ {'192.168.0.1': ['file1.txt']}\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_single_file_duplicates (__main__.TestFindDuplicateIps)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 1342, in patched\n",
      "    return func(*newargs, **newkeywargs)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 43, in test_single_file_duplicates\n",
      "    self.assertEqual(result, expected_result)\n",
      "AssertionError: {'192.168.0.1': ['file1.txt', 'file1.txt']} != {'192.168.0.1': ['file1.txt']}\n",
      "- {'192.168.0.1': ['file1.txt', 'file1.txt']}\n",
      "?                  -------------\n",
      "\n",
      "+ {'192.168.0.1': ['file1.txt']}\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.012s\n",
      "\n",
      "FAILED (failures=4, errors=1)\n",
      "\n",
      "Process completed with return code: 1\n",
      "66\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 4, in <module>\n",
      "    def topological_sort(courses: Iterable[Course]) -> List[LeveledCourse]:\n",
      "NameError: name 'Course' is not defined\n",
      "\n",
      "Process completed with return code: 1\n",
      "67\n",
      "\n",
      "F....\n",
      "======================================================================\n",
      "FAIL: test_empty_string_values (__main__.TestParseXamlToDict)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 57, in test_empty_string_values\n",
      "    self.assertEqual(result, expected)\n",
      "AssertionError: {} != {'Username': '', 'Password': ''}\n",
      "- {}\n",
      "+ {'Password': '', 'Username': ''}\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "FAILED (failures=1)\n",
      "\n",
      "Process completed with return code: 1\n",
      "68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 54/215 [00:07<00:20,  7.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "70\n",
      "\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 15\n",
      "    return re.findall(r'\n",
      "                       ^\n",
      "SyntaxError: EOL while scanning string literal\n",
      "\n",
      "Process completed with return code: 1\n",
      "71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 56/215 [00:07<00:20,  7.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.014s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "72\n",
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.006s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 58/215 [00:07<00:22,  7.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73\n",
      "\n",
      "E...\n",
      "======================================================================\n",
      "ERROR: test_empty_dictionary (__main__.TestDictOfListsToListOfDicts)\n",
      "Test the function with an empty dictionary.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 41, in test_empty_dictionary\n",
      "    result = dict_of_lists_to_list_of_dicts(dict_of_lists)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 5, in dict_of_lists_to_list_of_dicts\n",
      "    length = len(next(iter(dict_of_lists.values())))\n",
      "StopIteration\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.001s\n",
      "\n",
      "FAILED (errors=1)\n",
      "\n",
      "Process completed with return code: 1\n",
      "74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 60/215 [00:08<00:21,  7.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FFFF\n",
      "======================================================================\n",
      "FAIL: test_advance_32_bit_conversion (__main__.TestConvertDecimalToBinary)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 24, in test_advance_32_bit_conversion\n",
      "    self.assertEqual(convert_decimal_to_binary(1.5, 32), '00111111110000000000000000000000',\n",
      "AssertionError: '00000000000000001100000000111111' != '00111111110000000000000000000000'\n",
      "- 00000000000000001100000000111111\n",
      "+ 00111111110000000000000000000000\n",
      " : 1.5 should be correctly converted to 32-bit binary\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_advance_64_bit_conversion (__main__.TestConvertDecimalToBinary)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 28, in test_advance_64_bit_conversion\n",
      "    self.assertEqual(convert_decimal_to_binary(1.5, 64),\n",
      "AssertionError: '0000000000000000000000000000000000000000000000001111100000111111' != '0011111111111000000000000000000000000000000000000000000000000000'\n",
      "- 0000000000000000000000000000000000000000000000001111100000111111\n",
      "?                                                 -----   --------\n",
      "+ 0011111111111000000000000000000000000000000000000000000000000000\n",
      "? +++++++++++++\n",
      " : 1.5 should be correctly converted to 32-bit binary\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_basic_32_bit_conversion (__main__.TestConvertDecimalToBinary)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 14, in test_basic_32_bit_conversion\n",
      "    self.assertEqual(convert_decimal_to_binary(3.14, 32),\n",
      "AssertionError: '11000011111101010100100001000000' != '01000000010010001111010111000011'\n",
      "- 11000011111101010100100001000000\n",
      "+ 01000000010010001111010111000011\n",
      " : 3.14 should be correctly converted to 32-bit binary\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_basic_64_bit_conversion (__main__.TestConvertDecimalToBinary)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 19, in test_basic_64_bit_conversion\n",
      "    self.assertEqual(convert_decimal_to_binary(3.14, 64),\n",
      "AssertionError: '0001111110000101111010110101000110111000000111100000100101000000' != '0100000000001001000111101011100001010001111010111000010100011111'\n",
      "- 0001111110000101111010110101000110111000000111100000100101000000\n",
      "+ 0100000000001001000111101011100001010001111010111000010100011111\n",
      " : 3.14 should be correctly converted to 64-bit binary\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.002s\n",
      "\n",
      "FAILED (failures=4)\n",
      "\n",
      "Process completed with return code: 1\n",
      "75\n",
      "\n",
      "F.F.F\n",
      "======================================================================\n",
      "FAIL: test_basic_renaming (__main__.TestRenameFiles)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 55, in test_basic_renaming\n",
      "    self.assertEqual(result_files, expected_files)\n",
      "AssertionError: Lists differ: ['image10001.png', 'image20002.png', 'image30003.png'] != ['image1001.png', 'image2001.png', 'image3001.png']\n",
      "\n",
      "First differing element 0:\n",
      "'image10001.png'\n",
      "'image1001.png'\n",
      "\n",
      "- ['image10001.png', 'image20002.png', 'image30003.png']\n",
      "?           -                 ^^                ^^\n",
      "\n",
      "+ ['image1001.png', 'image2001.png', 'image3001.png']\n",
      "?                            ^                ^\n",
      "\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_files_with_existing_numbers (__main__.TestRenameFiles)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 95, in test_files_with_existing_numbers\n",
      "    self.assertEqual(result_files, expected_files)\n",
      "AssertionError: Lists differ: ['file0010001.png', 'file0020002.png', 'file0030003.png'] != ['file001001.png', 'file002001.png', 'file003001.png']\n",
      "\n",
      "First differing element 0:\n",
      "'file0010001.png'\n",
      "'file001001.png'\n",
      "\n",
      "- ['file0010001.png', 'file0020002.png', 'file0030003.png']\n",
      "?            -                  ^^                 ^^\n",
      "\n",
      "+ ['file001001.png', 'file002001.png', 'file003001.png']\n",
      "?                              ^                 ^\n",
      "\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_reset_counter_for_different_base_names (__main__.TestRenameFiles)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 66, in test_reset_counter_for_different_base_names\n",
      "    self.assertEqual(result_files, expected_files)\n",
      "AssertionError: Lists differ: ['image10001.png', 'image20002.png', 'picture10003.png', 'picture20004.png'] != ['image1001.png', 'image2001.png', 'picture1001.png', 'picture2001.png']\n",
      "\n",
      "First differing element 0:\n",
      "'image10001.png'\n",
      "'image1001.png'\n",
      "\n",
      "- ['image10001.png', 'image20002.png', 'picture10003.png', 'picture20004.png']\n",
      "?           -                 ^^                  ^^                  ^^\n",
      "\n",
      "+ ['image1001.png', 'image2001.png', 'picture1001.png', 'picture2001.png']\n",
      "?                            ^                  ^                  ^\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.005s\n",
      "\n",
      "FAILED (failures=3)\n",
      "\n",
      "Process completed with return code: 1\n",
      "76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 61/215 [00:08<00:22,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "77\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 3, in <module>\n",
      "    def format_timestamp_to_string(timestamp: float, date_format: Optional[str] = '%a %b %d %I:%M:%S %p %z %Y') -> str:\n",
      "NameError: name 'Optional' is not defined\n",
      "\n",
      "Process completed with return code: 1\n",
      "78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 64/215 [00:08<00:20,  7.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.007s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "79\n",
      "\n",
      "F.F.\n",
      "======================================================================\n",
      "FAIL: test_different_months_same_year (__main__.TestDateRangeString)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 23, in test_different_months_same_year\n",
      "    self.assertEqual(result, \"August 30 to September 5, 2023\")\n",
      "AssertionError: 'August 30, 2023 to September 5, 2023' != 'August 30 to September 5, 2023'\n",
      "- August 30, 2023 to September 5, 2023\n",
      "?          ------\n",
      "+ August 30 to September 5, 2023\n",
      "\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_incorrect_date_format (__main__.TestDateRangeString)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 34, in test_incorrect_date_format\n",
      "    self.assertTrue(\"Date must be in 'YYYY-MM-DD' format.\" in str(context.exception))\n",
      "AssertionError: False is not true\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.002s\n",
      "\n",
      "FAILED (failures=2)\n",
      "\n",
      "Process completed with return code: 1\n",
      "80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 66/215 [00:08<00:19,  7.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F..F.\n",
      "======================================================================\n",
      "FAIL: test_control_characters (__main__.TestSanitizeFilename)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 32, in test_control_characters\n",
      "    self.assertEqual(sanitize_filename(\"control\\x00char.txt\"), \"control_char.txt\")\n",
      "AssertionError: 'control\\x00char.txt' != 'control_char.txt'\n",
      "- control\u0000char.txt\n",
      "?        ^\n",
      "+ control_char.txt\n",
      "?        ^\n",
      "\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_long_filename (__main__.TestSanitizeFilename)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 38, in test_long_filename\n",
      "    self.assertEqual(len(sanitized_filename), 255)\n",
      "AssertionError: 260 != 255\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.001s\n",
      "\n",
      "FAILED (failures=2)\n",
      "\n",
      "Process completed with return code: 1\n",
      "81\n",
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "82\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 1, in <module>\n",
      "    def cycles_by_size(self, filter_repeat_nodes=True) -> Dict[int, List[nx.Graph]]:\n",
      "NameError: name 'Dict' is not defined\n",
      "\n",
      "Process completed with return code: 1\n",
      "83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 69/215 [00:09<00:15,  9.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "84\n",
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 71/215 [00:09<00:23,  6.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FF.\n",
      "======================================================================\n",
      "FAIL: test_basic_forward_fill (__main__.TestNaiveFfill)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 24, in test_basic_forward_fill\n",
      "    pd.testing.assert_frame_equal(df, expected)\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\pandas\\_testing\\asserters.py\", line 1224, in assert_frame_equal\n",
      "    assert_series_equal(\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\pandas\\_testing\\asserters.py\", line 931, in assert_series_equal\n",
      "    assert_attr_equal(\"dtype\", left, right, obj=f\"Attributes of {obj}\")\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\pandas\\_testing\\asserters.py\", line 415, in assert_attr_equal\n",
      "    raise_assert_detail(obj, msg, left_attr, right_attr)\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\pandas\\_testing\\asserters.py\", line 599, in raise_assert_detail\n",
      "    raise AssertionError(msg)\n",
      "AssertionError: Attributes of DataFrame.iloc[:, 0] (column name=\"A\") are different\n",
      "\n",
      "Attribute \"dtype\" are different\n",
      "[left]:  float64\n",
      "[right]: int64\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_multiple_columns (__main__.TestNaiveFfill)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 36, in test_multiple_columns\n",
      "    pd.testing.assert_frame_equal(df, expected)\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\pandas\\_testing\\asserters.py\", line 1224, in assert_frame_equal\n",
      "    assert_series_equal(\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\pandas\\_testing\\asserters.py\", line 931, in assert_series_equal\n",
      "    assert_attr_equal(\"dtype\", left, right, obj=f\"Attributes of {obj}\")\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\pandas\\_testing\\asserters.py\", line 415, in assert_attr_equal\n",
      "    raise_assert_detail(obj, msg, left_attr, right_attr)\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\pandas\\_testing\\asserters.py\", line 599, in raise_assert_detail\n",
      "    raise AssertionError(msg)\n",
      "AssertionError: Attributes of DataFrame.iloc[:, 0] (column name=\"A\") are different\n",
      "\n",
      "Attribute \"dtype\" are different\n",
      "[left]:  float64\n",
      "[right]: int64\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.002s\n",
      "\n",
      "FAILED (failures=2)\n",
      "\n",
      "Process completed with return code: 1\n",
      "86\n",
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 73/215 [00:10<00:22,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "...\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.006s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "214\n",
      "\n",
      "...\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.006s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 76/215 [00:10<00:16,  8.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.008s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "216\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 2, in <module>\n",
      "    import fcntl\n",
      "ModuleNotFoundError: No module named 'fcntl'\n",
      "\n",
      "Process completed with return code: 1\n",
      "219\n",
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 78/215 [00:10<00:17,  7.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EE.EE\n",
      "======================================================================\n",
      "ERROR: test_add_duplicate_elements (__main__.TestUniqueDeque)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 45, in test_add_duplicate_elements\n",
      "    self.assertEqual(list(ud), [1])\n",
      "TypeError: 'UniqueDeque' object is not iterable\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_add_unique_elements (__main__.TestUniqueDeque)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 38, in test_add_unique_elements\n",
      "    self.assertEqual(list(ud), [1, 2, 3])\n",
      "TypeError: 'UniqueDeque' object is not iterable\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_delete_elements (__main__.TestUniqueDeque)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 55, in test_delete_elements\n",
      "    self.assertEqual(list(ud), [1, 3])\n",
      "TypeError: 'UniqueDeque' object is not iterable\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_iter_and_len (__main__.TestUniqueDeque)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 70, in test_iter_and_len\n",
      "    items = list(iter(ud))\n",
      "TypeError: 'UniqueDeque' object is not iterable\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.001s\n",
      "\n",
      "FAILED (errors=4)\n",
      "\n",
      "Process completed with return code: 1\n",
      "221\n",
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.009s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 79/215 [00:10<00:17,  7.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "...\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.003s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 80/215 [00:11<00:34,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "..F.\n",
      "======================================================================\n",
      "FAIL: test_special_characters (__main__.TestTSVtoJSONL)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 66, in test_special_characters\n",
      "    self.assertEqual(lines, expected_lines)\n",
      "AssertionError: Lists differ: ['{\"N[39 chars]n', '{\"Name\":\"B\\\\u00f6b\",\"Age\":25,\"Country\":\"Ca\\\\u00f1ada\"}\\n'] != ['{\"N[39 chars]n', '{\"Name\":\"B\\xf6b\",\"Age\":25,\"Country\":\"Ca\\xf1ada\"}\\n']\n",
      "\n",
      "First differing element 1:\n",
      "'{\"Name\":\"B\\\\u00f6b\",\"Age\":25,\"Country\":\"Ca\\\\u00f1ada\"}\\n'\n",
      "'{\"Name\":\"B\\xf6b\",\"Age\":25,\"Country\":\"Ca\\xf1ada\"}\\n'\n",
      "\n",
      "  ['{\"Name\":\"Alice\",\"Age\":30,\"Country\":\"U$A\"}\\n',\n",
      "-  '{\"Name\":\"B\\\\u00f6b\",\"Age\":25,\"Country\":\"Ca\\\\u00f1ada\"}\\n']\n",
      "?             ^^^^^^^                         ^^^^^^^\n",
      "\n",
      "+  '{\"Name\":\"B\\xf6b\",\"Age\":25,\"Country\":\"Ca\\xf1ada\"}\\n']\n",
      "?             ^                         ^\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.026s\n",
      "\n",
      "FAILED (failures=1)\n",
      "\n",
      "Process completed with return code: 1\n",
      "227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 82/215 [00:11<00:29,  4.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EEEE\n",
      "======================================================================\n",
      "ERROR: test_case1 (__main__.TestCountUniqueColor)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 25, in test_case1\n",
      "    output = count_unique_colors(picture_path)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 13, in count_unique_colors\n",
      "    with Image.open(image_path) as img:\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\PIL\\Image.py\", line 3431, in open\n",
      "    fp = builtins.open(filename, \"rb\")\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'E:\\\\code\\\\code_back\\\\python_project\\\\RealisticEval-Data\\\\analysis\\\\picture1_2_color.png'\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_case2 (__main__.TestCountUniqueColor)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 31, in test_case2\n",
      "    output = count_unique_colors(picture_path)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 13, in count_unique_colors\n",
      "    with Image.open(image_path) as img:\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\PIL\\Image.py\", line 3431, in open\n",
      "    fp = builtins.open(filename, \"rb\")\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'E:\\\\code\\\\code_back\\\\python_project\\\\RealisticEval-Data\\\\analysis\\\\picture2_1_color.png'\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_case3 (__main__.TestCountUniqueColor)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 37, in test_case3\n",
      "    output = count_unique_colors(picture_path)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 13, in count_unique_colors\n",
      "    with Image.open(image_path) as img:\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\PIL\\Image.py\", line 3431, in open\n",
      "    fp = builtins.open(filename, \"rb\")\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'E:\\\\code\\\\code_back\\\\python_project\\\\RealisticEval-Data\\\\analysis\\\\picture3_2_color.png'\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_case4 (__main__.TestCountUniqueColor)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 43, in test_case4\n",
      "    output = count_unique_colors(picture_path)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 13, in count_unique_colors\n",
      "    with Image.open(image_path) as img:\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\PIL\\Image.py\", line 3431, in open\n",
      "    fp = builtins.open(filename, \"rb\")\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'E:\\\\code\\\\code_back\\\\python_project\\\\RealisticEval-Data\\\\analysis\\\\picture4_5_color.png'\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.001s\n",
      "\n",
      "FAILED (errors=4)\n",
      "\n",
      "Process completed with return code: 1\n",
      "229\n",
      "\n",
      "F.FFF\n",
      "======================================================================\n",
      "FAIL: test_auto_unit_selection (__main__.TestGetFileSize)\n",
      "Test automatic unit selection based on file size\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 25, in test_auto_unit_selection\n",
      "    self.assertEqual(get_file_size(500), ('500 B', 500))  # Bytes\n",
      "AssertionError: Tuples differ: ('B', 500) != ('500 B', 500)\n",
      "\n",
      "First differing element 0:\n",
      "'B'\n",
      "'500 B'\n",
      "\n",
      "- ('B', 500)\n",
      "+ ('500 B', 500)\n",
      "?   ++++\n",
      "\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_large_file_size (__main__.TestGetFileSize)\n",
      "Test with very large file size\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 43, in test_large_file_size\n",
      "    self.assertEqual(get_file_size(10 * 1024 ** 4), ('10240.00 GB', 10240.0))\n",
      "AssertionError: Tuples differ: ('GB', 10240.0) != ('10240.00 GB', 10240.0)\n",
      "\n",
      "First differing element 0:\n",
      "'GB'\n",
      "'10240.00 GB'\n",
      "\n",
      "- ('GB', 10240.0)\n",
      "+ ('10240.00 GB', 10240.0)\n",
      "?   +++++++++\n",
      "\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_specific_unit (__main__.TestGetFileSize)\n",
      "Test output when specific units are requested\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 33, in test_specific_unit\n",
      "    self.assertEqual(get_file_size(1024, 'KB'), ('1.00 KB', 1.0))\n",
      "AssertionError: Tuples differ: ('KB', 1.0) != ('1.00 KB', 1.0)\n",
      "\n",
      "First differing element 0:\n",
      "'KB'\n",
      "'1.00 KB'\n",
      "\n",
      "- ('KB', 1.0)\n",
      "+ ('1.00 KB', 1.0)\n",
      "?   +++++\n",
      "\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_zero_bytes (__main__.TestGetFileSize)\n",
      "Test with zero bytes\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 48, in test_zero_bytes\n",
      "    self.assertEqual(get_file_size(0), ('0 B', 0))\n",
      "AssertionError: Tuples differ: ('B', 0) != ('0 B', 0)\n",
      "\n",
      "First differing element 0:\n",
      "'B'\n",
      "'0 B'\n",
      "\n",
      "- ('B', 0)\n",
      "+ ('0 B', 0)\n",
      "?   ++\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.001s\n",
      "\n",
      "FAILED (failures=4)\n",
      "\n",
      "Process completed with return code: 1\n",
      "230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 84/215 [00:11<00:23,  5.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EEEEE\n",
      "======================================================================\n",
      "ERROR: test_all_emojis (__main__.TestMoveEmojisToEnd)\n",
      "Test string that contains only emojis\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 41, in test_all_emojis\n",
      "    self.assertEqual(move_emojis_to_end(input_text), expected_output)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 15, in move_emojis_to_end\n",
      "    emojis = ''.join(re.findall(emoji.get_emoji_regexp(), text))\n",
      "AttributeError: module 'emoji' has no attribute 'get_emoji_regexp'\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_emojis_and_whitespace (__main__.TestMoveEmojisToEnd)\n",
      "Test string with emojis and whitespace characters\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 53, in test_emojis_and_whitespace\n",
      "    self.assertEqual(move_emojis_to_end(input_text), expected_output)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 15, in move_emojis_to_end\n",
      "    emojis = ''.join(re.findall(emoji.get_emoji_regexp(), text))\n",
      "AttributeError: module 'emoji' has no attribute 'get_emoji_regexp'\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_multiple_emojis_mixed (__main__.TestMoveEmojisToEnd)\n",
      "Test string with multiple emojis mixed in text\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 35, in test_multiple_emojis_mixed\n",
      "    self.assertEqual(move_emojis_to_end(input_text), expected_output)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 15, in move_emojis_to_end\n",
      "    emojis = ''.join(re.findall(emoji.get_emoji_regexp(), text))\n",
      "AttributeError: module 'emoji' has no attribute 'get_emoji_regexp'\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_no_emojis (__main__.TestMoveEmojisToEnd)\n",
      "Test string with no emojis\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 47, in test_no_emojis\n",
      "    self.assertEqual(move_emojis_to_end(input_text), expected_output)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 15, in move_emojis_to_end\n",
      "    emojis = ''.join(re.findall(emoji.get_emoji_regexp(), text))\n",
      "AttributeError: module 'emoji' has no attribute 'get_emoji_regexp'\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_single_emoji_at_start (__main__.TestMoveEmojisToEnd)\n",
      "Test string with a single emoji at the start\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 29, in test_single_emoji_at_start\n",
      "    self.assertEqual(move_emojis_to_end(input_text), expected_output)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 15, in move_emojis_to_end\n",
      "    emojis = ''.join(re.findall(emoji.get_emoji_regexp(), text))\n",
      "AttributeError: module 'emoji' has no attribute 'get_emoji_regexp'\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "FAILED (errors=5)\n",
      "\n",
      "Process completed with return code: 1\n",
      "231\n",
      "\n",
      ".EEF.\n",
      "======================================================================\n",
      "ERROR: test_file_not_found (__main__.TestReadLog)\n",
      "Test behavior when the file does not exist\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 33, in test_file_not_found\n",
      "    train_loss, test_acc1 = read_log(\"nonexistent_path.json\")\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 7, in read_log\n",
      "    with open(log_file_path, 'r') as log_file:\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 1075, in __call__\n",
      "    return self._mock_call(*args, **kwargs)\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 1079, in _mock_call\n",
      "    return self._execute_mock_call(*args, **kwargs)\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 1134, in _execute_mock_call\n",
      "    raise effect\n",
      "FileNotFoundError\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_invalid_json (__main__.TestReadLog)\n",
      "Test behavior when file contains invalid JSON\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 42, in test_invalid_json\n",
      "    train_loss, test_acc1 = read_log(\"dummy_path.json\")\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 9, in read_log\n",
      "    entry = json.loads(line)\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 1075, in __call__\n",
      "    return self._mock_call(*args, **kwargs)\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 1079, in _mock_call\n",
      "    return self._execute_mock_call(*args, **kwargs)\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 1134, in _execute_mock_call\n",
      "    raise effect\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_partial_data_entries (__main__.TestReadLog)\n",
      "Test file with missing fields in some entries\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 59, in test_partial_data_entries\n",
      "    self.assertEqual(train_loss, [0.75])  # Only one complete entry\n",
      "AssertionError: Lists differ: [0.75, None] != [0.75]\n",
      "\n",
      "First list contains 1 additional elements.\n",
      "First extra element 1:\n",
      "None\n",
      "\n",
      "- [0.75, None]\n",
      "+ [0.75]\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.009s\n",
      "\n",
      "FAILED (failures=1, errors=2)\n",
      "\n",
      "Process completed with return code: 1\n",
      "232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 86/215 [00:12<00:18,  7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "233\n",
      "\n",
      "..F.F\n",
      "======================================================================\n",
      "FAIL: test_multi_line_comments (__main__.TestRemoveComments)\n",
      "Test string with multiple lines, each containing comments\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 29, in test_multi_line_comments\n",
      "    self.assertEqual(remove_comments(input_string), expected_output)\n",
      "AssertionError: 'Hello, world!\\n\\nPython is fun!' != 'Hello, world!\\n\\nPython is fun! '\n",
      "  Hello, world!\n",
      "  \n",
      "- Python is fun!+ Python is fun! ?               +\n",
      "\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_single_line_comment (__main__.TestRemoveComments)\n",
      "Test string with a comment on a single line\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 23, in test_single_line_comment\n",
      "    self.assertEqual(remove_comments(input_string), expected_output)\n",
      "AssertionError: 'Hello, world!' != 'Hello, world! '\n",
      "- Hello, world!\n",
      "+ Hello, world! \n",
      "?              +\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.001s\n",
      "\n",
      "FAILED (failures=2)\n",
      "\n",
      "Process completed with return code: 1\n",
      "234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 88/215 [00:12<00:16,  7.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "235\n",
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "240\n",
      "\n",
      "F.\n",
      "======================================================================\n",
      "FAIL: test_complete_time_string (__main__.TestGenTimeoutTimedelta)\n",
      "Test a string containing all time units\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 37, in test_complete_time_string\n",
      "    self.assertEqual(result.seconds, (2 * 3600) + (3 * 60) + 4)\n",
      "AssertionError: 37384 != 7384\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.000s\n",
      "\n",
      "FAILED (failures=1)\n",
      "\n",
      "Process completed with return code: 1\n",
      "241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 91/215 [00:12<00:14,  8.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....F\n",
      "======================================================================\n",
      "FAIL: test_words_on_same_line_multiple_times (__main__.TestGetMinDistance)\n",
      "Test where words appear multiple times on the same line\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 43, in test_words_on_same_line_multiple_times\n",
      "    self.assertEqual((line_number, distance), (0, 1))\n",
      "AssertionError: Tuples differ: (1, 1) != (0, 1)\n",
      "\n",
      "First differing element 0:\n",
      "1\n",
      "0\n",
      "\n",
      "- (1, 1)\n",
      "?  ^\n",
      "\n",
      "+ (0, 1)\n",
      "?  ^\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.010s\n",
      "\n",
      "FAILED (failures=1)\n",
      "\n",
      "Process completed with return code: 1\n",
      "242\n",
      "\n",
      "..FF.\n",
      "======================================================================\n",
      "FAIL: test_files_with_same_extension (__main__.TestClassifyFilesByExtension)\n",
      "Test with multiple files having the same extension.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 80, in test_files_with_same_extension\n",
      "    self.assertEqual(classify_files_by_extension(files), expected_result)\n",
      "AssertionError: {'txt': ['file1.txt', 'file2.txt', 'file3.txt'], 'TXT': ['file4.TXT']} != {'txt': ['file1.txt', 'file2.txt', 'file3.txt', 'file4.TXT']}\n",
      "- {'TXT': ['file4.TXT'], 'txt': ['file1.txt', 'file2.txt', 'file3.txt']}\n",
      "+ {'txt': ['file1.txt', 'file2.txt', 'file3.txt', 'file4.TXT']}\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_multiple_file_types (__main__.TestClassifyFilesByExtension)\n",
      "Test with multiple file types.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 45, in test_multiple_file_types\n",
      "    self.assertEqual(classify_files_by_extension(files), expected_result)\n",
      "AssertionError: {'doc[52 chars]: ['report.pdf'], 'PNG': ['image.PNG'], 'zip': ['archive.zip']} != {'doc[52 chars]: ['report.pdf'], 'png': ['image.PNG'], 'zip': ['archive.zip']}\n",
      "- {'PNG': ['image.PNG'],\n",
      "-  'docx': ['document.docx'],\n",
      "? ^\n",
      "\n",
      "+ {'docx': ['document.docx'],\n",
      "? ^\n",
      "\n",
      "   'jpeg': ['photo.jpeg'],\n",
      "   'pdf': ['report.pdf'],\n",
      "+  'png': ['image.PNG'],\n",
      "   'zip': ['archive.zip']}\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.001s\n",
      "\n",
      "FAILED (failures=2)\n",
      "\n",
      "Process completed with return code: 1\n",
      "244\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 1, in <module>\n",
      "    from typing import Callable, inspect\n",
      "ImportError: cannot import name 'inspect' from 'typing' (D:\\sdk\\python\\py38\\lib\\typing.py)\n",
      "\n",
      "Process completed with return code: 1\n",
      "248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 94/215 [00:13<00:13,  8.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".E...\n",
      "======================================================================\n",
      "ERROR: test_list_of_dicts (__main__.TestSanitizeData)\n",
      "Test a list containing dictionaries.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 58, in test_list_of_dicts\n",
      "    self.assertEqual(sanitize_data(data,key_to_remove), expected)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 6, in sanitize_data\n",
      "    return {k: v for k, v in data.items() if k not in key_to_remove}\n",
      "AttributeError: 'list' object has no attribute 'items'\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "FAILED (errors=1)\n",
      "\n",
      "Process completed with return code: 1\n",
      "249\n",
      "\n",
      "EE\n",
      "======================================================================\n",
      "ERROR: test_empty_file (__main__.TestExtractTextFromPDF)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 26, in test_empty_file\n",
      "    output = extract_text_from_pdf(pdf_path)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 53, in extract_text_from_pdf\n",
      "    with open(file_path, \"rb\") as file:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: './testcase1_empty.pdf'\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_normal_file (__main__.TestExtractTextFromPDF)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 32, in test_normal_file\n",
      "    output = extract_text_from_pdf(pdf_path)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 53, in extract_text_from_pdf\n",
      "    with open(file_path, \"rb\") as file:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: './testcase2_normal.pdf'\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.000s\n",
      "\n",
      "FAILED (errors=2)\n",
      "\n",
      "Process completed with return code: 1\n",
      "250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 96/215 [00:13<00:13,  8.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "252\n",
      "\n",
      ".FF..\n",
      "======================================================================\n",
      "FAIL: test_complex_structure_with_bits (__main__.TestBitSequenceEncoder)\n",
      "Test encoding a complex dictionary structure containing multiple 'bits' keys.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 51, in test_complex_structure_with_bits\n",
      "    self.assertEqual(result, '{\"processor\": {\"bits\": \"00000011\", \"type\": \"A\"}, \"memory\": {\"bits\": \"11111111\", \"size\": 16}, \"ports\": {\"count\": 2, \"bits\": \"10000000\"}}')\n",
      "AssertionError: '{\"pr[14 chars]ts\": 3, \"type\": \"A\"}, \"memory\": {\"bits\": 255, [44 chars]28}}' != '{\"pr[14 chars]ts\": \"00000011\", \"type\": \"A\"}, \"memory\": {\"bit[67 chars]0\"}}'\n",
      "- {\"processor\": {\"bits\": 3, \"type\": \"A\"}, \"memory\": {\"bits\": 255, \"size\": 16}, \"ports\": {\"count\": 2, \"bits\": 128}}\n",
      "?                        ^                                   ^^^                                              ^^\n",
      "+ {\"processor\": {\"bits\": \"00000011\", \"type\": \"A\"}, \"memory\": {\"bits\": \"11111111\", \"size\": 16}, \"ports\": {\"count\": 2, \"bits\": \"10000000\"}}\n",
      "?                        ^^^^^^^^^^                                   ^^^^^^^^^^                                             + ^^^^^^^^\n",
      "\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_nested_encoding (__main__.TestBitSequenceEncoder)\n",
      "Test encoding with nested dictionary containing 'bits'.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 29, in test_nested_encoding\n",
      "    self.assertEqual(result, '{\"component\": {\"name\": \"ALU\", \"bits\": \"10000000\"}, \"bits\": \"00000001\"}')\n",
      "AssertionError: '{\"component\": {\"name\": \"ALU\", \"bits\": 128}, \"bits\": \"1\"}' != '{\"component\": {\"name\": \"ALU\", \"bits\": \"10000000\"}, \"bits\": \"00000001\"}'\n",
      "- {\"component\": {\"name\": \"ALU\", \"bits\": 128}, \"bits\": \"1\"}\n",
      "?                                        ^^\n",
      "+ {\"component\": {\"name\": \"ALU\", \"bits\": \"10000000\"}, \"bits\": \"00000001\"}\n",
      "?                                       + ^^^^^^^^            +++++++\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.001s\n",
      "\n",
      "FAILED (failures=2)\n",
      "\n",
      "Process completed with return code: 1\n",
      "253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 97/215 [00:13<00:13,  8.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FF..F\n",
      "======================================================================\n",
      "FAIL: test_log_dictionary (__main__.TestLogFunction)\n",
      "Test logging a dictionary as JSON\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 1342, in patched\n",
      "    return func(*newargs, **newkeywargs)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 42, in test_log_dictionary\n",
      "    mock_print.assert_called_once_with(expected_json_output)\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 919, in assert_called_once_with\n",
      "    return self.assert_called_with(*args, **kwargs)\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 907, in assert_called_with\n",
      "    raise AssertionError(_error_message()) from cause\n",
      "AssertionError: expected call not found.\n",
      "Expected: print('{\\n    \"key\": \"value\",\\n    \"number\": 42\\n}')\n",
      "Actual: print('{\\n  \"key\": \"value\",\\n  \"number\": 42\\n}')\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_log_list (__main__.TestLogFunction)\n",
      "Test logging a list as JSON\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 1342, in patched\n",
      "    return func(*newargs, **newkeywargs)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 49, in test_log_list\n",
      "    mock_print.assert_called_once_with(expected_json_output)\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 919, in assert_called_once_with\n",
      "    return self.assert_called_with(*args, **kwargs)\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 907, in assert_called_with\n",
      "    raise AssertionError(_error_message()) from cause\n",
      "AssertionError: expected call not found.\n",
      "Expected: print('[\\n    1,\\n    2,\\n    3,\\n    4,\\n    5\\n]')\n",
      "Actual: print('[\\n  1,\\n  2,\\n  3,\\n  4,\\n  5\\n]')\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_log_unsupported_type (__main__.TestLogFunction)\n",
      "Test logging an unsupported type\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 1342, in patched\n",
      "    return func(*newargs, **newkeywargs)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 56, in test_log_unsupported_type\n",
      "    mock_print.assert_called_once_with(expected_error_message)\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 919, in assert_called_once_with\n",
      "    return self.assert_called_with(*args, **kwargs)\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 907, in assert_called_with\n",
      "    raise AssertionError(_error_message()) from cause\n",
      "AssertionError: expected call not found.\n",
      "Expected: print('Error: Unsupported type TestLogFunction for logging.')\n",
      "Actual: print(\"Error: Unsupported type <class '__main__.TestLogFunction'>\")\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.002s\n",
      "\n",
      "FAILED (failures=3)\n",
      "\n",
      "Process completed with return code: 1\n",
      "255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 99/215 [00:13<00:15,  7.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.008s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "256\n",
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 101/215 [00:13<00:14,  7.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "...F.\n",
      "======================================================================\n",
      "FAIL: test_multibyte_character (__main__.TestExtractCharacterBits)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 59, in test_multibyte_character\n",
      "    self.assertEqual(bits, '11100010 10000001 10000010')\n",
      "AssertionError: '111000111000000110101011' != '11100010 10000001 10000010'\n",
      "- 111000111000000110101011\n",
      "?        ^            ----\n",
      "+ 11100010 10000001 10000010\n",
      "?        ^^        + ++++\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.001s\n",
      "\n",
      "FAILED (failures=1)\n",
      "\n",
      "Process completed with return code: 1\n",
      "259\n",
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 103/215 [00:14<00:21,  5.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FEEEEF.\n",
      "======================================================================\n",
      "ERROR: test_clean_csv (__main__.TestCleanCSV)\n",
      "Test the cleaning functionality of the CSV.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 42, in test_clean_csv\n",
      "    clean_csv(self.input_file_path, self.output_file_path)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 10, in clean_csv\n",
      "    df = pd.read_csv(input_file_path)\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 912, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 583, in _read\n",
      "    return parser.read(nrows)\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 1704, in read\n",
      "    ) = self._engine.read(  # type: ignore[attr-defined]\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\", line 234, in read\n",
      "    chunks = self._reader.read_low_memory(nrows)\n",
      "  File \"pandas\\_libs\\parsers.pyx\", line 814, in pandas._libs.parsers.TextReader.read_low_memory\n",
      "  File \"pandas\\_libs\\parsers.pyx\", line 875, in pandas._libs.parsers.TextReader._read_rows\n",
      "  File \"pandas\\_libs\\parsers.pyx\", line 850, in pandas._libs.parsers.TextReader._tokenize_rows\n",
      "  File \"pandas\\_libs\\parsers.pyx\", line 861, in pandas._libs.parsers.TextReader._check_tokenize_status\n",
      "  File \"pandas\\_libs\\parsers.pyx\", line 2029, in pandas._libs.parsers.raise_parser_error\n",
      "pandas.errors.ParserError: Error tokenizing data. C error: Expected 4 fields in line 5, saw 5\n",
      "\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_clean_csv (__main__.TestCleanCSV)\n",
      "Test the cleaning functionality of the CSV.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 38, in tearDown\n",
      "    os.remove(self.output_file_path)\n",
      "FileNotFoundError: [WinError 2] ϵͳҲָļ: 'test_output.csv'\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_empty_file (__main__.TestCleanCSV)\n",
      "Test with an empty input file.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 57, in test_empty_file\n",
      "    clean_csv(self.input_file_path, self.output_file_path)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 10, in clean_csv\n",
      "    df = pd.read_csv(input_file_path)\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 912, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 577, in _read\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 1407, in __init__\n",
      "    self._engine = self._make_engine(f, self.engine)\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 1679, in _make_engine\n",
      "    return mapping[engine](f, **self.options)\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\", line 93, in __init__\n",
      "    self._reader = parsers.TextReader(src, **kwds)\n",
      "  File \"pandas\\_libs\\parsers.pyx\", line 557, in pandas._libs.parsers.TextReader.__cinit__\n",
      "pandas.errors.EmptyDataError: No columns to parse from file\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_empty_file (__main__.TestCleanCSV)\n",
      "Test with an empty input file.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 38, in tearDown\n",
      "    os.remove(self.output_file_path)\n",
      "FileNotFoundError: [WinError 2] ϵͳҲָļ: 'test_output.csv'\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_all_rows_invalid (__main__.TestCleanCSV)\n",
      "Test when all rows should be filtered out.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 69, in test_all_rows_invalid\n",
      "    self.assertEqual(result, [])\n",
      "AssertionError: Lists differ: [['John', 'Unnamed: 1', 'Unnamed: 2']] != []\n",
      "\n",
      "First list contains 1 additional elements.\n",
      "First extra element 0:\n",
      "['John', 'Unnamed: 1', 'Unnamed: 2']\n",
      "\n",
      "- [['John', 'Unnamed: 1', 'Unnamed: 2']]\n",
      "+ []\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_mixed_rows (__main__.TestCleanCSV)\n",
      "Test a file containing a mix of valid and invalid rows.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 100, in test_mixed_rows\n",
      "    self.assertEqual(result, expected)\n",
      "AssertionError: Lists differ: [['Eve', 'Unnamed: 1', 'Unnamed: 2'], ['28', 'Seattle', 'WA']] != [['Adam', '28', 'Seattle', 'WA']]\n",
      "\n",
      "First differing element 0:\n",
      "['Eve', 'Unnamed: 1', 'Unnamed: 2']\n",
      "['Adam', '28', 'Seattle', 'WA']\n",
      "\n",
      "First list contains 1 additional elements.\n",
      "First extra element 1:\n",
      "['28', 'Seattle', 'WA']\n",
      "\n",
      "- [['Eve', 'Unnamed: 1', 'Unnamed: 2'], ['28', 'Seattle', 'WA']]\n",
      "+ [['Adam', '28', 'Seattle', 'WA']]\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.037s\n",
      "\n",
      "FAILED (failures=2, errors=4)\n",
      "\n",
      "Process completed with return code: 1\n",
      "262\n",
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 105/215 [00:14<00:17,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "264\n",
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.015s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 107/215 [00:15<00:14,  7.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F.EFF\n",
      "======================================================================\n",
      "ERROR: test_list_of_mixed_data_types (__main__.TestHandleNestedData)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 35, in test_list_of_mixed_data_types\n",
      "    self.assertEqual(handle_nested_data(data), expected)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 15, in handle_nested_data\n",
      "    return {key: convert_value(value) for key, value in data.items()}\n",
      "AttributeError: 'list' object has no attribute 'items'\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_complex_nested_structure (__main__.TestHandleNestedData)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 55, in test_complex_nested_structure\n",
      "    self.assertEqual(handle_nested_data(data), expected)\n",
      "AssertionError: {'tea[31 chars]s': ['1000', '2000.2']}, {'name': 'Daisy', 'sk[38 chars]2'}]} != {'tea[31 chars]s': [1000, 2000.2]}, {'name': 'Daisy', 'skills[32 chars]22}]}\n",
      "- {'team': [{'name': 'Charlie', 'scores': ['1000', '2000.2']},\n",
      "?                                          -    -  -      -\n",
      "\n",
      "+ {'team': [{'name': 'Charlie', 'scores': [1000, 2000.2]},\n",
      "-           {'age': '22', 'name': 'Daisy', 'skills': ['Coding', 'Design']}]}\n",
      "?                   -  -\n",
      "\n",
      "+           {'age': 22, 'name': 'Daisy', 'skills': ['Coding', 'Design']}]}\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_nested_dictionary (__main__.TestHandleNestedData)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 30, in test_nested_dictionary\n",
      "    self.assertEqual(handle_nested_data(data), expected)\n",
      "AssertionError: {'user': {'name': 'Bob', 'details': {'age': '25', 'height': '175.5'}}} != {'user': {'name': 'Bob', 'details': {'age': 25, 'height': 175.5}}}\n",
      "- {'user': {'details': {'age': '25', 'height': '175.5'}, 'name': 'Bob'}}\n",
      "?                              -  -            -     -\n",
      "\n",
      "+ {'user': {'details': {'age': 25, 'height': 175.5}, 'name': 'Bob'}}\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_simple_dictionary (__main__.TestHandleNestedData)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 25, in test_simple_dictionary\n",
      "    self.assertEqual(handle_nested_data(data), expected)\n",
      "AssertionError: {'name': 'Alice', 'age': '30'} != {'name': 'Alice', 'age': 30}\n",
      "- {'age': '30', 'name': 'Alice'}\n",
      "?         -  -\n",
      "\n",
      "+ {'age': 30, 'name': 'Alice'}\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.001s\n",
      "\n",
      "FAILED (failures=3, errors=1)\n",
      "\n",
      "Process completed with return code: 1\n",
      "267\n",
      "\n",
      "F..F.\n",
      "======================================================================\n",
      "FAIL: test_edge_case_empty_string (__main__.TestExtractSldTld)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 30, in test_edge_case_empty_string\n",
      "    extract_sld_tld(\"\")\n",
      "AssertionError: ValueError not raised\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_single_level_domain (__main__.TestExtractSldTld)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 25, in test_single_level_domain\n",
      "    extract_sld_tld(\"localhost\")\n",
      "AssertionError: ValueError not raised\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "FAILED (failures=2)\n",
      "\n",
      "Process completed with return code: 1\n",
      "268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 109/215 [00:15<00:13,  8.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "269\n",
      "\n",
      "...\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 111/215 [00:15<00:11,  8.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "..F..\n",
      "======================================================================\n",
      "FAIL: test_vectors_of_different_lengths (__main__.TestSquaredEuclideanDistance)\n",
      "Test vectors of different lengths to ensure it raises ValueError.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 21, in test_vectors_of_different_lengths\n",
      "    squared_euclidean_distance(vec1, vec2)\n",
      "AssertionError: ValueError not raised\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "FAILED (failures=1)\n",
      "\n",
      "Process completed with return code: 1\n",
      "282\n",
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 113/215 [00:15<00:11,  8.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "288\n",
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 115/215 [00:15<00:11,  8.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FF.FF\n",
      "======================================================================\n",
      "FAIL: test_basic_conversion (__main__.TestRDFJSONLDToNGSILDConversion)\n",
      "Test a basic and correct conversion from JSON-LD to NGSI-LD.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 66, in test_basic_conversion\n",
      "    self.assertEqual(result, expected_ngsild)\n",
      "AssertionError: {} != {'id': 'urn:ngsi-ld:Vehicle:A123', 'type':[138 chars]'}}]}\n",
      "- {}\n",
      "+ {'@context': 'http://schema.org/',\n",
      "+  'attributes': [{'name': 'speed',\n",
      "+                  'type': 'Property',\n",
      "+                  'value': {'unitCode': 'KMH', 'value': 60}}],\n",
      "+  'id': 'urn:ngsi-ld:Vehicle:A123',\n",
      "+  'type': 'Vehicle'}\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_empty_jsonld (__main__.TestRDFJSONLDToNGSILDConversion)\n",
      "Test the conversion of an empty JSON-LD document.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 120, in test_empty_jsonld\n",
      "    self.assertEqual(result, expected_ngsild)\n",
      "AssertionError: {} != {'id': 'urn:ngsi-ld:unknown:id', 'type': '[82 chars]: []}\n",
      "- {}\n",
      "+ {'@context': 'https://schema.lab.fiware.org/ld/context',\n",
      "+  'attributes': [],\n",
      "+  'id': 'urn:ngsi-ld:unknown:id',\n",
      "+  'type': 'UnknownType'}\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_missing_id_and_type (__main__.TestRDFJSONLDToNGSILDConversion)\n",
      "Test conversion when @id and @type are missing.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 83, in test_missing_id_and_type\n",
      "    self.assertEqual(result, expected_ngsild)\n",
      "AssertionError: {} != {'id': 'urn:ngsi-ld:unknown:id', 'type': '[140 chars]'}}]}\n",
      "- {}\n",
      "+ {'@context': 'http://schema.org/',\n",
      "+  'attributes': [{'name': 'speed',\n",
      "+                  'type': 'Property',\n",
      "+                  'value': {'unitCode': 'KMH', 'value': 60}}],\n",
      "+  'id': 'urn:ngsi-ld:unknown:id',\n",
      "+  'type': 'UnknownType'}\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_with_nested_objects (__main__.TestRDFJSONLDToNGSILDConversion)\n",
      "Test conversion with nested objects.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 102, in test_with_nested_objects\n",
      "    self.assertEqual(result, expected_ngsild)\n",
      "AssertionError: {} != {'id': 'urn:ngsi-ld:Vehicle:A123', 'type':[151 chars]2}}]}\n",
      "- {}\n",
      "+ {'@context': 'http://schema.org/',\n",
      "+  'attributes': [{'name': 'location',\n",
      "+                  'type': 'Property',\n",
      "+                  'value': {'latitude': 48.8566, 'longitude': 2.3522}}],\n",
      "+  'id': 'urn:ngsi-ld:Vehicle:A123',\n",
      "+  'type': 'Vehicle'}\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.001s\n",
      "\n",
      "FAILED (failures=4)\n",
      "\n",
      "Process completed with return code: 1\n",
      "291\n",
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.019s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 117/215 [00:16<00:16,  5.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".E...\n",
      "======================================================================\n",
      "ERROR: test_extract_nonexistent_document (__main__.TestExtractTextFromWord)\n",
      "Test extraction from a non-existent Word file.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 63, in test_extract_nonexistent_document\n",
      "    extracted_text = extract_text_from_word(nonexistent_docx_path)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 13, in extract_text_from_word\n",
      "    doc = Document(docx_file_path)\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\docx\\api.py\", line 27, in Document\n",
      "    document_part = cast(\"DocumentPart\", Package.open(docx).main_document_part)\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\docx\\opc\\package.py\", line 127, in open\n",
      "    pkg_reader = PackageReader.from_file(pkg_file)\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\docx\\opc\\pkgreader.py\", line 22, in from_file\n",
      "    phys_reader = PhysPkgReader(pkg_file)\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\docx\\opc\\phys_pkg.py\", line 21, in __new__\n",
      "    raise PackageNotFoundError(\"Package not found at '%s'\" % pkg_file)\n",
      "docx.opc.exceptions.PackageNotFoundError: Package not found at 'nonexistent_document.docx'\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.196s\n",
      "\n",
      "FAILED (errors=1)\n",
      "\n",
      "Process completed with return code: 1\n",
      "369\n",
      "\n",
      ".E.\n",
      "======================================================================\n",
      "ERROR: test_no_solution_scenario (__main__.TestEightQueens)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 59, in test_no_solution_scenario\n",
      "    no_solution_queens()\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 55, in no_solution_queens\n",
      "    if not solve_queens(board, 0):\n",
      "NameError: name 'solve_queens' is not defined\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.001s\n",
      "\n",
      "FAILED (errors=1)\n",
      "\n",
      "Process completed with return code: 1\n",
      "370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 119/215 [00:16<00:13,  7.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "380\n",
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "381\n",
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 121/215 [00:16<00:12,  7.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "386\n",
      "\n",
      "...\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.017s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 123/215 [00:17<00:11,  7.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".F.E.\n",
      "======================================================================\n",
      "ERROR: test_input_not_string (__main__.TestSplitIntoSentences)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 37, in test_input_not_string\n",
      "    split_into_sentences(text)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 5, in split_into_sentences\n",
      "    sentences = re.split(r'(?<=[.!?]) +', text)\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\re.py\", line 229, in split\n",
      "    return _compile(pattern, flags).split(string, maxsplit)\n",
      "TypeError: expected string or bytes-like object\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_complex_punctuation (__main__.TestSplitIntoSentences)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 24, in test_complex_punctuation\n",
      "    self.assertEqual(result, expected)\n",
      "AssertionError: Lists differ: ['He said, \"This is amazing!\" Then he left.'] != ['He said, \"This is amazing!\"', 'Then he left.']\n",
      "\n",
      "First differing element 0:\n",
      "'He said, \"This is amazing!\" Then he left.'\n",
      "'He said, \"This is amazing!\"'\n",
      "\n",
      "Second list contains 1 additional elements.\n",
      "First extra element 1:\n",
      "'Then he left.'\n",
      "\n",
      "- ['He said, \"This is amazing!\" Then he left.']\n",
      "?                              ^\n",
      "\n",
      "+ ['He said, \"This is amazing!\"', 'Then he left.']\n",
      "?                              ^^^^\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.001s\n",
      "\n",
      "FAILED (failures=1, errors=1)\n",
      "\n",
      "Process completed with return code: 1\n",
      "392\n",
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "394\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 1, in <module>\n",
      "    def gradient_descent_euclidean(start: np.array, learning_rate: float, n_steps: int, grad_f: Callable):\n",
      "NameError: name 'np' is not defined\n",
      "\n",
      "Process completed with return code: 1\n",
      "395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 126/215 [00:17<00:09,  9.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "396\n",
      "\n",
      ".......\n",
      "----------------------------------------------------------------------\n",
      "Ran 7 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 128/215 [00:17<00:09,  9.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EEEEE\n",
      "======================================================================\n",
      "ERROR: test_all_files_excluded (__main__.TestExtractFiles)\n",
      "Test when all files are excluded.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 74, in test_all_files_excluded\n",
      "    extract_files_excluding_csv(self.folderA, csv_file, self.folderB)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 7, in extract_files_excluding_csv\n",
      "    excluded_files = {line.strip() for line in csv.reader(file).next()}\n",
      "AttributeError: '_csv.reader' object has no attribute 'next'\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_basic_functionality (__main__.TestExtractFiles)\n",
      "Test basic functionality with some files excluded.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 53, in test_basic_functionality\n",
      "    extract_files_excluding_csv(self.folderA, csv_file, self.folderB)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 7, in extract_files_excluding_csv\n",
      "    excluded_files = {line.strip() for line in csv.reader(file).next()}\n",
      "AttributeError: '_csv.reader' object has no attribute 'next'\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_destination_folder_already_has_files (__main__.TestExtractFiles)\n",
      "Test when folderB already contains files.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 87, in test_destination_folder_already_has_files\n",
      "    extract_files_excluding_csv(self.folderA, csv_file, self.folderB)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 7, in extract_files_excluding_csv\n",
      "    excluded_files = {line.strip() for line in csv.reader(file).next()}\n",
      "AttributeError: '_csv.reader' object has no attribute 'next'\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_empty_csv_file (__main__.TestExtractFiles)\n",
      "Test with an empty CSV file.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 99, in test_empty_csv_file\n",
      "    extract_files_excluding_csv(self.folderA, csv_file, self.folderB)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 7, in extract_files_excluding_csv\n",
      "    excluded_files = {line.strip() for line in csv.reader(file).next()}\n",
      "AttributeError: '_csv.reader' object has no attribute 'next'\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_empty_folderA (__main__.TestExtractFiles)\n",
      "Test when folderA is empty.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 62, in test_empty_folderA\n",
      "    extract_files_excluding_csv(self.folderA, csv_file, self.folderB)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 7, in extract_files_excluding_csv\n",
      "    excluded_files = {line.strip() for line in csv.reader(file).next()}\n",
      "AttributeError: '_csv.reader' object has no attribute 'next'\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.016s\n",
      "\n",
      "FAILED (errors=5)\n",
      "\n",
      "Process completed with return code: 1\n",
      "401\n",
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 130/215 [00:17<00:09,  8.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "405\n",
      "\n",
      "......\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 131/215 [00:17<00:09,  8.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FFFFFF\n",
      "======================================================================\n",
      "FAIL: test_blue (__main__.TestColors)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 39, in test_blue\n",
      "    self.assertEqual(Colors.blue(\"hello\"), '\\033[34mhello\\033[0m')\n",
      "AssertionError: '\\x1b[94mhello\\x1b[0m' != '\\x1b[34mhello\\x1b[0m'\n",
      "- \u001B[94mhello\u001B[0m\n",
      "?   ^\n",
      "+ \u001B[34mhello\u001B[0m\n",
      "?   ^\n",
      "\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_cyan (__main__.TestColors)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 51, in test_cyan\n",
      "    self.assertEqual(Colors.cyan(\"hello\"), '\\033[36mhello\\033[0m')\n",
      "AssertionError: '\\x1b[96mhello\\x1b[0m' != '\\x1b[36mhello\\x1b[0m'\n",
      "- \u001B[96mhello\u001B[0m\n",
      "?   ^\n",
      "+ \u001B[36mhello\u001B[0m\n",
      "?   ^\n",
      "\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_green (__main__.TestColors)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 35, in test_green\n",
      "    self.assertEqual(Colors.green(\"hello\"), '\\033[32mhello\\033[0m')\n",
      "AssertionError: '\\x1b[92mhello\\x1b[0m' != '\\x1b[32mhello\\x1b[0m'\n",
      "- \u001B[92mhello\u001B[0m\n",
      "?   ^\n",
      "+ \u001B[32mhello\u001B[0m\n",
      "?   ^\n",
      "\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_magenta (__main__.TestColors)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 47, in test_magenta\n",
      "    self.assertEqual(Colors.magenta(\"hello\"), '\\033[35mhello\\033[0m')\n",
      "AssertionError: '\\x1b[95mhello\\x1b[0m' != '\\x1b[35mhello\\x1b[0m'\n",
      "- \u001B[95mhello\u001B[0m\n",
      "?   ^\n",
      "+ \u001B[35mhello\u001B[0m\n",
      "?   ^\n",
      "\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_red (__main__.TestColors)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 31, in test_red\n",
      "    self.assertEqual(Colors.red(\"hello\"), '\\033[31mhello\\033[0m')\n",
      "AssertionError: '\\x1b[91mhello\\x1b[0m' != '\\x1b[31mhello\\x1b[0m'\n",
      "- \u001B[91mhello\u001B[0m\n",
      "?   ^\n",
      "+ \u001B[31mhello\u001B[0m\n",
      "?   ^\n",
      "\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_yellow (__main__.TestColors)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 43, in test_yellow\n",
      "    self.assertEqual(Colors.yellow(\"hello\"), '\\033[33mhello\\033[0m')\n",
      "AssertionError: '\\x1b[93mhello\\x1b[0m' != '\\x1b[33mhello\\x1b[0m'\n",
      "- \u001B[93mhello\u001B[0m\n",
      "?   ^\n",
      "+ \u001B[33mhello\u001B[0m\n",
      "?   ^\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 0.001s\n",
      "\n",
      "FAILED (failures=6)\n",
      "\n",
      "Process completed with return code: 1\n",
      "410\n",
      "\n",
      "....F\n",
      "======================================================================\n",
      "FAIL: test_multiple_rows (__main__.TestCheckXorSum)\n",
      "Test with a combination that contains multiple rows.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 56, in test_multiple_rows\n",
      "    self.assertTrue(check_xor_sum(combination))\n",
      "AssertionError: False is not true\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "FAILED (failures=1)\n",
      "\n",
      "Process completed with return code: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 134/215 [00:18<00:08, 10.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412\n",
      "413\n",
      "\n",
      "...F\n",
      "======================================================================\n",
      "FAIL: test_single_digit (__main__.TestNthPalindrome)\n",
      "Test case for the first palindrome\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 14, in test_single_digit\n",
      "    self.assertEqual(get_palindrome_list(1), [0], \"The first palindrome should be 0\")\n",
      "AssertionError: Lists differ: [0, 1] != [0]\n",
      "\n",
      "First list contains 1 additional elements.\n",
      "First extra element 1:\n",
      "1\n",
      "\n",
      "- [0, 1]\n",
      "+ [0] : The first palindrome should be 0\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.001s\n",
      "\n",
      "FAILED (failures=1)\n",
      "\n",
      "Process completed with return code: 1\n",
      "414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 136/215 [00:18<00:08,  9.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".EEEE\n",
      "======================================================================\n",
      "ERROR: test_incorrect_format (__main__.TestExtractBibInfo)\n",
      "Test extraction from a badly formatted BibTeX entry.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 72, in test_incorrect_format\n",
      "    result = extract_bib_info(\"dummy.bib\")\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 12, in extract_bib_info\n",
      "    author = re.search(r'author\\s*=\\s*{(.*?)}', entry).group(1)\n",
      "AttributeError: 'NoneType' object has no attribute 'group'\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_missing_fields (__main__.TestExtractBibInfo)\n",
      "Test extraction when some fields are missing.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 56, in test_missing_fields\n",
      "    result = extract_bib_info(\"dummy.bib\")\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 11, in extract_bib_info\n",
      "    title = re.search(r'title\\s*=\\s*{(.*?)}', entry).group(1)\n",
      "AttributeError: 'NoneType' object has no attribute 'group'\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_multiple_entries (__main__.TestExtractBibInfo)\n",
      "Test extraction from multiple BibTeX entries.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 45, in test_multiple_entries\n",
      "    result = extract_bib_info(\"dummy.bib\")\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 11, in extract_bib_info\n",
      "    title = re.search(r'title\\s*=\\s*{(.*?)}', entry).group(1)\n",
      "AttributeError: 'NoneType' object has no attribute 'group'\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_valid_entry (__main__.TestExtractBibInfo)\n",
      "Test extraction from a valid BibTeX entry.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 28, in test_valid_entry\n",
      "    result = extract_bib_info(\"dummy.bib\")\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 11, in extract_bib_info\n",
      "    title = re.search(r'title\\s*=\\s*{(.*?)}', entry).group(1)\n",
      "AttributeError: 'NoneType' object has no attribute 'group'\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.010s\n",
      "\n",
      "FAILED (errors=4)\n",
      "\n",
      "Process completed with return code: 1\n",
      "418\n",
      "\n",
      "...\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "420\n",
      "423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 138/215 [00:18<00:06, 11.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".F..\n",
      "======================================================================\n",
      "FAIL: test_write_empty_line (__main__.TestWriteUniqueLineToFile)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 66, in test_write_empty_line\n",
      "    self.assertEqual(file.read(), \"\")\n",
      "AssertionError: '\\n' != ''\n",
      "- \n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.013s\n",
      "\n",
      "FAILED (failures=1)\n",
      "\n",
      "Process completed with return code: 1\n",
      "424\n",
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 140/215 [00:18<00:07, 10.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "E\n",
      "======================================================================\n",
      "ERROR: test_sequences (__main__.TestCheckSequences)\n",
      "Test the sequences for Munodi property.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 47, in test_sequences\n",
      "    results = check_sequences(self.test_file)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 20, in check_sequences\n",
      "    seq = list(map(int, line.strip().split()))\n",
      "ValueError: invalid literal for int() with base 10: '2,4,6,8'\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.002s\n",
      "\n",
      "FAILED (errors=1)\n",
      "\n",
      "Process completed with return code: 1\n",
      "428\n",
      "\n",
      ".E.EE\n",
      "======================================================================\n",
      "ERROR: test_complex_type (__main__.TestParseTypeHint)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 57, in test_complex_type\n",
      "    self.assertEqual(parse_type_hint(type_hint), expected)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 25, in parse_type_hint\n",
      "    extract_types(node.body)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 11, in extract_types\n",
      "    parsed_types.append(n.slice.value.id)\n",
      "AttributeError: 'Tuple' object has no attribute 'id'\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_tuple_type (__main__.TestParseTypeHint)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 52, in test_tuple_type\n",
      "    self.assertEqual(parse_type_hint(type_hint), expected)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 25, in parse_type_hint\n",
      "    extract_types(node.body)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 11, in extract_types\n",
      "    parsed_types.append(n.slice.value.id)\n",
      "AttributeError: 'Tuple' object has no attribute 'id'\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_union_type (__main__.TestParseTypeHint)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 47, in test_union_type\n",
      "    self.assertEqual(parse_type_hint(type_hint), expected)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 25, in parse_type_hint\n",
      "    extract_types(node.body)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 11, in extract_types\n",
      "    parsed_types.append(n.slice.value.id)\n",
      "AttributeError: 'Tuple' object has no attribute 'id'\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.001s\n",
      "\n",
      "FAILED (errors=3)\n",
      "\n",
      "Process completed with return code: 1\n",
      "430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 142/215 [00:19<00:07, 10.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".F...\n",
      "======================================================================\n",
      "FAIL: test_case2 (__main__.TestIntersectVertically)\n",
      "Test with rectangles touching at a point (not overlapping).\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 32, in test_case2\n",
      "    self.assertTrue(intersect_vertically(rect1, rect2))\n",
      "AssertionError: False is not true\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "FAILED (failures=1)\n",
      "\n",
      "Process completed with return code: 1\n",
      "431\n",
      "\n",
      ".FF..\n",
      "======================================================================\n",
      "FAIL: test_case2 (__main__.TestIntersectHorizontally)\n",
      "Test with rectangles touching at a point (not overlapping).\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 37, in test_case2\n",
      "    self.assertTrue(intersect_horizontally(rect1, rect2))\n",
      "AssertionError: False is not true\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_case3 (__main__.TestIntersectHorizontally)\n",
      "Test with adjacent rectangles (no overlap).\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 43, in test_case3\n",
      "    self.assertTrue(intersect_horizontally(rect1, rect2))\n",
      "AssertionError: False is not true\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "FAILED (failures=2)\n",
      "\n",
      "Process completed with return code: 1\n",
      "433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 144/215 [00:19<00:07,  9.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "434\n",
      "\n",
      "F....\n",
      "======================================================================\n",
      "FAIL: test_case_1 (__main__.TestGetMaxPeople)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 31, in test_case_1\n",
      "    self.assertEqual(get_max_people(people, status), expected)\n",
      "AssertionError: 2 != 1\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "FAILED (failures=1)\n",
      "\n",
      "Process completed with return code: 1\n",
      "438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 147/215 [00:19<00:09,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".EE.\n",
      "======================================================================\n",
      "ERROR: test_read_empty_csv (__main__.TestReadCsvToDataFrame)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 62, in test_read_empty_csv\n",
      "    df = read_csv_to_dataframe(self.test_files['empty_csv'])\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 13, in read_csv_to_dataframe\n",
      "    return pd.read_csv(file_path)\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 912, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 577, in _read\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 1407, in __init__\n",
      "    self._engine = self._make_engine(f, self.engine)\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 1679, in _make_engine\n",
      "    return mapping[engine](f, **self.options)\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\", line 93, in __init__\n",
      "    self._reader = parsers.TextReader(src, **kwds)\n",
      "  File \"pandas\\_libs\\parsers.pyx\", line 557, in pandas._libs.parsers.TextReader.__cinit__\n",
      "pandas.errors.EmptyDataError: No columns to parse from file\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_read_non_existent_csv (__main__.TestReadCsvToDataFrame)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 66, in test_read_non_existent_csv\n",
      "    df = read_csv_to_dataframe(self.test_files['non_existent_csv'])\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 13, in read_csv_to_dataframe\n",
      "    return pd.read_csv(file_path)\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 912, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 577, in _read\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 1407, in __init__\n",
      "    self._engine = self._make_engine(f, self.engine)\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 1661, in _make_engine\n",
      "    self.handles = get_handle(\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\pandas\\io\\common.py\", line 859, in get_handle\n",
      "    handle = open(\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'non_existent.csv'\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.008s\n",
      "\n",
      "FAILED (errors=2)\n",
      "\n",
      "Process completed with return code: 1\n",
      "442\n",
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 149/215 [00:20<00:09,  7.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "444\n",
      "\n",
      ".F.F.\n",
      "======================================================================\n",
      "FAIL: test_exact_max_length (__main__.TestFormatComment)\n",
      "Test with a line that is exactly max_length characters long\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 60, in test_exact_max_length\n",
      "    self.assertEqual(format_comment(input_string, max_length=60), expected_output)\n",
      "AssertionError: '# \\n# AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA' != '# AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA'\n",
      "- # \n",
      "  # AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_multiple_lines (__main__.TestFormatComment)\n",
      "Test with multiple lines of input\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 54, in test_multiple_lines\n",
      "    self.assertEqual(format_comment(input_string, max_length=60), expected_output)\n",
      "AssertionError: '# First line. Second line that is quite long and needs to be\\n# wrapped.' != '# First line.\\n# Second line that is quite long and needs to be wrapped.'\n",
      "+ # First line.\n",
      "- # First line. Second line that is quite long and needs to be\n",
      "?  ------------                                               ^\n",
      "+ # Second line that is quite long and needs to be wrapped.?                                                 ^^^^^^^^^\n",
      "- # wrapped.\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.001s\n",
      "\n",
      "FAILED (failures=2)\n",
      "\n",
      "Process completed with return code: 1\n",
      "445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 150/215 [00:20<00:10,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.001s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 152/215 [00:20<00:10,  6.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.028s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "460\n",
      "\n",
      "F...\n",
      "======================================================================\n",
      "FAIL: test_invalid_dimensions (__main__.TestMatrixVectorMultiplication)\n",
      "Test case for incompatible dimensions.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 25, in test_invalid_dimensions\n",
      "    self.assertEqual(str(context.exception), \"Matrix and vector dimensions are not compatible for multiplication\")\n",
      "AssertionError: 'Matrix and vector dimensions are not compatible for multiplication.' != 'Matrix and vector dimensions are not compatible for multiplication'\n",
      "- Matrix and vector dimensions are not compatible for multiplication.\n",
      "?                                                                   -\n",
      "+ Matrix and vector dimensions are not compatible for multiplication\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.001s\n",
      "\n",
      "FAILED (failures=1)\n",
      "\n",
      "Process completed with return code: 1\n",
      "461\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 1, in <module>\n",
      "    def average_of_levels(root: Optional[TreeNode]) -> List[float]:\n",
      "NameError: name 'Optional' is not defined\n",
      "\n",
      "Process completed with return code: 1\n",
      "462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 155/215 [00:21<00:07,  7.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "463\n",
      "\n",
      "E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py:86: ResourceWarning: unclosed file <_io.BufferedRandom name=3>\n",
      "  output_file_path = tempfile.NamedTemporaryFile(delete=False).name\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      ".E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py:69: ResourceWarning: unclosed file <_io.BufferedRandom name=3>\n",
      "  output_file_path = tempfile.NamedTemporaryFile(delete=False).name\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      ".E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py:120: ResourceWarning: unclosed file <_io.BufferedRandom name=3>\n",
      "  output_file_path = tempfile.NamedTemporaryFile(delete=False).name\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      ".E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py:101: ResourceWarning: unclosed file <_io.BufferedRandom name=3>\n",
      "  output_file_path = tempfile.NamedTemporaryFile(delete=False).name\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      ".E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py:53: ResourceWarning: unclosed file <_io.BufferedRandom name=3>\n",
      "  output_file_path = tempfile.NamedTemporaryFile(delete=False).name\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.021s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 156/215 [00:21<00:08,  7.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.005s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "468\n",
      "\n",
      ".EE..\n",
      "======================================================================\n",
      "ERROR: test_invalid_matrix_shape (__main__.TestGetTranslationFunction)\n",
      "Test for an invalid matrix input (not 3x3)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 51, in test_invalid_matrix_shape\n",
      "    get_translation(invalid_matrix)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 13, in get_translation\n",
      "    return matrix[0:2, 2]\n",
      "IndexError: index 2 is out of bounds for axis 1 with size 2\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_invalid_matrix_type (__main__.TestGetTranslationFunction)\n",
      "Test for an invalid input type (not a numpy array)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 59, in test_invalid_matrix_type\n",
      "    get_translation(invalid_matrix)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 13, in get_translation\n",
      "    return matrix[0:2, 2]\n",
      "TypeError: list indices must be integers or slices, not tuple\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.006s\n",
      "\n",
      "FAILED (errors=2)\n",
      "\n",
      "Process completed with return code: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 158/215 [00:21<00:08,  6.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 3, in <module>\n",
      "    def get_scale(matrix: np.ndarray) -> tuple[np.float64, np.float64]:\n",
      "TypeError: 'type' object is not subscriptable\n",
      "\n",
      "Process completed with return code: 1\n",
      "470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 160/215 [00:21<00:09,  6.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F.FF\n",
      "======================================================================\n",
      "FAIL: test_high_shear_factor (__main__.TestShearTransformation)\n",
      "Test with a high shear factor to see how the matrix adapts to extreme transformations.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 41, in test_high_shear_factor\n",
      "    np.testing.assert_array_equal(result, expected_output, \"The matrix should be correctly sheared with a high shear factor.\")\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\numpy\\testing\\_private\\utils.py\", line 985, in assert_array_equal\n",
      "    assert_array_compare(operator.__eq__, x, y, err_msg=err_msg,\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\contextlib.py\", line 75, in inner\n",
      "    return func(*args, **kwds)\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\numpy\\testing\\_private\\utils.py\", line 862, in assert_array_compare\n",
      "    raise AssertionError(msg)\n",
      "AssertionError: \n",
      "Arrays are not equal\n",
      "The matrix should be correctly sheared with a high shear factor.\n",
      "Mismatched elements: 2 / 4 (50%)\n",
      "Max absolute difference: 10\n",
      "Max relative difference: 10.\n",
      " x: array([[11, 11],\n",
      "       [ 1,  1]])\n",
      " y: array([[ 1, 11],\n",
      "       [ 1, 11]])\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_negative_shear (__main__.TestShearTransformation)\n",
      "Test with a negative shear factor.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 32, in test_negative_shear\n",
      "    np.testing.assert_array_equal(result, expected_output, \"The matrix should be correctly sheared negatively.\")\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\numpy\\testing\\_private\\utils.py\", line 985, in assert_array_equal\n",
      "    assert_array_compare(operator.__eq__, x, y, err_msg=err_msg,\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\contextlib.py\", line 75, in inner\n",
      "    return func(*args, **kwds)\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\numpy\\testing\\_private\\utils.py\", line 862, in assert_array_compare\n",
      "    raise AssertionError(msg)\n",
      "AssertionError: \n",
      "Arrays are not equal\n",
      "The matrix should be correctly sheared negatively.\n",
      "Mismatched elements: 3 / 4 (75%)\n",
      "Max absolute difference: 3\n",
      "Max relative difference: 3.\n",
      " x: array([[-2, -2],\n",
      "       [ 3,  4]])\n",
      " y: array([[1, 1],\n",
      "       [3, 1]])\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_positive_shear (__main__.TestShearTransformation)\n",
      "Test with a positive shear factor.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 24, in test_positive_shear\n",
      "    np.testing.assert_array_equal(result, expected_output, \"The matrix should be correctly sheared.\")\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\numpy\\testing\\_private\\utils.py\", line 985, in assert_array_equal\n",
      "    assert_array_compare(operator.__eq__, x, y, err_msg=err_msg,\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\contextlib.py\", line 75, in inner\n",
      "    return func(*args, **kwds)\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\numpy\\testing\\_private\\utils.py\", line 862, in assert_array_compare\n",
      "    raise AssertionError(msg)\n",
      "AssertionError: \n",
      "Arrays are not equal\n",
      "The matrix should be correctly sheared.\n",
      "Mismatched elements: 3 / 4 (75%)\n",
      "Max absolute difference: 3\n",
      "Max relative difference: 3.\n",
      " x: array([[4, 6],\n",
      "       [3, 4]])\n",
      " y: array([[1, 3],\n",
      "       [3, 7]])\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.007s\n",
      "\n",
      "FAILED (failures=3)\n",
      "\n",
      "Process completed with return code: 1\n",
      "471\n",
      "\n",
      "..F.F\n",
      "======================================================================\n",
      "FAIL: test_rotation_90_degrees (__main__.TestGetRotationFunction)\n",
      "Test for a rotation of 90 degrees\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 45, in test_rotation_90_degrees\n",
      "    self.assertAlmostEqual(get_rotation(matrix), expected_rotation, places=6)\n",
      "AssertionError: -1.5707963267948966 != 1.5707963267948966 within 6 places (3.141592653589793 difference)\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_rotation_negative_90_degrees (__main__.TestGetRotationFunction)\n",
      "Test for a rotation of -90 degrees\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 61, in test_rotation_negative_90_degrees\n",
      "    self.assertAlmostEqual(get_rotation(matrix), expected_rotation, places=6)\n",
      "AssertionError: 1.5707963267948966 != -1.5707963267948966 within 6 places (3.141592653589793 difference)\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "FAILED (failures=2)\n",
      "\n",
      "Process completed with return code: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 162/215 [00:22<00:07,  7.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "473\n",
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "474\n",
      "\n",
      "....F\n",
      "======================================================================\n",
      "FAIL: test_same_node_case (__main__.TestAreSiblings)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 44, in test_same_node_case\n",
      "    self.assertFalse(result)\n",
      "AssertionError: True is not false\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.001s\n",
      "\n",
      "FAILED (failures=1)\n",
      "\n",
      "Process completed with return code: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 163/215 [00:22<00:06,  7.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "475\n",
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 165/215 [00:22<00:05,  8.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "477\n",
      "\n",
      "......\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "478\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 3, in <module>\n",
      "    def class_to_dict(obj: Any) -> Dict[str, Any]:\n",
      "NameError: name 'Any' is not defined\n",
      "\n",
      "Process completed with return code: 1\n",
      "482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 168/215 [00:22<00:04,  9.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FF.F.\n",
      "======================================================================\n",
      "FAIL: test_mixed_bracket_types (__main__.TestExtractOutermostBrackets)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 30, in test_mixed_bracket_types\n",
      "    self.assertEqual(extract_outermost_brackets(\"Mixed (types {of brackets [in use]})\"), \"types {of brackets [in use]}\")\n",
      "AssertionError: 'in use' != 'types {of brackets [in use]}'\n",
      "- in use\n",
      "+ types {of brackets [in use]}\n",
      "\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_nested_brackets (__main__.TestExtractOutermostBrackets)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 24, in test_nested_brackets\n",
      "    self.assertEqual(extract_outermost_brackets(\"Text {with some {nested} brackets}\"), \"with some {nested} brackets\")\n",
      "AssertionError: '' != 'with some {nested} brackets'\n",
      "+ with some {nested} brackets\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_single_parentheses (__main__.TestExtractOutermostBrackets)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 21, in test_single_parentheses\n",
      "    self.assertEqual(extract_outermost_brackets(\"Text (example) more text\"), \"example\")\n",
      "AssertionError: '' != 'example'\n",
      "+ example\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "FAILED (failures=3)\n",
      "\n",
      "Process completed with return code: 1\n",
      "483\n",
      "\n",
      ".......\n",
      "----------------------------------------------------------------------\n",
      "Ran 7 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 170/215 [00:22<00:05,  8.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FF...\n",
      "======================================================================\n",
      "FAIL: test_missing_parameters (__main__.TestPrepareQuery)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 44, in test_missing_parameters\n",
      "    self.assertEqual(new_sql, expected_sql)\n",
      "AssertionError: 'SELECT * FROM users WHERE id = $1 AND status = $status' != 'SELECT * FROM users WHERE id = $1 AND status = $2'\n",
      "- SELECT * FROM users WHERE id = $1 AND status = $status\n",
      "?                                                 ^^^^^^\n",
      "+ SELECT * FROM users WHERE id = $1 AND status = $2\n",
      "?                                                 ^\n",
      "\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_multiple_same_parameters (__main__.TestPrepareQuery)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 66, in test_multiple_same_parameters\n",
      "    self.assertEqual(new_sql, expected_sql)\n",
      "AssertionError: 'SELECT * FROM users WHERE id = $1 AND status = $2' != 'SELECT * FROM users WHERE id = $1 AND status = $1'\n",
      "- SELECT * FROM users WHERE id = $1 AND status = $2\n",
      "?                                                 ^\n",
      "+ SELECT * FROM users WHERE id = $1 AND status = $1\n",
      "?                                                 ^\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.001s\n",
      "\n",
      "FAILED (failures=2)\n",
      "\n",
      "Process completed with return code: 1\n",
      "486\n",
      "\n",
      "..F..\n",
      "======================================================================\n",
      "FAIL: test_divide_by_zero (__main__.TestCalculator)\n",
      "Test division by zero raises ValueError.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 48, in test_divide_by_zero\n",
      "    self.assertEqual(str(context.exception), \"Cannot divide by zero.\")\n",
      "AssertionError: 'Division by zero is not allowed.' != 'Cannot divide by zero.'\n",
      "- Division by zero is not allowed.\n",
      "+ Cannot divide by zero.\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "FAILED (failures=1)\n",
      "\n",
      "Process completed with return code: 1\n",
      "487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 172/215 [00:23<00:05,  7.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "488\n",
      "\n",
      ".EEEE\n",
      "======================================================================\n",
      "ERROR: test_local_ip_found (__main__.TestGetLocalIP)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 1342, in patched\n",
      "    return func(*newargs, **newkeywargs)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 31, in test_local_ip_found\n",
      "    result = get_local_ip()\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 9, in get_local_ip\n",
      "    matches = re.findall(pattern, output, re.MULTILINE)\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\re.py\", line 239, in findall\n",
      "    return _compile(pattern, flags).findall(string)\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\re.py\", line 302, in _compile\n",
      "    p = sre_compile.compile(pattern, flags)\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\sre_compile.py\", line 768, in compile\n",
      "    code = _code(p, flags)\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\sre_compile.py\", line 607, in _code\n",
      "    _compile(code, p.data, flags)\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\sre_compile.py\", line 182, in _compile\n",
      "    raise error(\"look-behind requires fixed-width pattern\")\n",
      "re.error: look-behind requires fixed-width pattern\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_multiple_ips_found (__main__.TestGetLocalIP)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 1342, in patched\n",
      "    return func(*newargs, **newkeywargs)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 46, in test_multiple_ips_found\n",
      "    result = get_local_ip()\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 9, in get_local_ip\n",
      "    matches = re.findall(pattern, output, re.MULTILINE)\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\re.py\", line 239, in findall\n",
      "    return _compile(pattern, flags).findall(string)\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\re.py\", line 302, in _compile\n",
      "    p = sre_compile.compile(pattern, flags)\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\sre_compile.py\", line 768, in compile\n",
      "    code = _code(p, flags)\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\sre_compile.py\", line 607, in _code\n",
      "    _compile(code, p.data, flags)\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\sre_compile.py\", line 182, in _compile\n",
      "    raise error(\"look-behind requires fixed-width pattern\")\n",
      "re.error: look-behind requires fixed-width pattern\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_no_local_ip_found (__main__.TestGetLocalIP)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 1342, in patched\n",
      "    return func(*newargs, **newkeywargs)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 38, in test_no_local_ip_found\n",
      "    result = get_local_ip()\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 9, in get_local_ip\n",
      "    matches = re.findall(pattern, output, re.MULTILINE)\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\re.py\", line 239, in findall\n",
      "    return _compile(pattern, flags).findall(string)\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\re.py\", line 302, in _compile\n",
      "    p = sre_compile.compile(pattern, flags)\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\sre_compile.py\", line 768, in compile\n",
      "    code = _code(p, flags)\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\sre_compile.py\", line 607, in _code\n",
      "    _compile(code, p.data, flags)\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\sre_compile.py\", line 182, in _compile\n",
      "    raise error(\"look-behind requires fixed-width pattern\")\n",
      "re.error: look-behind requires fixed-width pattern\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_unexpected_error (__main__.TestGetLocalIP)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 1342, in patched\n",
      "    return func(*newargs, **newkeywargs)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 60, in test_unexpected_error\n",
      "    result = get_local_ip()\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 7, in get_local_ip\n",
      "    output = subprocess.check_output(['ipconfig'], text=True)\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\subprocess.py\", line 411, in check_output\n",
      "    return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 1075, in __call__\n",
      "    return self._mock_call(*args, **kwargs)\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 1079, in _mock_call\n",
      "    return self._execute_mock_call(*args, **kwargs)\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 1134, in _execute_mock_call\n",
      "    raise effect\n",
      "Exception: Unexpected error\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.003s\n",
      "\n",
      "FAILED (errors=4)\n",
      "\n",
      "Process completed with return code: 1\n",
      "490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 174/215 [00:23<00:04,  9.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 21\n",
      "    open_count = sum(line.count('\n",
      "                                ^\n",
      "SyntaxError: EOL while scanning string literal\n",
      "\n",
      "Process completed with return code: 1\n",
      "492\n",
      "\n",
      ".E...\n",
      "======================================================================\n",
      "ERROR: test_content_with_special_characters (__main__.TestSaveContentToFile)\n",
      "Test if content with special characters is handled correctly.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 76, in test_content_with_special_characters\n",
      "    save_content_to_file(content, self.test_file_path)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 15, in save_content_to_file\n",
      "    file.write(cleaned_content)\n",
      "UnicodeEncodeError: 'gbk' codec can't encode character '\\U0001f60a' in position 16: illegal multibyte sequence\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.010s\n",
      "\n",
      "FAILED (errors=1)\n",
      "\n",
      "Process completed with return code: 1\n",
      "493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 176/215 [00:23<00:04,  7.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "...FF.\n",
      "======================================================================\n",
      "FAIL: test_multi_line_content (__main__.TestWrapContentGenerator)\n",
      "Test with multiple lines of content each fitting within default width.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 35, in test_multi_line_content\n",
      "    self.assertEqual(result, [\"Hello\", \"World\", \"Python\"])\n",
      "AssertionError: Lists differ: ['Hello World Python'] != ['Hello', 'World', 'Python']\n",
      "\n",
      "First differing element 0:\n",
      "'Hello World Python'\n",
      "'Hello'\n",
      "\n",
      "Second list contains 2 additional elements.\n",
      "First extra element 1:\n",
      "'World'\n",
      "\n",
      "- ['Hello World Python']\n",
      "?        ^     ^\n",
      "\n",
      "+ ['Hello', 'World', 'Python']\n",
      "?        ^^^^     ^^^^\n",
      "\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_only_whitespaces (__main__.TestWrapContentGenerator)\n",
      "Test content that contains only whitespace characters.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 52, in test_only_whitespaces\n",
      "    self.assertEqual(result, [\"\\n\"])\n",
      "AssertionError: Lists differ: [] != ['\\n']\n",
      "\n",
      "Second list contains 1 additional elements.\n",
      "First extra element 0:\n",
      "'\\n'\n",
      "\n",
      "- []\n",
      "+ ['\\n']\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 0.001s\n",
      "\n",
      "FAILED (failures=2)\n",
      "\n",
      "Process completed with return code: 1\n",
      "494\n",
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 178/215 [00:23<00:04,  8.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".F..\n",
      "======================================================================\n",
      "FAIL: test_multiple_keywords (__main__.TestFilterContentWithContext)\n",
      "Test multiple keywords with overlapping context.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 50, in test_multiple_keywords\n",
      "    self.assertEqual(result.strip(), expected_output.strip(), \"Failed to filter content for multiple keywords.\")\n",
      "AssertionError: 'Line[83 chars]     This line contains a keyword.\\n        An[38 chars]our.' != 'Line[83 chars]     Line four.'\n",
      "  Line one.\n",
      "          This line contains a keyword.\n",
      "          Another keyword is here.\n",
      "-         This line contains a keyword.\n",
      "-         Another keyword is here.\n",
      "          Line four. : Failed to filter content for multiple keywords.\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.001s\n",
      "\n",
      "FAILED (failures=1)\n",
      "\n",
      "Process completed with return code: 1\n",
      "496\n",
      "\n",
      "......\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▎ | 180/215 [00:24<00:03,  8.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EEEEE\n",
      "======================================================================\n",
      "ERROR: test_bigger_shape (__main__.TestBroadcastIndex)\n",
      "Test case where the big_shape is larger than the shape.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 91, in test_bigger_shape\n",
      "    broadcast_index(big_index, big_shape, shape, out_index_big)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 50, in broadcast_index\n",
      "    raise ValueError(\"Invalid broadcasting due to non-unit dimension.\")\n",
      "ValueError: Invalid broadcasting due to non-unit dimension.\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_empty_shape (__main__.TestBroadcastIndex)\n",
      "Test case with an empty shape.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 82, in test_empty_shape\n",
      "    broadcast_index(self.big_index, self.big_shape, empty_shape, out_index_empty)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 50, in broadcast_index\n",
      "    raise ValueError(\"Invalid broadcasting due to non-unit dimension.\")\n",
      "ValueError: Invalid broadcasting due to non-unit dimension.\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_shape_with_multiple_ones (__main__.TestBroadcastIndex)\n",
      "Test case with multiple dimensions of size 1 in shape.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 98, in test_shape_with_multiple_ones\n",
      "    broadcast_index(self.big_index, self.big_shape, shape_multiple_ones, out_index_multiple_ones)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 45, in broadcast_index\n",
      "    raise ValueError(\"Invalid broadcasting from big_shape to shape.\")\n",
      "ValueError: Invalid broadcasting from big_shape to shape.\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_shape_with_one_dimension (__main__.TestBroadcastIndex)\n",
      "Test case where shape contains a dimension of size 1.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 75, in test_shape_with_one_dimension\n",
      "    broadcast_index(self.big_index, self.big_shape, shape_with_one, out_index_with_one)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 45, in broadcast_index\n",
      "    raise ValueError(\"Invalid broadcasting from big_shape to shape.\")\n",
      "ValueError: Invalid broadcasting from big_shape to shape.\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_standard_case (__main__.TestBroadcastIndex)\n",
      "Test standard broadcasting behavior.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 68, in test_standard_case\n",
      "    broadcast_index(self.big_index, self.big_shape, self.shape, self.out_index)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 50, in broadcast_index\n",
      "    raise ValueError(\"Invalid broadcasting due to non-unit dimension.\")\n",
      "ValueError: Invalid broadcasting due to non-unit dimension.\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "FAILED (errors=5)\n",
      "\n",
      "Process completed with return code: 1\n",
      "498\n",
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 182/215 [00:24<00:03,  8.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "..FFF\n",
      "======================================================================\n",
      "FAIL: test_valid_float_weight (__main__.TestCleanPattern)\n",
      "Test case for valid float weight.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 29, in test_valid_float_weight\n",
      "    self.assertEqual(result, 15.75)\n",
      "AssertionError: '15.75 kg' != 15.75\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_valid_integer_weight (__main__.TestCleanPattern)\n",
      "Test case for valid integer weight.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 23, in test_valid_integer_weight\n",
      "    self.assertEqual(result, 25.0)\n",
      "AssertionError: '25 kg' != 25.0\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_weight_with_extra_text (__main__.TestCleanPattern)\n",
      "Test case for weight with additional text.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 47, in test_weight_with_extra_text\n",
      "    self.assertEqual(result, 45.3)\n",
      "AssertionError: '45.3 kg' != 45.3\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.001s\n",
      "\n",
      "FAILED (failures=3)\n",
      "\n",
      "Process completed with return code: 1\n",
      "500\n",
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 184/215 [00:24<00:03,  9.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "505\n",
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 186/215 [00:24<00:03,  9.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "507\n",
      "\n",
      "......\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 188/215 [00:25<00:03,  8.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "510\n",
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 190/215 [00:25<00:02,  9.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "..\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "512\n",
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 192/215 [00:25<00:02,  9.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "514\n",
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 194/215 [00:25<00:02,  8.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.002s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "516\n",
      "\n",
      "...\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.006s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 196/215 [00:25<00:02,  8.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "...\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.003s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "518\n",
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 198/215 [00:26<00:01,  8.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "520\n",
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 199/215 [00:26<00:01,  8.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FFF.\n",
      "======================================================================\n",
      "FAIL: test_basic_functionality (__main__.TestWordFilterCounter)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 28, in test_basic_functionality\n",
      "    self.assertEqual(word_filter_counter(text, filter_words), expected_output)\n",
      "AssertionError: {\"I'll\": 0, 'go': 2, 'to': 2, 'the': 2, 'school': 1, 'park': 1, 'play': 0} != {\"I'll\": 2, 'go': 2, 'to': 2, 'the': 2, 'school': 1, 'park': 1, 'play': 0}\n",
      "- {\"I'll\": 0, 'go': 2, 'park': 1, 'play': 0, 'school': 1, 'the': 2, 'to': 2}\n",
      "?          ^\n",
      "\n",
      "+ {\"I'll\": 2, 'go': 2, 'park': 1, 'play': 0, 'school': 1, 'the': 2, 'to': 2}\n",
      "?          ^\n",
      "\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_case_insensitivity (__main__.TestWordFilterCounter)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 42, in test_case_insensitivity\n",
      "    self.assertEqual(word_filter_counter(text, filter_words), expected_output)\n",
      "AssertionError: {\"I'll\": 0, 'go': 2, 'to': 2, 'the': 2, 'school': 1, 'park': 1, 'play': 0} != {\"I'll\": 2, 'go': 2, 'to': 2, 'the': 2, 'school': 1, 'park': 1, 'play': 0}\n",
      "- {\"I'll\": 0, 'go': 2, 'park': 1, 'play': 0, 'school': 1, 'the': 2, 'to': 2}\n",
      "?          ^\n",
      "\n",
      "+ {\"I'll\": 2, 'go': 2, 'park': 1, 'play': 0, 'school': 1, 'the': 2, 'to': 2}\n",
      "?          ^\n",
      "\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_filter_words_with_special_characters (__main__.TestWordFilterCounter)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 71, in test_filter_words_with_special_characters\n",
      "    self.assertEqual(word_filter_counter(text, filter_words), expected_output)\n",
      "AssertionError: {\"I'll\": 0, 'go': 1, 'to': 1, 'the': 1, \"school's\": 0, 'park': 1, 'play': 0} != {\"I'll\": 0, 'go': 1, 'to': 1, 'the': 1, \"school's\": 1, 'park': 1, 'play': 0}\n",
      "- {\"I'll\": 0, 'go': 1, 'park': 1, 'play': 0, \"school's\": 0, 'the': 1, 'to': 1}\n",
      "?                                                        ^\n",
      "\n",
      "+ {\"I'll\": 0, 'go': 1, 'park': 1, 'play': 0, \"school's\": 1, 'the': 1, 'to': 1}\n",
      "?                                                        ^\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.001s\n",
      "\n",
      "FAILED (failures=3)\n",
      "\n",
      "Process completed with return code: 1\n",
      "522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 201/215 [00:26<00:02,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "..F.\n",
      "======================================================================\n",
      "FAIL: test_negative_rotation (__main__.TestRotatePointCloud)\n",
      "Test rotation with a negative angle (-90 degrees).\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 58, in test_negative_rotation\n",
      "    np.testing.assert_array_almost_equal(rotate_point_cloud(point_cloud, rotation_angle), expected_output)\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\contextlib.py\", line 75, in inner\n",
      "    return func(*args, **kwds)\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\numpy\\testing\\_private\\utils.py\", line 1099, in assert_array_almost_equal\n",
      "    assert_array_compare(compare, x, y, err_msg=err_msg, verbose=verbose,\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\contextlib.py\", line 75, in inner\n",
      "    return func(*args, **kwds)\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\numpy\\testing\\_private\\utils.py\", line 862, in assert_array_compare\n",
      "    raise AssertionError(msg)\n",
      "AssertionError: \n",
      "Arrays are not almost equal to 6 decimals\n",
      "\n",
      "Mismatched elements: 1 / 3 (33.3%)\n",
      "Max absolute difference: 2.\n",
      "Max relative difference: 2.\n",
      " x: array([[6.123234e-17, 0.000000e+00, 1.000000e+00]])\n",
      " y: array([[ 0.,  0., -1.]])\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.007s\n",
      "\n",
      "FAILED (failures=1)\n",
      "\n",
      "Process completed with return code: 1\n",
      "523\n",
      "\n",
      "F....\n",
      "======================================================================\n",
      "FAIL: test_invalid_translation_vector (__main__.TestTranslatePointCloud)\n",
      "Test handling of an invalid translation vector shape.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 56, in test_invalid_translation_vector\n",
      "    self.assertEqual(str(context.exception), \"translation_vector must be a 1D array of shape (3,)\")\n",
      "AssertionError: 'operands could not be broadcast together with shapes (1,3) (2,) ' != 'translation_vector must be a 1D array of shape (3,)'\n",
      "- operands could not be broadcast together with shapes (1,3) (2,) \n",
      "+ translation_vector must be a 1D array of shape (3,)\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.006s\n",
      "\n",
      "FAILED (failures=1)\n",
      "\n",
      "Process completed with return code: 1\n",
      "524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 202/215 [00:26<00:02,  6.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F....\n",
      "======================================================================\n",
      "FAIL: test_invalid_point_cloud_shape (__main__.TestScalePointCloud)\n",
      "Test handling of an invalid point cloud shape.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 55, in test_invalid_point_cloud_shape\n",
      "    scale_point_cloud(point_cloud, scale_factor)\n",
      "AssertionError: ValueError not raised\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.006s\n",
      "\n",
      "FAILED (failures=1)\n",
      "\n",
      "Process completed with return code: 1\n",
      "525\n",
      "\n",
      "....E\n",
      "======================================================================\n",
      "ERROR: test_invalid_axis (__main__.TestFlipPointCloud)\n",
      "Test handling of an invalid axis.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 46, in test_invalid_axis\n",
      "    flip_point_cloud(point_cloud, axis=3)  # Invalid axis\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 15, in flip_point_cloud\n",
      "    point_cloud_flipped[:, axis] *= -1\n",
      "IndexError: index 3 is out of bounds for axis 1 with size 3\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.005s\n",
      "\n",
      "FAILED (errors=1)\n",
      "\n",
      "Process completed with return code: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 204/215 [00:27<00:01,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "526\n",
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 206/215 [00:27<00:01,  7.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "546\n",
      "\n",
      "...\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 208/215 [00:27<00:00,  8.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".F.....\n",
      "======================================================================\n",
      "FAIL: test_empty_list (__main__.TestCalculateColumnWidths)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 22, in test_empty_list\n",
      "    calculate_column_widths(data)\n",
      "AssertionError: IndexError not raised\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 7 tests in 0.000s\n",
      "\n",
      "FAILED (failures=1)\n",
      "\n",
      "Process completed with return code: 1\n",
      "548\n",
      "\n",
      ".EE.\n",
      "======================================================================\n",
      "ERROR: test_file_not_found (__main__.TestReadTxtAddJsonBracket)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 58, in test_file_not_found\n",
      "    result = read_txt_add_json_bracket('non_existent_file.txt')\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 17, in read_txt_add_json_bracket\n",
      "    with open(filename, 'r') as file:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'non_existent_file.txt'\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_invalid_json_file (__main__.TestReadTxtAddJsonBracket)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 50, in test_invalid_json_file\n",
      "    result = read_txt_add_json_bracket(self.invalid_file)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 20, in read_txt_add_json_bracket\n",
      "    return json.loads(json_content)\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\json\\__init__.py\", line 357, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\json\\decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\json\\decoder.py\", line 353, in raw_decode\n",
      "    obj, end = self.scan_once(s, idx)\n",
      "json.decoder.JSONDecodeError: Expecting ',' delimiter: line 2 column 1 (char 18)\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.012s\n",
      "\n",
      "FAILED (errors=2)\n",
      "\n",
      "Process completed with return code: 1\n",
      "549\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 1, in <module>\n",
      "    def get_T_in_log10_Kelvin(T_keV: Union[float, Tuple]):\n",
      "NameError: name 'Union' is not defined\n",
      "\n",
      "Process completed with return code: 1\n",
      "550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 211/215 [00:27<00:00,  7.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".......\n",
      "----------------------------------------------------------------------\n",
      "Ran 7 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "551\n",
      "\n",
      ".......\n",
      "----------------------------------------------------------------------\n",
      "Ran 7 tests in 0.005s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 213/215 [00:28<00:00,  7.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EEEEEE\n",
      "======================================================================\n",
      "ERROR: test_different_length_sets (__main__.TestAreSetsEqual)\n",
      "Test with two sets of different lengths.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 23, in test_different_length_sets\n",
      "    self.assertFalse(are_sets_equal(set1, set2))\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 7, in are_sets_equal\n",
      "    return np.allclose(set1, set2, rtol=rtol, atol=atol)\n",
      "  File \"<__array_function__ internals>\", line 200, in allclose\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\numpy\\core\\numeric.py\", line 2270, in allclose\n",
      "    res = all(isclose(a, b, rtol=rtol, atol=atol, equal_nan=equal_nan))\n",
      "  File \"<__array_function__ internals>\", line 200, in isclose\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\numpy\\core\\numeric.py\", line 2377, in isclose\n",
      "    xfin = isfinite(x)\n",
      "TypeError: ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_empty_sets (__main__.TestAreSetsEqual)\n",
      "Test with two empty sets.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 47, in test_empty_sets\n",
      "    self.assertTrue(are_sets_equal(set1, set2))\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 7, in are_sets_equal\n",
      "    return np.allclose(set1, set2, rtol=rtol, atol=atol)\n",
      "  File \"<__array_function__ internals>\", line 200, in allclose\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\numpy\\core\\numeric.py\", line 2270, in allclose\n",
      "    res = all(isclose(a, b, rtol=rtol, atol=atol, equal_nan=equal_nan))\n",
      "  File \"<__array_function__ internals>\", line 200, in isclose\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\numpy\\core\\numeric.py\", line 2377, in isclose\n",
      "    xfin = isfinite(x)\n",
      "TypeError: ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_identical_sets (__main__.TestAreSetsEqual)\n",
      "Test with two identical sets of floats.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 17, in test_identical_sets\n",
      "    self.assertTrue(are_sets_equal(set1, set2))\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 7, in are_sets_equal\n",
      "    return np.allclose(set1, set2, rtol=rtol, atol=atol)\n",
      "  File \"<__array_function__ internals>\", line 200, in allclose\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\numpy\\core\\numeric.py\", line 2270, in allclose\n",
      "    res = all(isclose(a, b, rtol=rtol, atol=atol, equal_nan=equal_nan))\n",
      "  File \"<__array_function__ internals>\", line 200, in isclose\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\numpy\\core\\numeric.py\", line 2377, in isclose\n",
      "    xfin = isfinite(x)\n",
      "TypeError: ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_sets_with_close_values (__main__.TestAreSetsEqual)\n",
      "Test with two sets that are close within the tolerance.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 29, in test_sets_with_close_values\n",
      "    self.assertTrue(are_sets_equal(set1, set2, rtol=1e-5, atol=1e-6))\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 7, in are_sets_equal\n",
      "    return np.allclose(set1, set2, rtol=rtol, atol=atol)\n",
      "  File \"<__array_function__ internals>\", line 200, in allclose\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\numpy\\core\\numeric.py\", line 2270, in allclose\n",
      "    res = all(isclose(a, b, rtol=rtol, atol=atol, equal_nan=equal_nan))\n",
      "  File \"<__array_function__ internals>\", line 200, in isclose\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\numpy\\core\\numeric.py\", line 2377, in isclose\n",
      "    xfin = isfinite(x)\n",
      "TypeError: ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_sets_with_large_difference (__main__.TestAreSetsEqual)\n",
      "Test with two sets that have large differences beyond tolerance.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 35, in test_sets_with_large_difference\n",
      "    self.assertFalse(are_sets_equal(set1, set2))\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 7, in are_sets_equal\n",
      "    return np.allclose(set1, set2, rtol=rtol, atol=atol)\n",
      "  File \"<__array_function__ internals>\", line 200, in allclose\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\numpy\\core\\numeric.py\", line 2270, in allclose\n",
      "    res = all(isclose(a, b, rtol=rtol, atol=atol, equal_nan=equal_nan))\n",
      "  File \"<__array_function__ internals>\", line 200, in isclose\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\numpy\\core\\numeric.py\", line 2377, in isclose\n",
      "    xfin = isfinite(x)\n",
      "TypeError: ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_sets_with_negative_values (__main__.TestAreSetsEqual)\n",
      "Test with two sets containing negative floats.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 41, in test_sets_with_negative_values\n",
      "    self.assertTrue(are_sets_equal(set1, set2, rtol=1e-5, atol=1e-6))\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 7, in are_sets_equal\n",
      "    return np.allclose(set1, set2, rtol=rtol, atol=atol)\n",
      "  File \"<__array_function__ internals>\", line 200, in allclose\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\numpy\\core\\numeric.py\", line 2270, in allclose\n",
      "    res = all(isclose(a, b, rtol=rtol, atol=atol, equal_nan=equal_nan))\n",
      "  File \"<__array_function__ internals>\", line 200, in isclose\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\numpy\\core\\numeric.py\", line 2377, in isclose\n",
      "    xfin = isfinite(x)\n",
      "TypeError: ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 0.001s\n",
      "\n",
      "FAILED (errors=6)\n",
      "\n",
      "Process completed with return code: 1\n",
      "555\n",
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "557\n",
      "\n",
      ".......\n",
      "----------------------------------------------------------------------\n",
      "Ran 7 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 215/215 [00:28<00:00,  7.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "558\n",
      "\n",
      ".......\n",
      "----------------------------------------------------------------------\n",
      "Ran 7 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from executor.java_executor import JavaExecutor\n",
    "from executor.ccpp_executor import CCPPExecutor\n",
    "from executor.typescript_executor import TypeScriptExecutor\n",
    "from executor.javascript_executor import JavaScriptExecutor\n",
    "from executor.python_executor import PythonExecutor\n",
    "\n",
    "\n",
    "def get_parser(language, model):\n",
    "    if language == \"python\":\n",
    "        return PythonExecutor(model)\n",
    "    elif language == \"javascript\":\n",
    "        return JavaScriptExecutor(model)\n",
    "    elif language == \"typescript\":\n",
    "        return TypeScriptExecutor(model)\n",
    "    elif language == \"c&cpp\":\n",
    "        return CCPPExecutor(model)\n",
    "    elif language == \"java\":\n",
    "        return JavaExecutor(model)\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "for task in TASK_LIST:\n",
    "    answer_path = f\"{ANSWER_PATH}\\\\{task['model']}\"\n",
    "    Path(f\"./model_answer_result/{task['model']}\").mkdir(exist_ok=True)\n",
    "    for language in task[\"language\"]:\n",
    "        try:\n",
    "            print(language)\n",
    "            parser = get_parser(language, task['model'])\n",
    "            file_path = f\"{ANSWER_PATH}\\\\{task['model']}_answer\\\\{language}_answer.json\"\n",
    "            parser.batch_run(file_path)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    delete_files_in_directory()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LLM回答数据统计"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TASK_LIST = [\n",
    "    {\n",
    "        \"model\": \"chatglm-6b\",\n",
    "        \"language\": [\"python\", \"javascript\", \"typescript\", \"c&cpp\"]\n",
    "    },\n",
    "    {\n",
    "        \"model\": \"codegeex4-all-9b\",\n",
    "        \"language\": [\"python\", \"javascript\", \"typescript\", \"c&cpp\"]\n",
    "    },\n",
    "    {\n",
    "        \"model\": \"codegen25-7b-instruct_P\",\n",
    "        \"language\": [\"python\",\"javascript\",\"typescript\",\"c&cpp\"]\n",
    "    },\n",
    "    {\n",
    "        \"model\": \"CodeLlama-7b-hf\",\n",
    "        \"language\": [\"python\", \"javascript\", \"typescript\", \"c&cpp\"]\n",
    "    },\n",
    "    {\n",
    "        \"model\": \"deepseek-coder-6.7b-instruct\",\n",
    "        \"language\": [\"python\", \"javascript\", \"typescript\", \"c&cpp\"]\n",
    "    },\n",
    "    {\n",
    "        \"model\": \"Meta-Llama-3.1-8B-Instruct\",\n",
    "        \"language\": [\"python\", \"javascript\", \"typescript\", \"c&cpp\"]\n",
    "    },\n",
    "    {\n",
    "        \"model\": \"Mistral-7B-Instruct-v0.3\",\n",
    "        \"language\": [\"python\", \"javascript\", \"typescript\", \"c&cpp\"]\n",
    "    },\n",
    "    {\n",
    "        \"model\": \"Phi-3-small-8k-instruct\",\n",
    "        \"language\": [\"python\", \"javascript\", \"typescript\", \"c&cpp\"]\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"model\": \"starcoder2-7b\",\n",
    "        \"language\": [\"python\", \"javascript\", \"typescript\", \"c&cpp\"]\n",
    "    },\n",
    "    {\n",
    "        \"model\": \"gpt-3.5-turbo\",\n",
    "        \"language\":[\"python\",\"javascript\",\"typescript\",\"c&cpp\"]\n",
    "    }\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result_list = []\n",
    "for task in TASK_LIST:\n",
    "    model_name = task[\"model\"]\n",
    "    language = task[\"language\"]\n",
    "    temp = {\n",
    "        \"model\": model_name\n",
    "    }\n",
    "    for l in language:\n",
    "        file_path = f\"./model_answer_result/{model_name}/{model_name}_{l}.xlsx\"\n",
    "        data = pd.read_excel(file_path)\n",
    "        pass_count = (data[\"result_return_code\"] == 0).sum()\n",
    "        failed_count = (data[\"result_return_code\"] != 0).sum()\n",
    "        pass_rate = (pass_count / len(data)) * 100\n",
    "        temp[f\"{l}_pass_count\"] = pass_count\n",
    "        temp[f\"{l}_failed_count\"] = failed_count\n",
    "        temp[f\"{l}_pass_rate\"] = f\"{pass_rate:.2f}%\"\n",
    "    result_list.append(temp)\n",
    "result_data = pd.DataFrame(result_list)\n",
    "result_data.to_excel(\"./model_answer_result.xlsx\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
