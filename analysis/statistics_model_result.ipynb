{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# LLM回答校验"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def delete_non_ipynb_files():\n",
    "    # 获取当前工作目录\n",
    "    current_directory = os.getcwd()\n",
    "\n",
    "    # 遍历当前目录中的所有文件\n",
    "    for filename in os.listdir(current_directory):\n",
    "        # 检查文件是否为.ipynb文件\n",
    "        if not filename.endswith('.ipynb'):\n",
    "            file_path = os.path.join(current_directory, filename)\n",
    "            # 检查路径是否为文件，避免删除目录\n",
    "            if os.path.isfile(file_path):\n",
    "                try:\n",
    "                    # 删除文件\n",
    "                    os.remove(file_path)\n",
    "                    print(f\"Deleted: {file_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error deleting {file_path}: {e}\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "TASK_LIST = [\n",
    "    # {\n",
    "    #     \"model\": \"chatglm-6b\",\n",
    "    #     \"language\": [\"c&cpp\"]\n",
    "    # }\n",
    "    # {\n",
    "    #     \"model\": \"codegeex4-all-9b\",\n",
    "    #     \"language\": [\"javascript\", \"typescript\", \"c&cpp\"]\n",
    "    # },\n",
    "    # {\n",
    "    #     \"model\": \"codegen25-7b-instruct_P\",\n",
    "    #     \"language\": [\"c&cpp\"]\n",
    "    # },\n",
    "    # {\n",
    "    #     \"model\": \"deepseek-coder-6.7b-instruct\",\n",
    "    #     \"language\": [\"python\", \"javascript\", \"typescript\", \"c&cpp\"]\n",
    "    # },\n",
    "    # {\n",
    "    #     \"model\": \"Meta-Llama-3.1-8B-Instruct\",\n",
    "    #     \"language\": [\"javascript\"]\n",
    "    # },\n",
    "    # {\n",
    "    #     \"model\": \"Mistral-7B-Instruct-v0.3\",\n",
    "    #     \"language\": [\"python\", \"javascript\", \"typescript\", \"c&cpp\"]\n",
    "    # },\n",
    "    # {\n",
    "    #     \"model\": \"Phi-3-small-8k-instruct\",\n",
    "    #     \"language\": [\"typescript\"]\n",
    "    # },\n",
    "    # {\n",
    "    #     \"model\": \"CodeLlama-7b-hf\",\n",
    "    #     \"language\": [\"python\", \"javascript\", \"typescript\", \"c&cpp\"]\n",
    "    # },\n",
    "    # {\n",
    "    #     \"model\": \"starcoder2-7b\",\n",
    "    #     \"language\": [\"python\", \"javascript\", \"typescript\", \"c&cpp\"]\n",
    "    # },\n",
    "    {\n",
    "        \"model\": \"gpt-3.5-turbo\",\n",
    "        \"language\": [\"python\"]\n",
    "    }\n",
    "]\n",
    "ANSWER_PATH = \"E:\\code\\code_back\\python_project\\llm\\qa\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/214 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/214 [00:00<00:28,  7.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/214 [00:00<00:25,  8.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 3/214 [00:00<00:26,  7.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 4/214 [00:00<00:26,  7.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "...\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 5/214 [00:00<00:26,  7.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 6/214 [00:00<00:26,  7.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 7/214 [00:00<00:25,  8.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "12\n",
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 10/214 [00:01<00:20,  9.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "14\n",
      "\n",
      "EEEEEE\n",
      "======================================================================\n",
      "ERROR: test_empty_json_file (__main__.TestFindJsonFilesWithKeyword)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 1342, in patched\n",
      "    return func(*newargs, **newkeywargs)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 65, in test_empty_json_file\n",
      "    result = find_json_files_with_keyword('/testdir', 'value')\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 7, in find_json_files_with_keyword\n",
      "    for filename in os.listdir(directory):\n",
      "FileNotFoundError: [WinError 3] ϵͳҲָ·: '/testdir'\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_io_error_while_reading_file (__main__.TestFindJsonFilesWithKeyword)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 1342, in patched\n",
      "    return func(*newargs, **newkeywargs)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 74, in test_io_error_while_reading_file\n",
      "    result = find_json_files_with_keyword('/testdir', 'value')\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 7, in find_json_files_with_keyword\n",
      "    for filename in os.listdir(directory):\n",
      "FileNotFoundError: [WinError 3] ϵͳҲָ·: '/testdir'\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_multiple_files_match (__main__.TestFindJsonFilesWithKeyword)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 1342, in patched\n",
      "    return func(*newargs, **newkeywargs)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 39, in test_multiple_files_match\n",
      "    result = find_json_files_with_keyword('/testdir', 'value')\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 7, in find_json_files_with_keyword\n",
      "    for filename in os.listdir(directory):\n",
      "FileNotFoundError: [WinError 3] ϵͳҲָ·: '/testdir'\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_nested_keyword_match (__main__.TestFindJsonFilesWithKeyword)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 1342, in patched\n",
      "    return func(*newargs, **newkeywargs)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 56, in test_nested_keyword_match\n",
      "    result = find_json_files_with_keyword('/testdir', 'nested_value')\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 7, in find_json_files_with_keyword\n",
      "    for filename in os.listdir(directory):\n",
      "FileNotFoundError: [WinError 3] ϵͳҲָ·: '/testdir'\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_no_json_files (__main__.TestFindJsonFilesWithKeyword)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 1342, in patched\n",
      "    return func(*newargs, **newkeywargs)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 47, in test_no_json_files\n",
      "    result = find_json_files_with_keyword('/testdir', 'value')\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 7, in find_json_files_with_keyword\n",
      "    for filename in os.listdir(directory):\n",
      "FileNotFoundError: [WinError 3] ϵͳҲָ·: '/testdir'\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_single_file_match (__main__.TestFindJsonFilesWithKeyword)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 1342, in patched\n",
      "    return func(*newargs, **newkeywargs)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 30, in test_single_file_match\n",
      "    result = find_json_files_with_keyword('/testdir', 'value')\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 7, in find_json_files_with_keyword\n",
      "    for filename in os.listdir(directory):\n",
      "FileNotFoundError: [WinError 3] ϵͳҲָ·: '/testdir'\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 0.004s\n",
      "\n",
      "FAILED (errors=6)\n",
      "\n",
      "Process completed with return code: 1\n",
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 12/214 [00:01<00:20,  9.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "18\n",
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 14/214 [00:01<00:21,  9.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "20\n",
      "\n",
      "F\n",
      "======================================================================\n",
      "FAIL: test_markdown_processing (__main__.TestMarkdownProcessor)\n",
      "Run all test cases.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 58, in test_markdown_processing\n",
      "    self.assertEqual(processed_content, expected_content)\n",
      "AssertionError: 'This is bold and _italic_ text.' != 'This is **bold** and _italic_ text.'\n",
      "- This is bold and _italic_ text.\n",
      "+ This is **bold** and _italic_ text.\n",
      "?         ++    ++\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.010s\n",
      "\n",
      "FAILED (failures=1)\n",
      "\n",
      "Process completed with return code: 1\n",
      "21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 16/214 [00:01<00:21,  9.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.011s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "22\n",
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 18/214 [00:02<00:25,  7.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "24\n",
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.038s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 20/214 [00:02<00:21,  9.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 3, in <module>\n",
      "    def classify_json_objects_by_pid(source_file: str, pid_list: List[int], match_file: str, mismatch_file: str) -> None:\n",
      "NameError: name 'List' is not defined\n",
      "\n",
      "Process completed with return code: 1\n",
      "26\n",
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "27\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 1, in <module>\n",
      "    def concatenate_json_arrays(directory: str) -> List:\n",
      "NameError: name 'List' is not defined\n",
      "\n",
      "Process completed with return code: 1\n",
      "28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 23/214 [00:02<00:19,  9.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "31\n",
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 25/214 [00:03<00:28,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.003s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "35\n",
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "36\n",
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 28/214 [00:03<00:21,  8.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 1, in <module>\n",
      "    def lanczos(n: int, quadrature_rule: QuadratureRule) -> Tuple[np.ndarray, np.ndarray, np.ndarray, QuadratureRule]:\n",
      "NameError: name 'QuadratureRule' is not defined\n",
      "\n",
      "Process completed with return code: 1\n",
      "38\n",
      "\n",
      "...\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 31/214 [00:03<00:26,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FFEFF\n",
      "======================================================================\n",
      "ERROR: test_invalid_note_name (__main__.TestAdjustToCMajor)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 36, in test_invalid_note_name\n",
      "    self.assertEqual(adjust_to_c_major(\"H2\"), \"C4\")\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 13, in adjust_to_c_major\n",
      "    note = pitch.Pitch(note_name)\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\music21\\pitch.py\", line 1848, in __init__\n",
      "    self.name = name  # set based on string\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\music21\\pitch.py\", line 2675, in name\n",
      "    self.step = usrStr  # type: ignore\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\music21\\pitch.py\", line 2879, in step\n",
      "    raise PitchException(f'Cannot make a step out of {usrStr!r}')\n",
      "music21.pitch.PitchException: Cannot make a step out of 'H'\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_edge_case_note_transitions (__main__.TestAdjustToCMajor)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 45, in test_edge_case_note_transitions\n",
      "    self.assertEqual(adjust_to_c_major(\"B3\"), \"B3\")\n",
      "AssertionError: 'C3' != 'B3'\n",
      "- C3\n",
      "+ B3\n",
      "\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_extreme_octaves (__main__.TestAdjustToCMajor)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 40, in test_extreme_octaves\n",
      "    self.assertEqual(adjust_to_c_major(\"A0\"), \"A0\")\n",
      "AssertionError: 'C0' != 'A0'\n",
      "- C0\n",
      "+ A0\n",
      "\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_note_in_c_major (__main__.TestAdjustToCMajor)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 25, in test_note_in_c_major\n",
      "    self.assertEqual(adjust_to_c_major(\"E5\"), \"E5\")\n",
      "AssertionError: 'B5' != 'E5'\n",
      "- B5\n",
      "+ E5\n",
      "\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_transpose_to_c_major (__main__.TestAdjustToCMajor)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 30, in test_transpose_to_c_major\n",
      "    self.assertEqual(adjust_to_c_major(\"F#4\"), \"G4\")\n",
      "AssertionError: 'F4' != 'G4'\n",
      "- F4\n",
      "+ G4\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.009s\n",
      "\n",
      "FAILED (failures=4, errors=1)\n",
      "\n",
      "Process completed with return code: 1\n",
      "41\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 1, in <module>\n",
      "    import mmh3\n",
      "ModuleNotFoundError: No module named 'mmh3'\n",
      "\n",
      "Process completed with return code: 1\n",
      "42\n",
      "\n",
      ".F...\n",
      "======================================================================\n",
      "FAIL: test_international_number (__main__.TestReplacePhoneNumbers)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 18, in test_international_number\n",
      "    self.assertEqual(replace_phone_numbers(msg), expected)\n",
      "AssertionError: 'Contact us at 44 123 456 789.' != 'Contact us at [PHONE_NUM].'\n",
      "- Contact us at 44 123 456 789.\n",
      "+ Contact us at [PHONE_NUM].\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.001s\n",
      "\n",
      "FAILED (failures=1)\n",
      "\n",
      "Process completed with return code: 1\n",
      "43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 33/214 [00:04<00:23,  7.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "44\n",
      "\n",
      ".......\n",
      "----------------------------------------------------------------------\n",
      "Ran 7 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 35/214 [00:04<00:21,  8.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "..F..\n",
      "======================================================================\n",
      "FAIL: test_end_of_month (__main__.TestGetCurrentDateInfo)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 52, in test_end_of_month\n",
      "    self.assertEqual(result, expected)\n",
      "AssertionError: {'yea[20 chars]January', 'week_of_the_month': 5, 'day_of_the_week': 'Tuesday'} != {'yea[20 chars]January', 'week_of_the_month': 6, 'day_of_the_week': 'Tuesday'}\n",
      "  {'day_of_the_week': 'Tuesday',\n",
      "   'month': 'January',\n",
      "-  'week_of_the_month': 5,\n",
      "?                       ^\n",
      "\n",
      "+  'week_of_the_month': 6,\n",
      "?                       ^\n",
      "\n",
      "   'year': 2023}\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "FAILED (failures=1)\n",
      "\n",
      "Process completed with return code: 1\n",
      "46\n",
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "47\n",
      "\n",
      "...F.\n",
      "======================================================================\n",
      "FAIL: test_out_of_range (__main__.TestFindNthWeekdayOfSpecificYear)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 37, in test_out_of_range\n",
      "    self.assertEqual(result, expected)\n",
      "AssertionError: datetime.date(2023, 6, 26) != datetime.date(2023, 5, 29)\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "FAILED (failures=1)\n",
      "\n",
      "Process completed with return code: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 37/214 [00:04<00:23,  7.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n",
      "\n",
      "EEEEE\n",
      "======================================================================\n",
      "ERROR: test_identity_transformation (__main__.TestChangeReferenceFrame)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 33, in test_identity_transformation\n",
      "    result = change_reference_frame(self.point_cloud, self.ref_frame_points)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 12, in change_reference_frame\n",
      "    x_axis /= np.linalg.norm(x_axis)\n",
      "numpy.core._exceptions._UFuncOutputCastingError: Cannot cast ufunc 'divide' output from dtype('float64') to dtype('int32') with casting rule 'same_kind'\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_inverted_frame (__main__.TestChangeReferenceFrame)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 65, in test_inverted_frame\n",
      "    result = change_reference_frame(self.point_cloud, frame_points)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 12, in change_reference_frame\n",
      "    x_axis /= np.linalg.norm(x_axis)\n",
      "numpy.core._exceptions._UFuncOutputCastingError: Cannot cast ufunc 'divide' output from dtype('float64') to dtype('int32') with casting rule 'same_kind'\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_non_orthonormal_frame (__main__.TestChangeReferenceFrame)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 53, in test_non_orthonormal_frame\n",
      "    result = change_reference_frame(self.point_cloud, frame_points)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 12, in change_reference_frame\n",
      "    x_axis /= np.linalg.norm(x_axis)\n",
      "numpy.core._exceptions._UFuncOutputCastingError: Cannot cast ufunc 'divide' output from dtype('float64') to dtype('int32') with casting rule 'same_kind'\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_rotation (__main__.TestChangeReferenceFrame)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 46, in test_rotation\n",
      "    result = change_reference_frame(self.point_cloud, frame_points)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 12, in change_reference_frame\n",
      "    x_axis /= np.linalg.norm(x_axis)\n",
      "numpy.core._exceptions._UFuncOutputCastingError: Cannot cast ufunc 'divide' output from dtype('float64') to dtype('int32') with casting rule 'same_kind'\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_translation (__main__.TestChangeReferenceFrame)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 39, in test_translation\n",
      "    result = change_reference_frame(self.point_cloud, frame_points)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 12, in change_reference_frame\n",
      "    x_axis /= np.linalg.norm(x_axis)\n",
      "numpy.core._exceptions._UFuncOutputCastingError: Cannot cast ufunc 'divide' output from dtype('float64') to dtype('int32') with casting rule 'same_kind'\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.002s\n",
      "\n",
      "FAILED (errors=5)\n",
      "\n",
      "Process completed with return code: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 38/214 [00:04<00:22,  7.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n",
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 41/214 [00:05<00:17,  9.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.001s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "54\n",
      "\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 4\n",
      "    return [s.replace('\n",
      "                      ^\n",
      "SyntaxError: EOL while scanning string literal\n",
      "\n",
      "Process completed with return code: 1\n",
      "55\n",
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 42/214 [00:05<00:31,  5.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.311s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 44/214 [00:05<00:30,  5.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FF.FF\n",
      "======================================================================\n",
      "FAIL: test_default_icon_size (__main__.TestConvertPngToIco)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 1342, in patched\n",
      "    return func(*newargs, **newkeywargs)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 37, in test_default_icon_size\n",
      "    mock_image.save.assert_called_with('output.ico', format='ICO', sizes=[(32, 32)])\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 898, in assert_called_with\n",
      "    raise AssertionError(error_message)\n",
      "AssertionError: expected call not found.\n",
      "Expected: save('output.ico', format='ICO', sizes=[(32, 32)])\n",
      "Actual: not called.\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_file_handling (__main__.TestConvertPngToIco)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 1342, in patched\n",
      "    return func(*newargs, **newkeywargs)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 45, in test_file_handling\n",
      "    mock_image.save.assert_called_once_with('output.ico', format='ICO', sizes=[(32, 32)])\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 918, in assert_called_once_with\n",
      "    raise AssertionError(msg)\n",
      "AssertionError: Expected 'save' to be called once. Called 0 times.\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_multiple_icon_sizes (__main__.TestConvertPngToIco)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 1342, in patched\n",
      "    return func(*newargs, **newkeywargs)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 31, in test_multiple_icon_sizes\n",
      "    mock_image.save.assert_called_with('output.ico', format='ICO', sizes=[(16, 16), (32, 32), (64, 64)])\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 898, in assert_called_with\n",
      "    raise AssertionError(error_message)\n",
      "AssertionError: expected call not found.\n",
      "Expected: save('output.ico', format='ICO', sizes=[(16, 16), (32, 32), (64, 64)])\n",
      "Actual: not called.\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_single_icon_size (__main__.TestConvertPngToIco)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 1342, in patched\n",
      "    return func(*newargs, **newkeywargs)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 25, in test_single_icon_size\n",
      "    mock_image.save.assert_called_with('output.ico', format='ICO', sizes=[(64, 64)])\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 898, in assert_called_with\n",
      "    raise AssertionError(error_message)\n",
      "AssertionError: expected call not found.\n",
      "Expected: save('output.ico', format='ICO', sizes=[(64, 64)])\n",
      "Actual: not called.\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.005s\n",
      "\n",
      "FAILED (failures=4)\n",
      "\n",
      "Process completed with return code: 1\n",
      "58\n",
      "\n",
      "...\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 45/214 [00:05<00:26,  6.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 47/214 [00:06<00:32,  5.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.039s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "62\n",
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 49/214 [00:07<00:35,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FFFFF\n",
      "======================================================================\n",
      "FAIL: test_empty_dataframe (__main__.TestDataframeToMarkdown)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 32, in test_empty_dataframe\n",
      "    self.assertEqual(result, expected_markdown)\n",
      "AssertionError: '' != '|  |\\n|  |\\n'\n",
      "+ |  |\n",
      "+ |  |\n",
      "\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_non_string_columns (__main__.TestDataframeToMarkdown)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 46, in test_non_string_columns\n",
      "    self.assertEqual(result, expected_markdown)\n",
      "AssertionError: '| Name   |   Age |   Height |\\n|:-------|------:[70 chars]   |' != '| Name | Age | Height |\\n| --- | --- | --- |\\n| [36 chars] |\\n'\n",
      "- | Name   |   Age |   Height |\n",
      "?        -- --      --\n",
      "+ | Name | Age | Height |\n",
      "- |:-------|------:|---------:|\n",
      "+ | --- | --- | --- |\n",
      "- | Alice  |    25 |      5.5 |\n",
      "?         - ---     -----\n",
      "+ | Alice | 25 | 5.5 |\n",
      "- | Bob    |    30 |      6   |+ | Bob | 30 | 6.0 |\n",
      "\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_single_row_dataframe (__main__.TestDataframeToMarkdown)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 39, in test_single_row_dataframe\n",
      "    self.assertEqual(result, expected_markdown)\n",
      "AssertionError: '| Name   |   Age |\\n|:-------|------:|\\n| Alice  |    30 |' != '| Name | Age |\\n| --- | --- |\\n| Alice | 30 |\\n'\n",
      "- | Name   |   Age |\n",
      "?        -- --\n",
      "+ | Name | Age |\n",
      "- |:-------|------:|\n",
      "+ | --- | --- |\n",
      "- | Alice  |    30 |?         - ---\n",
      "+ | Alice | 30 |\n",
      "?               +\n",
      "\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_special_characters (__main__.TestDataframeToMarkdown)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 54, in test_special_characters\n",
      "    self.assertEqual(result, expected_markdown)\n",
      "AssertionError: '| Name   | Comments                |\\n|:-------|[98 chars]le |' != '| Name | Comments |\\n| --- | --- |\\n| Alice | Go[43 chars] |\\n'\n",
      "- | Name   | Comments                |\n",
      "- |:-------|:------------------------|\n",
      "+ | Name | Comments |\n",
      "+ | --- | --- |\n",
      "- | Alice  | Good@Work!              |\n",
      "?         -             -------------\n",
      "+ | Alice | Good@Work! |\n",
      "- | Bob    | Excellent & Commendable |?       ---\n",
      "+ | Bob | Excellent & Commendable |\n",
      "?                                  +\n",
      "\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_write_to_file (__main__.TestDataframeToMarkdown)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 1342, in patched\n",
      "    return func(*newargs, **newkeywargs)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 24, in test_write_to_file\n",
      "    mock_file().write.assert_called_once_with(expected_markdown)\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 919, in assert_called_once_with\n",
      "    return self.assert_called_with(*args, **kwargs)\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 907, in assert_called_with\n",
      "    raise AssertionError(_error_message()) from cause\n",
      "AssertionError: expected call not found.\n",
      "Expected: write('| Name | Age |\\n| --- | --- |\\n| Alice | 25 |\\n| Bob | 30 |\\n')\n",
      "Actual: write('| Name   |   Age |\\n|:-------|------:|\\n| Alice  |    25 |\\n| Bob    |    30 |')\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.013s\n",
      "\n",
      "FAILED (failures=5)\n",
      "\n",
      "Process completed with return code: 1\n",
      "64\n",
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.023s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 52/214 [00:07<00:22,  7.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".......\n",
      "----------------------------------------------------------------------\n",
      "Ran 7 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "66\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 4, in <module>\n",
      "    def topological_sort(courses: Iterable[Course]) -> List[LeveledCourse]:\n",
      "NameError: name 'Course' is not defined\n",
      "\n",
      "Process completed with return code: 1\n",
      "67\n",
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 53/214 [00:07<00:21,  7.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "70\n",
      "\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 5\n",
      "    code_blocks = re.findall(r'\n",
      "                              ^\n",
      "SyntaxError: EOL while scanning string literal\n",
      "\n",
      "Process completed with return code: 1\n",
      "71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 56/214 [00:07<00:22,  7.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.027s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "72\n",
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.009s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 58/214 [00:08<00:19,  7.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73\n",
      "\n",
      "...\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "74\n",
      "\n",
      "FFFF\n",
      "======================================================================\n",
      "FAIL: test_advance_32_bit_conversion (__main__.TestConvertDecimalToBinary)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 27, in test_advance_32_bit_conversion\n",
      "    self.assertEqual(convert_decimal_to_binary(1.5, 32), '00111111110000000000000000000000',\n",
      "AssertionError: '00000000000000001100000000111111' != '00111111110000000000000000000000'\n",
      "- 00000000000000001100000000111111\n",
      "+ 00111111110000000000000000000000\n",
      " : 1.5 should be correctly converted to 32-bit binary\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_advance_64_bit_conversion (__main__.TestConvertDecimalToBinary)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 31, in test_advance_64_bit_conversion\n",
      "    self.assertEqual(convert_decimal_to_binary(1.5, 64),\n",
      "AssertionError: '0000000000000000000000000000000000000000000000001111100000111111' != '0011111111111000000000000000000000000000000000000000000000000000'\n",
      "- 0000000000000000000000000000000000000000000000001111100000111111\n",
      "?                                                 -----   --------\n",
      "+ 0011111111111000000000000000000000000000000000000000000000000000\n",
      "? +++++++++++++\n",
      " : 1.5 should be correctly converted to 32-bit binary\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_basic_32_bit_conversion (__main__.TestConvertDecimalToBinary)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 17, in test_basic_32_bit_conversion\n",
      "    self.assertEqual(convert_decimal_to_binary(3.14, 32),\n",
      "AssertionError: '11000011111101010100100001000000' != '01000000010010001111010111000011'\n",
      "- 11000011111101010100100001000000\n",
      "+ 01000000010010001111010111000011\n",
      " : 3.14 should be correctly converted to 32-bit binary\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_basic_64_bit_conversion (__main__.TestConvertDecimalToBinary)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 22, in test_basic_64_bit_conversion\n",
      "    self.assertEqual(convert_decimal_to_binary(3.14, 64),\n",
      "AssertionError: '0001111110000101111010110101000110111000000111100000100101000000' != '0100000000001001000111101011100001010001111010111000010100011111'\n",
      "- 0001111110000101111010110101000110111000000111100000100101000000\n",
      "+ 0100000000001001000111101011100001010001111010111000010100011111\n",
      " : 3.14 should be correctly converted to 64-bit binary\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.002s\n",
      "\n",
      "FAILED (failures=4)\n",
      "\n",
      "Process completed with return code: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 59/214 [00:08<00:19,  8.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n",
      "\n",
      "F.F.F\n",
      "======================================================================\n",
      "FAIL: test_basic_renaming (__main__.TestRenameFiles)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 55, in test_basic_renaming\n",
      "    self.assertEqual(result_files, expected_files)\n",
      "AssertionError: Lists differ: ['image10001.png', 'image20002.png', 'image30003.png'] != ['image1001.png', 'image2001.png', 'image3001.png']\n",
      "\n",
      "First differing element 0:\n",
      "'image10001.png'\n",
      "'image1001.png'\n",
      "\n",
      "- ['image10001.png', 'image20002.png', 'image30003.png']\n",
      "?           -                 ^^                ^^\n",
      "\n",
      "+ ['image1001.png', 'image2001.png', 'image3001.png']\n",
      "?                            ^                ^\n",
      "\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_files_with_existing_numbers (__main__.TestRenameFiles)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 95, in test_files_with_existing_numbers\n",
      "    self.assertEqual(result_files, expected_files)\n",
      "AssertionError: Lists differ: ['file0010001.png', 'file0020002.png', 'file0030003.png'] != ['file001001.png', 'file002001.png', 'file003001.png']\n",
      "\n",
      "First differing element 0:\n",
      "'file0010001.png'\n",
      "'file001001.png'\n",
      "\n",
      "- ['file0010001.png', 'file0020002.png', 'file0030003.png']\n",
      "?            -                  ^^                 ^^\n",
      "\n",
      "+ ['file001001.png', 'file002001.png', 'file003001.png']\n",
      "?                              ^                 ^\n",
      "\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_reset_counter_for_different_base_names (__main__.TestRenameFiles)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 66, in test_reset_counter_for_different_base_names\n",
      "    self.assertEqual(result_files, expected_files)\n",
      "AssertionError: Lists differ: ['image10001.png', 'image20002.png', 'picture10003.png', 'picture20004.png'] != ['image1001.png', 'image2001.png', 'picture1001.png', 'picture2001.png']\n",
      "\n",
      "First differing element 0:\n",
      "'image10001.png'\n",
      "'image1001.png'\n",
      "\n",
      "- ['image10001.png', 'image20002.png', 'picture10003.png', 'picture20004.png']\n",
      "?           -                 ^^                  ^^                  ^^\n",
      "\n",
      "+ ['image1001.png', 'image2001.png', 'picture1001.png', 'picture2001.png']\n",
      "?                            ^                  ^                  ^\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.006s\n",
      "\n",
      "FAILED (failures=3)\n",
      "\n",
      "Process completed with return code: 1\n",
      "76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 61/214 [00:08<00:18,  8.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "77\n",
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 63/214 [00:08<00:19,  7.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.006s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "79\n",
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.002s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "80\n",
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 65/214 [00:08<00:17,  8.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n",
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 67/214 [00:09<00:32,  4.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.315s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "83\n",
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 68/214 [00:09<00:27,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 70/214 [00:10<00:29,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.002s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "86\n",
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 72/214 [00:10<00:24,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "...\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.007s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "214\n",
      "\n",
      "F.FF\n",
      "======================================================================\n",
      "FAIL: test_malformed_line_no_comma (__main__.TestReadMappingFile)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 49, in test_malformed_line_no_comma\n",
      "    self.assertEqual(str(context.exception), \"Each line must contain exactly one comma separating the pattern and the replacement.\")\n",
      "AssertionError: 'not enough values to unpack (expected 2, got 1)' != 'Each line must contain exactly one comma [39 chars]ent.'\n",
      "- not enough values to unpack (expected 2, got 1)\n",
      "+ Each line must contain exactly one comma separating the pattern and the replacement.\n",
      "\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_valid_mapping_file (__main__.TestReadMappingFile)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 36, in test_valid_mapping_file\n",
      "    self.assertEqual(result, expected)\n",
      "AssertionError: Lists differ: [(re.compile(\"'old_pattern1'\"), \"'new_word1'\"), (re.co[35 chars]2'\")] != [(re.compile('old_pattern1'), 'new_word1'), (re.compil[27 chars]d2')]\n",
      "\n",
      "First differing element 0:\n",
      "(re.compile(\"'old_pattern1'\"), \"'new_word1'\")\n",
      "(re.compile('old_pattern1'), 'new_word1')\n",
      "\n",
      "- [(re.compile(\"'old_pattern1'\"), \"'new_word1'\"),\n",
      "?              -              -   -           -\n",
      "\n",
      "+ [(re.compile('old_pattern1'), 'new_word1'),\n",
      "-  (re.compile(\"'old_pattern2'\"), \"'new_word2'\")]\n",
      "?              -              -   -           -\n",
      "\n",
      "+  (re.compile('old_pattern2'), 'new_word2')]\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_valid_patterns_with_special_characters (__main__.TestReadMappingFile)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 60, in test_valid_patterns_with_special_characters\n",
      "    self.assertEqual(result, expected)\n",
      "AssertionError: Lists differ: [(re.compile(\"'\\\\d+'\"), \" 'number'\"), (re.compile(\"'\\\\w+'\"), \" 'word'\")] != [(re.compile('\\\\d+'), 'number'), (re.compile('\\\\w+'), 'word')]\n",
      "\n",
      "First differing element 0:\n",
      "(re.compile(\"'\\\\d+'\"), \" 'number'\")\n",
      "(re.compile('\\\\d+'), 'number')\n",
      "\n",
      "- [(re.compile(\"'\\\\d+'\"), \" 'number'\"), (re.compile(\"'\\\\w+'\"), \" 'word'\")]\n",
      "?              -      -  --         -               -      -  --       -\n",
      "\n",
      "+ [(re.compile('\\\\d+'), 'number'), (re.compile('\\\\w+'), 'word')]\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.008s\n",
      "\n",
      "FAILED (failures=3)\n",
      "\n",
      "Process completed with return code: 1\n",
      "215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 74/214 [00:10<00:20,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.009s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "216\n",
      "\n",
      "F..\n",
      "======================================================================\n",
      "FAIL: test_command_failure (__main__.TestGetLocalIp)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 1342, in patched\n",
      "    return func(*newargs, **newkeywargs)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 46, in test_command_failure\n",
      "    get_local_ip('wlan0')\n",
      "AssertionError: RuntimeError not raised\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.002s\n",
      "\n",
      "FAILED (failures=1)\n",
      "\n",
      "Process completed with return code: 1\n",
      "219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 76/214 [00:10<00:17,  7.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "220\n",
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 78/214 [00:11<00:16,  8.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.008s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "224\n",
      "\n",
      "...\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.003s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 79/214 [00:11<00:27,  4.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "...\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.028s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 81/214 [00:11<00:25,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.082s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "229\n",
      "\n",
      ".......\n",
      "----------------------------------------------------------------------\n",
      "Ran 7 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 83/214 [00:12<00:20,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EEEEE\n",
      "======================================================================\n",
      "ERROR: test_all_emojis (__main__.TestMoveEmojisToEnd)\n",
      "Test string that contains only emojis\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 38, in test_all_emojis\n",
      "    self.assertEqual(move_emojis_to_end(input_text), expected_output)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 14, in move_emojis_to_end\n",
      "    emojis = ''.join(re.findall(emoji.get_emoji_regexp(), text))\n",
      "AttributeError: module 'emoji' has no attribute 'get_emoji_regexp'\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_emojis_and_whitespace (__main__.TestMoveEmojisToEnd)\n",
      "Test string with emojis and whitespace characters\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 50, in test_emojis_and_whitespace\n",
      "    self.assertEqual(move_emojis_to_end(input_text), expected_output)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 14, in move_emojis_to_end\n",
      "    emojis = ''.join(re.findall(emoji.get_emoji_regexp(), text))\n",
      "AttributeError: module 'emoji' has no attribute 'get_emoji_regexp'\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_multiple_emojis_mixed (__main__.TestMoveEmojisToEnd)\n",
      "Test string with multiple emojis mixed in text\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 32, in test_multiple_emojis_mixed\n",
      "    self.assertEqual(move_emojis_to_end(input_text), expected_output)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 14, in move_emojis_to_end\n",
      "    emojis = ''.join(re.findall(emoji.get_emoji_regexp(), text))\n",
      "AttributeError: module 'emoji' has no attribute 'get_emoji_regexp'\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_no_emojis (__main__.TestMoveEmojisToEnd)\n",
      "Test string with no emojis\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 44, in test_no_emojis\n",
      "    self.assertEqual(move_emojis_to_end(input_text), expected_output)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 14, in move_emojis_to_end\n",
      "    emojis = ''.join(re.findall(emoji.get_emoji_regexp(), text))\n",
      "AttributeError: module 'emoji' has no attribute 'get_emoji_regexp'\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_single_emoji_at_start (__main__.TestMoveEmojisToEnd)\n",
      "Test string with a single emoji at the start\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 26, in test_single_emoji_at_start\n",
      "    self.assertEqual(move_emojis_to_end(input_text), expected_output)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 14, in move_emojis_to_end\n",
      "    emojis = ''.join(re.findall(emoji.get_emoji_regexp(), text))\n",
      "AttributeError: module 'emoji' has no attribute 'get_emoji_regexp'\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "FAILED (errors=5)\n",
      "\n",
      "Process completed with return code: 1\n",
      "231\n",
      "\n",
      ".E..\n",
      "======================================================================\n",
      "ERROR: test_invalid_json (__main__.TestReadLog)\n",
      "Test behavior when file contains invalid JSON\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 35, in test_invalid_json\n",
      "    train_loss, test_acc1 = read_log(\"dummy_path.json\")\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 9, in read_log\n",
      "    entry = json.loads(line.strip())\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 1075, in __call__\n",
      "    return self._mock_call(*args, **kwargs)\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 1079, in _mock_call\n",
      "    return self._execute_mock_call(*args, **kwargs)\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 1134, in _execute_mock_call\n",
      "    raise effect\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.009s\n",
      "\n",
      "FAILED (errors=1)\n",
      "\n",
      "Process completed with return code: 1\n",
      "232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 85/214 [00:12<00:16,  7.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "233\n",
      "\n",
      "...F\n",
      "======================================================================\n",
      "FAIL: test_single_line_comment (__main__.TestRemoveComments)\n",
      "Test string with a comment on a single line\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 20, in test_single_line_comment\n",
      "    self.assertEqual(remove_comments(input_string), expected_output)\n",
      "AssertionError: 'Hello, world!' != 'Hello, world! '\n",
      "- Hello, world!\n",
      "+ Hello, world! \n",
      "?              +\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.000s\n",
      "\n",
      "FAILED (failures=1)\n",
      "\n",
      "Process completed with return code: 1\n",
      "234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 87/214 [00:12<00:15,  8.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "235\n",
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 89/214 [00:12<00:14,  8.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".F.....\n",
      "======================================================================\n",
      "FAIL: test_multiple_units (__main__.TestGenTimeoutTimedelta)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 31, in test_multiple_units\n",
      "    self.assertEqual(gen_timeout_timedelta(\"1d 2h 3m 4s 500ms\"),\n",
      "AssertionError: datetime.timedelta(days=1, seconds=37384) != datetime.timedelta(days=1, seconds=7384, microseconds=500000)\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 7 tests in 0.000s\n",
      "\n",
      "FAILED (failures=1)\n",
      "\n",
      "Process completed with return code: 1\n",
      "241\n",
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.008s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 91/214 [00:13<00:13,  8.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....F\n",
      "======================================================================\n",
      "FAIL: test_no_extension_files (__main__.TestClassifyFilesByExtension)\n",
      "Test with files that have no extensions.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 49, in test_no_extension_files\n",
      "    self.assertEqual(classify_files_by_extension(files), expected_result)\n",
      "AssertionError: {'no_extension': ['README', 'LICENSE', 'script', 'data']} != {}\n",
      "- {'no_extension': ['README', 'LICENSE', 'script', 'data']}\n",
      "+ {}\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "FAILED (failures=1)\n",
      "\n",
      "Process completed with return code: 1\n",
      "244\n",
      "\n",
      "..\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 93/214 [00:13<00:14,  8.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "...\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "249\n",
      "\n",
      "FFF\n",
      "======================================================================\n",
      "FAIL: test_empty_file (__main__.TestExtractTextFromPDF)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 27, in test_empty_file\n",
      "    self.assertEqual(output, expected)\n",
      "AssertionError: ' ' != ' \\n'\n",
      "-  \n",
      "+  \n",
      "\n",
      "?  \n",
      "+\n",
      "\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_more_text_file (__main__.TestExtractTextFromPDF)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 39, in test_more_text_file\n",
      "    self.assertEqual(output, expected)\n",
      "AssertionError: '11111  \\n22222  \\n33333  \\n44444  ' != '11111  \\n22222  \\n33333  \\n44444  \\n'\n",
      "  11111  \n",
      "  22222  \n",
      "  33333  \n",
      "- 44444  + 44444  \n",
      "?        +\n",
      "\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_normal_file (__main__.TestExtractTextFromPDF)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 33, in test_normal_file\n",
      "    self.assertEqual(output, expected)\n",
      "AssertionError: '11111  ' != '11111  \\n'\n",
      "- 11111  \n",
      "+ 11111  \n",
      "\n",
      "?        \n",
      "+\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.006s\n",
      "\n",
      "FAILED (failures=3)\n",
      "\n",
      "Process completed with return code: 1\n",
      "250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 95/214 [00:13<00:13,  8.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "252\n",
      "\n",
      ".FF..\n",
      "======================================================================\n",
      "FAIL: test_complex_structure_with_bits (__main__.TestBitSequenceEncoder)\n",
      "Test encoding a complex dictionary structure containing multiple 'bits' keys.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 46, in test_complex_structure_with_bits\n",
      "    self.assertEqual(result, '{\"processor\": {\"bits\": \"00000011\", \"type\": \"A\"}, \"memory\": {\"bits\": \"11111111\", \"size\": 16}, \"ports\": {\"count\": 2, \"bits\": \"10000000\"}}')\n",
      "AssertionError: '{\"pr[14 chars]ts\": 3, \"type\": \"A\"}, \"memory\": {\"bits\": 255, [44 chars]28}}' != '{\"pr[14 chars]ts\": \"00000011\", \"type\": \"A\"}, \"memory\": {\"bit[67 chars]0\"}}'\n",
      "- {\"processor\": {\"bits\": 3, \"type\": \"A\"}, \"memory\": {\"bits\": 255, \"size\": 16}, \"ports\": {\"count\": 2, \"bits\": 128}}\n",
      "?                        ^                                   ^^^                                              ^^\n",
      "+ {\"processor\": {\"bits\": \"00000011\", \"type\": \"A\"}, \"memory\": {\"bits\": \"11111111\", \"size\": 16}, \"ports\": {\"count\": 2, \"bits\": \"10000000\"}}\n",
      "?                        ^^^^^^^^^^                                   ^^^^^^^^^^                                             + ^^^^^^^^\n",
      "\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_nested_encoding (__main__.TestBitSequenceEncoder)\n",
      "Test encoding with nested dictionary containing 'bits'.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 24, in test_nested_encoding\n",
      "    self.assertEqual(result, '{\"component\": {\"name\": \"ALU\", \"bits\": \"10000000\"}, \"bits\": \"00000001\"}')\n",
      "AssertionError: '{\"component\": {\"name\": \"ALU\", \"bits\": 128}, \"bits\": \"1\"}' != '{\"component\": {\"name\": \"ALU\", \"bits\": \"10000000\"}, \"bits\": \"00000001\"}'\n",
      "- {\"component\": {\"name\": \"ALU\", \"bits\": 128}, \"bits\": \"1\"}\n",
      "?                                        ^^\n",
      "+ {\"component\": {\"name\": \"ALU\", \"bits\": \"10000000\"}, \"bits\": \"00000001\"}\n",
      "?                                       + ^^^^^^^^            +++++++\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.001s\n",
      "\n",
      "FAILED (failures=2)\n",
      "\n",
      "Process completed with return code: 1\n",
      "253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 96/214 [00:13<00:13,  8.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.001s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "255\n",
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.010s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 98/214 [00:13<00:15,  7.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n",
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 100/214 [00:14<00:13,  8.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "...FF\n",
      "======================================================================\n",
      "FAIL: test_case_4_valid_utf16 (__main__.TestExtractCharacterBits)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 41, in test_case_4_valid_utf16\n",
      "    self.assertEqual(result, expected_result)\n",
      "AssertionError: None != (12, '00100001 00000000')\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_case_5_special_characters_utf8 (__main__.TestExtractCharacterBits)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 48, in test_case_5_special_characters_utf8\n",
      "    self.assertEqual(result, expected_result)\n",
      "AssertionError: Tuples differ: (7, '11110000100111111001000010001101') != (7, '11110000 10011111 10010000 10001101')\n",
      "\n",
      "First differing element 1:\n",
      "'11110000100111111001000010001101'\n",
      "'11110000 10011111 10010000 10001101'\n",
      "\n",
      "- (7, '11110000100111111001000010001101')\n",
      "+ (7, '11110000 10011111 10010000 10001101')\n",
      "?              +        +        +\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.001s\n",
      "\n",
      "FAILED (failures=2)\n",
      "\n",
      "Process completed with return code: 1\n",
      "259\n",
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 102/214 [00:14<00:19,  5.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "..E.\n",
      "======================================================================\n",
      "ERROR: test_case_4 (__main__.TestProcessCSV)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 101, in test_case_4\n",
      "    output = self.process_data(self.input_data_4)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 78, in process_data\n",
      "    process_csv(input_file_path, output_file_path)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 13, in process_csv\n",
      "    df = pd.read_csv(file_path)\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 912, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 577, in _read\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 1407, in __init__\n",
      "    self._engine = self._make_engine(f, self.engine)\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 1679, in _make_engine\n",
      "    return mapping[engine](f, **self.options)\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\", line 93, in __init__\n",
      "    self._reader = parsers.TextReader(src, **kwds)\n",
      "  File \"pandas\\_libs\\parsers.pyx\", line 557, in pandas._libs.parsers.TextReader.__cinit__\n",
      "pandas.errors.EmptyDataError: No columns to parse from file\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.029s\n",
      "\n",
      "FAILED (errors=1)\n",
      "\n",
      "Process completed with return code: 1\n",
      "262\n",
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 104/214 [00:14<00:16,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "264\n",
      "\n",
      "E..F\n",
      "======================================================================\n",
      "ERROR: test_empty_log_file (__main__.TestExtractLogEntries)\n",
      "Test behavior with an empty log file.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 67, in test_empty_log_file\n",
      "    with open(f\"{level.lower()}_logs.txt\", 'r') as file:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'warning_logs.txt'\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_no_logs_of_certain_levels (__main__.TestExtractLogEntries)\n",
      "Test the situation where there are no log entries for one or more levels.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 54, in test_no_logs_of_certain_levels\n",
      "    self.assertEqual('', file.read())\n",
      "AssertionError: '' != 'WARNING: Watch out!\\n'\n",
      "+ WARNING: Watch out!\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.025s\n",
      "\n",
      "FAILED (failures=1, errors=1)\n",
      "\n",
      "Process completed with return code: 1\n",
      "266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 106/214 [00:15<00:13,  7.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F.EFF\n",
      "======================================================================\n",
      "ERROR: test_list_of_mixed_data_types (__main__.TestHandleNestedData)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 37, in test_list_of_mixed_data_types\n",
      "    self.assertEqual(handle_nested_data(data), expected)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 17, in handle_nested_data\n",
      "    return {key: convert_value(value) for key, value in data.items()}\n",
      "AttributeError: 'list' object has no attribute 'items'\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_complex_nested_structure (__main__.TestHandleNestedData)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 57, in test_complex_nested_structure\n",
      "    self.assertEqual(handle_nested_data(data), expected)\n",
      "AssertionError: {'tea[31 chars]s': ['1000', '2000.2']}, {'name': 'Daisy', 'sk[38 chars]2'}]} != {'tea[31 chars]s': [1000, 2000.2]}, {'name': 'Daisy', 'skills[32 chars]22}]}\n",
      "- {'team': [{'name': 'Charlie', 'scores': ['1000', '2000.2']},\n",
      "?                                          -    -  -      -\n",
      "\n",
      "+ {'team': [{'name': 'Charlie', 'scores': [1000, 2000.2]},\n",
      "-           {'age': '22', 'name': 'Daisy', 'skills': ['Coding', 'Design']}]}\n",
      "?                   -  -\n",
      "\n",
      "+           {'age': 22, 'name': 'Daisy', 'skills': ['Coding', 'Design']}]}\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_nested_dictionary (__main__.TestHandleNestedData)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 32, in test_nested_dictionary\n",
      "    self.assertEqual(handle_nested_data(data), expected)\n",
      "AssertionError: {'user': {'name': 'Bob', 'details': {'age': '25', 'height': '175.5'}}} != {'user': {'name': 'Bob', 'details': {'age': 25, 'height': 175.5}}}\n",
      "- {'user': {'details': {'age': '25', 'height': '175.5'}, 'name': 'Bob'}}\n",
      "?                              -  -            -     -\n",
      "\n",
      "+ {'user': {'details': {'age': 25, 'height': 175.5}, 'name': 'Bob'}}\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_simple_dictionary (__main__.TestHandleNestedData)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 27, in test_simple_dictionary\n",
      "    self.assertEqual(handle_nested_data(data), expected)\n",
      "AssertionError: {'name': 'Alice', 'age': '30'} != {'name': 'Alice', 'age': 30}\n",
      "- {'age': '30', 'name': 'Alice'}\n",
      "?         -  -\n",
      "\n",
      "+ {'age': 30, 'name': 'Alice'}\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.001s\n",
      "\n",
      "FAILED (failures=3, errors=1)\n",
      "\n",
      "Process completed with return code: 1\n",
      "267\n",
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 108/214 [00:15<00:12,  8.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "269\n",
      "\n",
      "...\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "281\n",
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 111/214 [00:15<00:11,  9.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282\n",
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "286\n",
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 112/214 [00:15<00:11,  9.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288\n",
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 114/214 [00:16<00:11,  8.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FF.FF\n",
      "======================================================================\n",
      "FAIL: test_basic_conversion (__main__.TestRDFJSONLDToNGSILDConversion)\n",
      "Test a basic and correct conversion from JSON-LD to NGSI-LD.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 56, in test_basic_conversion\n",
      "    self.assertEqual(result, expected_ngsild)\n",
      "AssertionError: {'@context': 'http://schema.org/'} != {'id': 'urn:ngsi-ld:Vehicle:A123', 'type': [137 chars]'}}]}\n",
      "- {'@context': 'http://schema.org/'}\n",
      "?                                  ^\n",
      "\n",
      "+ {'@context': 'http://schema.org/',\n",
      "?                                  ^\n",
      "\n",
      "+  'attributes': [{'name': 'speed',\n",
      "+                  'type': 'Property',\n",
      "+                  'value': {'unitCode': 'KMH', 'value': 60}}],\n",
      "+  'id': 'urn:ngsi-ld:Vehicle:A123',\n",
      "+  'type': 'Vehicle'}\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_empty_jsonld (__main__.TestRDFJSONLDToNGSILDConversion)\n",
      "Test the conversion of an empty JSON-LD document.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 110, in test_empty_jsonld\n",
      "    self.assertEqual(result, expected_ngsild)\n",
      "AssertionError: {} != {'id': 'urn:ngsi-ld:unknown:id', 'type': '[82 chars]: []}\n",
      "- {}\n",
      "+ {'@context': 'https://schema.lab.fiware.org/ld/context',\n",
      "+  'attributes': [],\n",
      "+  'id': 'urn:ngsi-ld:unknown:id',\n",
      "+  'type': 'UnknownType'}\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_missing_id_and_type (__main__.TestRDFJSONLDToNGSILDConversion)\n",
      "Test conversion when @id and @type are missing.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 73, in test_missing_id_and_type\n",
      "    self.assertEqual(result, expected_ngsild)\n",
      "AssertionError: {'@context': 'http://schema.org/'} != {'id': 'urn:ngsi-ld:unknown:id', 'type': 'U[139 chars]'}}]}\n",
      "- {'@context': 'http://schema.org/'}\n",
      "?                                  ^\n",
      "\n",
      "+ {'@context': 'http://schema.org/',\n",
      "?                                  ^\n",
      "\n",
      "+  'attributes': [{'name': 'speed',\n",
      "+                  'type': 'Property',\n",
      "+                  'value': {'unitCode': 'KMH', 'value': 60}}],\n",
      "+  'id': 'urn:ngsi-ld:unknown:id',\n",
      "+  'type': 'UnknownType'}\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_with_nested_objects (__main__.TestRDFJSONLDToNGSILDConversion)\n",
      "Test conversion with nested objects.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 92, in test_with_nested_objects\n",
      "    self.assertEqual(result, expected_ngsild)\n",
      "AssertionError: {'@context': 'http://schema.org/'} != {'id': 'urn:ngsi-ld:Vehicle:A123', 'type': [150 chars]2}}]}\n",
      "- {'@context': 'http://schema.org/'}\n",
      "?                                  ^\n",
      "\n",
      "+ {'@context': 'http://schema.org/',\n",
      "?                                  ^\n",
      "\n",
      "+  'attributes': [{'name': 'location',\n",
      "+                  'type': 'Property',\n",
      "+                  'value': {'latitude': 48.8566, 'longitude': 2.3522}}],\n",
      "+  'id': 'urn:ngsi-ld:Vehicle:A123',\n",
      "+  'type': 'Vehicle'}\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.001s\n",
      "\n",
      "FAILED (failures=4)\n",
      "\n",
      "Process completed with return code: 1\n",
      "291\n",
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.019s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 116/214 [00:16<00:16,  5.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.174s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "369\n",
      "\n",
      "FE.\n",
      "======================================================================\n",
      "ERROR: test_no_solution_scenario (__main__.TestEightQueens)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 67, in test_no_solution_scenario\n",
      "    no_solution_queens()\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 63, in no_solution_queens\n",
      "    if not solve_queens(board, 0):\n",
      "NameError: name 'solve_queens' is not defined\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_correct_number_of_queens (__main__.TestEightQueens)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 54, in test_correct_number_of_queens\n",
      "    self.assertEqual(num_queens, 8, \"Each board should contain exactly 8 queens.\")\n",
      "AssertionError: 736 != 8 : Each board should contain exactly 8 queens.\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.018s\n",
      "\n",
      "FAILED (failures=1, errors=1)\n",
      "\n",
      "Process completed with return code: 1\n",
      "370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 118/214 [00:16<00:13,  7.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "380\n",
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 120/214 [00:16<00:12,  7.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "386\n",
      "\n",
      "...\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.026s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 122/214 [00:17<00:10,  8.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "392\n",
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 124/214 [00:17<00:11,  8.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EEEE\n",
      "======================================================================\n",
      "ERROR: test_convergence_to_minimum (__main__.TestGradientDescentEuclidean)\n",
      "Test that gradient descent converges to the minimum of f(x) = (x-3)^2\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 28, in test_convergence_to_minimum\n",
      "    path = gradient_descent_euclidean(start, learning_rate, n_steps, grad_f)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 5, in gradient_descent_euclidean\n",
      "    path = np.zeros((n_steps + 1, *start.shape))\n",
      "AttributeError: 'float' object has no attribute 'shape'\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_large_learning_rate (__main__.TestGradientDescentEuclidean)\n",
      "Test with a large learning rate, which may overshoot the minimum.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 58, in test_large_learning_rate\n",
      "    path = gradient_descent_euclidean(start, learning_rate, n_steps, grad_f)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 5, in gradient_descent_euclidean\n",
      "    path = np.zeros((n_steps + 1, *start.shape))\n",
      "AttributeError: 'float' object has no attribute 'shape'\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_no_steps (__main__.TestGradientDescentEuclidean)\n",
      "Test the case where no steps are taken.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 43, in test_no_steps\n",
      "    path = gradient_descent_euclidean(start, learning_rate, n_steps, grad_f)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 5, in gradient_descent_euclidean\n",
      "    path = np.zeros((n_steps + 1, *start.shape))\n",
      "AttributeError: 'float' object has no attribute 'shape'\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_path_length (__main__.TestGradientDescentEuclidean)\n",
      "Test that the path length is correct.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 74, in test_path_length\n",
      "    path = gradient_descent_euclidean(start, learning_rate, n_steps, grad_f)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 5, in gradient_descent_euclidean\n",
      "    path = np.zeros((n_steps + 1, *start.shape))\n",
      "AttributeError: 'float' object has no attribute 'shape'\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.000s\n",
      "\n",
      "FAILED (errors=4)\n",
      "\n",
      "Process completed with return code: 1\n",
      "395\n",
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "396\n",
      "\n",
      ".......\n",
      "----------------------------------------------------------------------\n",
      "Ran 7 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 126/214 [00:17<00:10,  8.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398\n",
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.033s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 128/214 [00:17<00:09,  8.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "404\n",
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 130/214 [00:18<00:09,  8.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "......\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "406\n",
      "\n",
      "FFFFFF\n",
      "======================================================================\n",
      "FAIL: test_blue (__main__.TestColors)\n",
      "Test blue color method\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 40, in test_blue\n",
      "    self.assertEqual(Colors.blue(\"Hello\"), \"\\033[34mHello\\033[0m\")\n",
      "AssertionError: '\\x1b[94mHello\\x1b[0m' != '\\x1b[34mHello\\x1b[0m'\n",
      "- \u001B[94mHello\u001B[0m\n",
      "?   ^\n",
      "+ \u001B[34mHello\u001B[0m\n",
      "?   ^\n",
      "\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_cyan (__main__.TestColors)\n",
      "Test cyan color method\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 52, in test_cyan\n",
      "    self.assertEqual(Colors.cyan(\"Hello\"), \"\\033[36mHello\\033[0m\")\n",
      "AssertionError: '\\x1b[96mHello\\x1b[0m' != '\\x1b[36mHello\\x1b[0m'\n",
      "- \u001B[96mHello\u001B[0m\n",
      "?   ^\n",
      "+ \u001B[36mHello\u001B[0m\n",
      "?   ^\n",
      "\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_green (__main__.TestColors)\n",
      "Test green color method\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 36, in test_green\n",
      "    self.assertEqual(Colors.green(\"Hello\"), \"\\033[32mHello\\033[0m\")\n",
      "AssertionError: '\\x1b[92mHello\\x1b[0m' != '\\x1b[32mHello\\x1b[0m'\n",
      "- \u001B[92mHello\u001B[0m\n",
      "?   ^\n",
      "+ \u001B[32mHello\u001B[0m\n",
      "?   ^\n",
      "\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_magenta (__main__.TestColors)\n",
      "Test magenta color method\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 48, in test_magenta\n",
      "    self.assertEqual(Colors.magenta(\"Hello\"), \"\\033[35mHello\\033[0m\")\n",
      "AssertionError: '\\x1b[95mHello\\x1b[0m' != '\\x1b[35mHello\\x1b[0m'\n",
      "- \u001B[95mHello\u001B[0m\n",
      "?   ^\n",
      "+ \u001B[35mHello\u001B[0m\n",
      "?   ^\n",
      "\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_red (__main__.TestColors)\n",
      "Test red color method\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 32, in test_red\n",
      "    self.assertEqual(Colors.red(\"Hello\"), \"\\033[31mHello\\033[0m\")\n",
      "AssertionError: '\\x1b[91mHello\\x1b[0m' != '\\x1b[31mHello\\x1b[0m'\n",
      "- \u001B[91mHello\u001B[0m\n",
      "?   ^\n",
      "+ \u001B[31mHello\u001B[0m\n",
      "?   ^\n",
      "\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_yellow (__main__.TestColors)\n",
      "Test yellow color method\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 44, in test_yellow\n",
      "    self.assertEqual(Colors.yellow(\"Hello\"), \"\\033[33mHello\\033[0m\")\n",
      "AssertionError: '\\x1b[93mHello\\x1b[0m' != '\\x1b[33mHello\\x1b[0m'\n",
      "- \u001B[93mHello\u001B[0m\n",
      "?   ^\n",
      "+ \u001B[33mHello\u001B[0m\n",
      "?   ^\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 0.001s\n",
      "\n",
      "FAILED (failures=6)\n",
      "\n",
      "Process completed with return code: 1\n",
      "410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 133/214 [00:18<00:07, 10.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".F..F\n",
      "======================================================================\n",
      "FAIL: test_edge_case_with_zero (__main__.TestCheckXorSum)\n",
      "Test with a combination where all values are zero.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 41, in test_edge_case_with_zero\n",
      "    self.assertFalse(check_xor_sum(combination))\n",
      "AssertionError: True is not false\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_multiple_rows (__main__.TestCheckXorSum)\n",
      "Test with a combination that contains multiple rows.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 58, in test_multiple_rows\n",
      "    self.assertTrue(check_xor_sum(combination))\n",
      "AssertionError: False is not true\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "FAILED (failures=2)\n",
      "\n",
      "Process completed with return code: 1\n",
      "412\n",
      "413\n",
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 135/214 [00:18<00:07,  9.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "..FFF\n",
      "======================================================================\n",
      "FAIL: test_missing_fields (__main__.TestExtractBibInfo)\n",
      "Test extraction when some fields are missing.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 74, in test_missing_fields\n",
      "    self.assertEqual(result, expected)\n",
      "AssertionError: Lists differ: [{'title': None, 'author': 'John Doe', 'year': None}] != [{'title': 'Title Missing Year', 'author': 'John Doe', 'year': None}]\n",
      "\n",
      "First differing element 0:\n",
      "{'title': None, 'author': 'John Doe', 'year': None}\n",
      "{'title': 'Title Missing Year', 'author': 'John Doe', 'year': None}\n",
      "\n",
      "- [{'author': 'John Doe', 'title': None, 'year': None}]\n",
      "?                                  ^^\n",
      "\n",
      "+ [{'author': 'John Doe', 'title': 'Title Missing Year', 'year': None}]\n",
      "?                                  ^^^^^^^^^^^^ +++ +++\n",
      "\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_multiple_entries (__main__.TestExtractBibInfo)\n",
      "Test extraction from multiple BibTeX entries.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 66, in test_multiple_entries\n",
      "    self.assertEqual(result, expected)\n",
      "AssertionError: Lists differ: [{'title': None, 'author': 'John Doe', 'year': None}[51 chars]one}] != [{'title': 'A Comprehensive Study on AI', 'author': [102 chars]23'}]\n",
      "\n",
      "First differing element 0:\n",
      "{'title': None, 'author': 'John Doe', 'year': None}\n",
      "{'title': 'A Comprehensive Study on AI', 'author': 'John Doe', 'year': '2024'}\n",
      "\n",
      "- [{'author': 'John Doe', 'title': None, 'year': None},\n",
      "-  {'author': 'Jane Smith', 'title': None, 'year': None}]\n",
      "+ [{'author': 'John Doe', 'title': 'A Comprehensive Study on AI', 'year': '2024'},\n",
      "+  {'author': 'Jane Smith', 'title': 'Deep Learning Techniques', 'year': '2023'}]\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_valid_entry (__main__.TestExtractBibInfo)\n",
      "Test extraction from a valid BibTeX entry.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 46, in test_valid_entry\n",
      "    self.assertEqual(result, expected)\n",
      "AssertionError: Lists differ: [{'title': None, 'author': 'John Doe and Jane Smith', 'year': None}] != [{'title': 'A Comprehensive Study on AI', 'author': [38 chars]24'}]\n",
      "\n",
      "First differing element 0:\n",
      "{'title': None, 'author': 'John Doe and Jane Smith', 'year': None}\n",
      "{'title': 'A Comprehensive Study on AI', 'author': [37 chars]024'}\n",
      "\n",
      "- [{'author': 'John Doe and Jane Smith', 'title': None, 'year': None}]\n",
      "+ [{'author': 'John Doe and Jane Smith',\n",
      "+   'title': 'A Comprehensive Study on AI',\n",
      "+   'year': '2024'}]\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.011s\n",
      "\n",
      "FAILED (failures=3)\n",
      "\n",
      "Process completed with return code: 1\n",
      "418\n",
      "\n",
      "...\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "420\n",
      "423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 137/214 [00:18<00:06, 11.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FF..\n",
      "======================================================================\n",
      "FAIL: test_write_duplicate_line (__main__.TestWriteUniqueLineToFile)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 43, in test_write_duplicate_line\n",
      "    self.assertEqual(file.read().strip().count(line_content), 1)\n",
      "AssertionError: 2 != 1\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_write_empty_line (__main__.TestWriteUniqueLineToFile)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 60, in test_write_empty_line\n",
      "    self.assertEqual(file.read(), \"\")\n",
      "AssertionError: '\\n' != ''\n",
      "- \n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.020s\n",
      "\n",
      "FAILED (failures=2)\n",
      "\n",
      "Process completed with return code: 1\n",
      "424\n",
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 139/214 [00:18<00:07, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "E\n",
      "======================================================================\n",
      "ERROR: test_sequences (__main__.TestCheckSequences)\n",
      "Test the sequences for Munodi property.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 43, in test_sequences\n",
      "    results = check_sequences(self.test_file)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 16, in check_sequences\n",
      "    sequence = list(map(int, line.strip().split()))\n",
      "ValueError: invalid literal for int() with base 10: '2,4,6,8'\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.006s\n",
      "\n",
      "FAILED (errors=1)\n",
      "\n",
      "Process completed with return code: 1\n",
      "428\n",
      "\n",
      ".FFFF\n",
      "======================================================================\n",
      "FAIL: test_complex_type (__main__.TestParseTypeHint)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 54, in test_complex_type\n",
      "    self.assertEqual(parse_type_hint(type_hint), expected)\n",
      "AssertionError: Lists differ: ['List'] != ['List', 'Union', 'int', 'float', 'Tuple', 'str', 'int']\n",
      "\n",
      "Second list contains 6 additional elements.\n",
      "First extra element 1:\n",
      "'Union'\n",
      "\n",
      "- ['List']\n",
      "+ ['List', 'Union', 'int', 'float', 'Tuple', 'str', 'int']\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_list_type (__main__.TestParseTypeHint)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 39, in test_list_type\n",
      "    self.assertEqual(parse_type_hint(type_hint), expected)\n",
      "AssertionError: Lists differ: ['List'] != ['List', 'int']\n",
      "\n",
      "Second list contains 1 additional elements.\n",
      "First extra element 1:\n",
      "'int'\n",
      "\n",
      "- ['List']\n",
      "+ ['List', 'int']\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_tuple_type (__main__.TestParseTypeHint)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 49, in test_tuple_type\n",
      "    self.assertEqual(parse_type_hint(type_hint), expected)\n",
      "AssertionError: Lists differ: ['Tuple'] != ['Tuple', 'str', 'int', 'float']\n",
      "\n",
      "Second list contains 3 additional elements.\n",
      "First extra element 1:\n",
      "'str'\n",
      "\n",
      "- ['Tuple']\n",
      "+ ['Tuple', 'str', 'int', 'float']\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_union_type (__main__.TestParseTypeHint)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 44, in test_union_type\n",
      "    self.assertEqual(parse_type_hint(type_hint), expected)\n",
      "AssertionError: Lists differ: ['Union'] != ['Union', 'str', 'float']\n",
      "\n",
      "Second list contains 2 additional elements.\n",
      "First extra element 1:\n",
      "'str'\n",
      "\n",
      "- ['Union']\n",
      "+ ['Union', 'str', 'float']\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.001s\n",
      "\n",
      "FAILED (failures=4)\n",
      "\n",
      "Process completed with return code: 1\n",
      "430\n",
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 143/214 [00:19<00:07, 10.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "431\n",
      "\n",
      ".FF..\n",
      "======================================================================\n",
      "FAIL: test_case2 (__main__.TestIntersectHorizontally)\n",
      "Test with rectangles touching at a point (not overlapping).\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 32, in test_case2\n",
      "    self.assertTrue(intersect_horizontally(rect1, rect2))\n",
      "AssertionError: False is not true\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_case3 (__main__.TestIntersectHorizontally)\n",
      "Test with adjacent rectangles (no overlap).\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 38, in test_case3\n",
      "    self.assertTrue(intersect_horizontally(rect1, rect2))\n",
      "AssertionError: False is not true\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "FAILED (failures=2)\n",
      "\n",
      "Process completed with return code: 1\n",
      "433\n",
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "434\n",
      "\n",
      "F....\n",
      "======================================================================\n",
      "FAIL: test_case_1 (__main__.TestGetMaxPeople)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 31, in test_case_1\n",
      "    self.assertEqual(get_max_people(people, status), expected)\n",
      "AssertionError: 2 != 1\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.001s\n",
      "\n",
      "FAILED (failures=1)\n",
      "\n",
      "Process completed with return code: 1\n",
      "438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 146/214 [00:19<00:09,  7.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "E.\n",
      "======================================================================\n",
      "ERROR: test_read_another_valid_csv (__main__.TestReadCsvToDataFrame)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 54, in test_read_another_valid_csv\n",
      "    df = read_csv_to_dataframe(self.test_files['another_valid_csv'])\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 13, in read_csv_to_dataframe\n",
      "    return pd.read_csv(file_path)\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 912, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 577, in _read\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 1407, in __init__\n",
      "    self._engine = self._make_engine(f, self.engine)\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 1661, in _make_engine\n",
      "    self.handles = get_handle(\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\pandas\\io\\common.py\", line 859, in get_handle\n",
      "    handle = open(\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'test_another_valid.csv'\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.008s\n",
      "\n",
      "FAILED (errors=1)\n",
      "\n",
      "Process completed with return code: 1\n",
      "442\n",
      "\n",
      ".FFEE\n",
      "======================================================================\n",
      "ERROR: test_mixed_structure (__main__.TestConvertStringsToNumbers)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 42, in test_mixed_structure\n",
      "    self.assertEqual(convert_strings_to_numbers(data), expected)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 14, in convert_strings_to_numbers\n",
      "    return {key: convert_strings_to_numbers(convert(value)) for key, value in data.items()}\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 14, in <dictcomp>\n",
      "    return {key: convert_strings_to_numbers(convert(value)) for key, value in data.items()}\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 6, in convert\n",
      "    return int(value)\n",
      "TypeError: int() argument must be a string, a bytes-like object or a number, not 'list'\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_nested_dict (__main__.TestConvertStringsToNumbers)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 32, in test_nested_dict\n",
      "    self.assertEqual(convert_strings_to_numbers(data), expected)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 14, in convert_strings_to_numbers\n",
      "    return {key: convert_strings_to_numbers(convert(value)) for key, value in data.items()}\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 14, in <dictcomp>\n",
      "    return {key: convert_strings_to_numbers(convert(value)) for key, value in data.items()}\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 6, in convert\n",
      "    return int(value)\n",
      "TypeError: int() argument must be a string, a bytes-like object or a number, not 'dict'\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_flat_dict (__main__.TestConvertStringsToNumbers)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 27, in test_flat_dict\n",
      "    self.assertEqual(convert_strings_to_numbers(data), expected)\n",
      "AssertionError: {'a': 1, 'b': 2, 'c': 'not a number'} != {'a': 1, 'b': 2.5, 'c': 'not a number'}\n",
      "- {'a': 1, 'b': 2, 'c': 'not a number'}\n",
      "+ {'a': 1, 'b': 2.5, 'c': 'not a number'}\n",
      "?                ++\n",
      "\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_list_of_strings (__main__.TestConvertStringsToNumbers)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 37, in test_list_of_strings\n",
      "    self.assertEqual(convert_strings_to_numbers(data), expected)\n",
      "AssertionError: Lists differ: [1, 2, 3, 'invalid'] != [1, 2.5, 3, 'invalid']\n",
      "\n",
      "First differing element 1:\n",
      "2\n",
      "2.5\n",
      "\n",
      "- [1, 2, 3, 'invalid']\n",
      "+ [1, 2.5, 3, 'invalid']\n",
      "?      ++\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.001s\n",
      "\n",
      "FAILED (failures=2, errors=2)\n",
      "\n",
      "Process completed with return code: 1\n",
      "443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 148/214 [00:20<00:08,  7.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "444\n",
      "\n",
      ".F.F.\n",
      "======================================================================\n",
      "FAIL: test_exact_max_length (__main__.TestFormatComment)\n",
      "Test with a line that is exactly max_length characters long\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 60, in test_exact_max_length\n",
      "    self.assertEqual(format_comment(input_string, max_length=60), expected_output)\n",
      "AssertionError: '# \\n# AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA' != '# AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA'\n",
      "- # \n",
      "  # AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_multiple_lines (__main__.TestFormatComment)\n",
      "Test with multiple lines of input\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 54, in test_multiple_lines\n",
      "    self.assertEqual(format_comment(input_string, max_length=60), expected_output)\n",
      "AssertionError: '# First line. Second line that is quite long and needs to be\\n# wrapped.' != '# First line.\\n# Second line that is quite long and needs to be wrapped.'\n",
      "+ # First line.\n",
      "- # First line. Second line that is quite long and needs to be\n",
      "?  ------------                                               ^\n",
      "+ # Second line that is quite long and needs to be wrapped.?                                                 ^^^^^^^^^\n",
      "- # wrapped.\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.001s\n",
      "\n",
      "FAILED (failures=2)\n",
      "\n",
      "Process completed with return code: 1\n",
      "445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 149/214 [00:20<00:09,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.001s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 151/214 [00:20<00:09,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.030s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "460\n",
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "461\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 1, in <module>\n",
      "    def average_of_levels(root: Optional[TreeNode]) -> List[float]:\n",
      "NameError: name 'Optional' is not defined\n",
      "\n",
      "Process completed with return code: 1\n",
      "462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 154/214 [00:21<00:07,  7.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "463\n",
      "\n",
      "E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py:87: ResourceWarning: unclosed file <_io.BufferedRandom name=3>\n",
      "  output_file_path = tempfile.NamedTemporaryFile(delete=False).name\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      ".E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py:70: ResourceWarning: unclosed file <_io.BufferedRandom name=3>\n",
      "  output_file_path = tempfile.NamedTemporaryFile(delete=False).name\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      ".E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py:121: ResourceWarning: unclosed file <_io.BufferedRandom name=3>\n",
      "  output_file_path = tempfile.NamedTemporaryFile(delete=False).name\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      ".E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py:102: ResourceWarning: unclosed file <_io.BufferedRandom name=3>\n",
      "  output_file_path = tempfile.NamedTemporaryFile(delete=False).name\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      ".E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py:54: ResourceWarning: unclosed file <_io.BufferedRandom name=3>\n",
      "  output_file_path = tempfile.NamedTemporaryFile(delete=False).name\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.035s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 155/214 [00:21<00:08,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.006s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "468\n",
      "\n",
      "...\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.005s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 157/214 [00:21<00:08,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469\n",
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 159/214 [00:21<00:09,  5.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F.FF\n",
      "======================================================================\n",
      "FAIL: test_high_shear_factor (__main__.TestShearTransformation)\n",
      "Test with a high shear factor to see how the matrix adapts to extreme transformations.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 58, in test_high_shear_factor\n",
      "    np.testing.assert_array_equal(result, expected_output, \"The matrix should be correctly sheared with a high shear factor.\")\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\numpy\\testing\\_private\\utils.py\", line 985, in assert_array_equal\n",
      "    assert_array_compare(operator.__eq__, x, y, err_msg=err_msg,\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\contextlib.py\", line 75, in inner\n",
      "    return func(*args, **kwds)\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\numpy\\testing\\_private\\utils.py\", line 862, in assert_array_compare\n",
      "    raise AssertionError(msg)\n",
      "AssertionError: \n",
      "Arrays are not equal\n",
      "The matrix should be correctly sheared with a high shear factor.\n",
      "Mismatched elements: 3 / 4 (75%)\n",
      "Max absolute difference: 11.\n",
      "Max relative difference: 1.\n",
      " x: array([[1., 1.],\n",
      "       [0., 0.]])\n",
      " y: array([[ 1, 11],\n",
      "       [ 1, 11]])\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_negative_shear (__main__.TestShearTransformation)\n",
      "Test with a negative shear factor.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 49, in test_negative_shear\n",
      "    np.testing.assert_array_equal(result, expected_output, \"The matrix should be correctly sheared negatively.\")\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\numpy\\testing\\_private\\utils.py\", line 985, in assert_array_equal\n",
      "    assert_array_compare(operator.__eq__, x, y, err_msg=err_msg,\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\contextlib.py\", line 75, in inner\n",
      "    return func(*args, **kwds)\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\numpy\\testing\\_private\\utils.py\", line 862, in assert_array_compare\n",
      "    raise AssertionError(msg)\n",
      "AssertionError: \n",
      "Arrays are not equal\n",
      "The matrix should be correctly sheared negatively.\n",
      "Mismatched elements: 3 / 4 (75%)\n",
      "Max absolute difference: 2.\n",
      "Max relative difference: 2.\n",
      " x: array([[1., 2.],\n",
      "       [4., 3.]])\n",
      " y: array([[1, 1],\n",
      "       [3, 1]])\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_positive_shear (__main__.TestShearTransformation)\n",
      "Test with a positive shear factor.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 41, in test_positive_shear\n",
      "    np.testing.assert_array_equal(result, expected_output, \"The matrix should be correctly sheared.\")\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\numpy\\testing\\_private\\utils.py\", line 985, in assert_array_equal\n",
      "    assert_array_compare(operator.__eq__, x, y, err_msg=err_msg,\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\contextlib.py\", line 75, in inner\n",
      "    return func(*args, **kwds)\n",
      "  File \"D:\\sdk\\python\\venvs\\realisticeval\\lib\\site-packages\\numpy\\testing\\_private\\utils.py\", line 862, in assert_array_compare\n",
      "    raise AssertionError(msg)\n",
      "AssertionError: \n",
      "Arrays are not equal\n",
      "The matrix should be correctly sheared.\n",
      "Mismatched elements: 3 / 4 (75%)\n",
      "Max absolute difference: 4.\n",
      "Max relative difference: 1.\n",
      " x: array([[1., 2.],\n",
      "       [0., 3.]])\n",
      " y: array([[1, 3],\n",
      "       [3, 7]])\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.018s\n",
      "\n",
      "FAILED (failures=3)\n",
      "\n",
      "Process completed with return code: 1\n",
      "471\n",
      "\n",
      "...F.\n",
      "======================================================================\n",
      "FAIL: test_rotation_invalid_matrix (__main__.TestGetRotationFunction)\n",
      "Test for an invalid matrix input\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 56, in test_rotation_invalid_matrix\n",
      "    get_rotation(invalid_matrix)\n",
      "AssertionError: ValueError not raised\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "FAILED (failures=1)\n",
      "\n",
      "Process completed with return code: 1\n",
      "473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 161/214 [00:22<00:07,  7.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "474\n",
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 163/214 [00:22<00:06,  8.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "476\n",
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 166/214 [00:22<00:04,  9.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "......\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "478\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 3, in <module>\n",
      "    def class_to_dict(obj: Any) -> Dict[str, Any]:\n",
      "NameError: name 'Any' is not defined\n",
      "\n",
      "Process completed with return code: 1\n",
      "482\n",
      "\n",
      "FF.F.\n",
      "======================================================================\n",
      "FAIL: test_mixed_bracket_types (__main__.TestExtractOutermostBrackets)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 30, in test_mixed_bracket_types\n",
      "    self.assertEqual(extract_outermost_brackets(\"Mixed (types {of brackets [in use]})\"), \"types {of brackets [in use]}\")\n",
      "AssertionError: 'in use' != 'types {of brackets [in use]}'\n",
      "- in use\n",
      "+ types {of brackets [in use]}\n",
      "\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_nested_brackets (__main__.TestExtractOutermostBrackets)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 24, in test_nested_brackets\n",
      "    self.assertEqual(extract_outermost_brackets(\"Text {with some {nested} brackets}\"), \"with some {nested} brackets\")\n",
      "AssertionError: '' != 'with some {nested} brackets'\n",
      "+ with some {nested} brackets\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_single_parentheses (__main__.TestExtractOutermostBrackets)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 21, in test_single_parentheses\n",
      "    self.assertEqual(extract_outermost_brackets(\"Text (example) more text\"), \"example\")\n",
      "AssertionError: '' != 'example'\n",
      "+ example\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "FAILED (failures=3)\n",
      "\n",
      "Process completed with return code: 1\n",
      "483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 168/214 [00:22<00:04,  9.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".......\n",
      "----------------------------------------------------------------------\n",
      "Ran 7 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "485\n",
      "\n",
      "EF...\n",
      "======================================================================\n",
      "ERROR: test_missing_parameters (__main__.TestPrepareQuery)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 48, in test_missing_parameters\n",
      "    new_sql, value_list = prepare_query(sql_query, parameters)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 18, in prepare_query\n",
      "    modified_sql = pattern.sub(replace_param, sql)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 16, in replace_param\n",
      "    raise ValueError(f\"Parameter '{param_name}' not found in params.\")\n",
      "ValueError: Parameter 'status' not found in params.\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_multiple_same_parameters (__main__.TestPrepareQuery)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 71, in test_multiple_same_parameters\n",
      "    self.assertEqual(new_sql, expected_sql)\n",
      "AssertionError: 'SELECT * FROM users WHERE id = $1 AND status = $2' != 'SELECT * FROM users WHERE id = $1 AND status = $1'\n",
      "- SELECT * FROM users WHERE id = $1 AND status = $2\n",
      "?                                                 ^\n",
      "+ SELECT * FROM users WHERE id = $1 AND status = $1\n",
      "?                                                 ^\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.001s\n",
      "\n",
      "FAILED (failures=1, errors=1)\n",
      "\n",
      "Process completed with return code: 1\n",
      "486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 170/214 [00:23<00:04,  9.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "..F..\n",
      "======================================================================\n",
      "FAIL: test_divide_by_zero (__main__.TestCalculator)\n",
      "Test division by zero raises ValueError.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 48, in test_divide_by_zero\n",
      "    self.assertEqual(str(context.exception), \"Cannot divide by zero.\")\n",
      "AssertionError: 'Division by zero is not allowed.' != 'Cannot divide by zero.'\n",
      "- Division by zero is not allowed.\n",
      "+ Cannot divide by zero.\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "FAILED (failures=1)\n",
      "\n",
      "Process completed with return code: 1\n",
      "487\n",
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 173/214 [00:23<00:04,  9.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".FF.E\n",
      "======================================================================\n",
      "ERROR: test_unexpected_error (__main__.TestGetLocalIP)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 1342, in patched\n",
      "    return func(*newargs, **newkeywargs)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 57, in test_unexpected_error\n",
      "    result = get_local_ip()\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 7, in get_local_ip\n",
      "    output = subprocess.check_output(f'ipconfig', shell=True, text=True)\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\subprocess.py\", line 411, in check_output\n",
      "    return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 1075, in __call__\n",
      "    return self._mock_call(*args, **kwargs)\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 1079, in _mock_call\n",
      "    return self._execute_mock_call(*args, **kwargs)\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 1134, in _execute_mock_call\n",
      "    raise effect\n",
      "Exception: Unexpected error\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_local_ip_found (__main__.TestGetLocalIP)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 1342, in patched\n",
      "    return func(*newargs, **newkeywargs)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 29, in test_local_ip_found\n",
      "    self.assertEqual(result, '192.168.1.10')\n",
      "AssertionError: None != '192.168.1.10'\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_multiple_ips_found (__main__.TestGetLocalIP)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 1342, in patched\n",
      "    return func(*newargs, **newkeywargs)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 44, in test_multiple_ips_found\n",
      "    self.assertEqual(result, '192.168.1.10')\n",
      "AssertionError: None != '192.168.1.10'\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.017s\n",
      "\n",
      "FAILED (failures=2, errors=1)\n",
      "\n",
      "Process completed with return code: 1\n",
      "490\n",
      "\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 25\n",
      "    if stripped_line.startswith(\"\n",
      "                                ^\n",
      "SyntaxError: EOL while scanning string literal\n",
      "\n",
      "Process completed with return code: 1\n",
      "492\n",
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.008s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 174/214 [00:23<00:04,  9.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "...FF.\n",
      "======================================================================\n",
      "FAIL: test_multi_line_content (__main__.TestWrapContentGenerator)\n",
      "Test with multiple lines of content each fitting within default width.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 35, in test_multi_line_content\n",
      "    self.assertEqual(result, [\"Hello\", \"World\", \"Python\"])\n",
      "AssertionError: Lists differ: ['Hello World Python'] != ['Hello', 'World', 'Python']\n",
      "\n",
      "First differing element 0:\n",
      "'Hello World Python'\n",
      "'Hello'\n",
      "\n",
      "Second list contains 2 additional elements.\n",
      "First extra element 1:\n",
      "'World'\n",
      "\n",
      "- ['Hello World Python']\n",
      "?        ^     ^\n",
      "\n",
      "+ ['Hello', 'World', 'Python']\n",
      "?        ^^^^     ^^^^\n",
      "\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_only_whitespaces (__main__.TestWrapContentGenerator)\n",
      "Test content that contains only whitespace characters.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 52, in test_only_whitespaces\n",
      "    self.assertEqual(result, [\"\\n\"])\n",
      "AssertionError: Lists differ: [] != ['\\n']\n",
      "\n",
      "Second list contains 1 additional elements.\n",
      "First extra element 0:\n",
      "'\\n'\n",
      "\n",
      "- []\n",
      "+ ['\\n']\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 0.001s\n",
      "\n",
      "FAILED (failures=2)\n",
      "\n",
      "Process completed with return code: 1\n",
      "494\n",
      "\n",
      ".F..\n",
      "======================================================================\n",
      "FAIL: test_none_and_nan (__main__.TestCleanDictionary)\n",
      "Test a dictionary with None and NaN values.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 43, in test_none_and_nan\n",
      "    self.assertEqual(clean_dictionary(input_dict), expected_output)\n",
      "AssertionError: {'key2': nan, 'key3': 'valid string'} != {'key3': 'valid string'}\n",
      "- {'key2': nan, 'key3': 'valid string'}\n",
      "?  -------------\n",
      "\n",
      "+ {'key3': 'valid string'}\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.000s\n",
      "\n",
      "FAILED (failures=1)\n",
      "\n",
      "Process completed with return code: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 176/214 [00:23<00:04,  8.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "495\n",
      "\n",
      "...\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 178/214 [00:24<00:04,  8.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "......\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "497\n",
      "\n",
      "FFFFF\n",
      "======================================================================\n",
      "FAIL: test_bigger_shape (__main__.TestBroadcastIndex)\n",
      "Test case where the big_shape is larger than the shape.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 65, in test_bigger_shape\n",
      "    self.assertEqual(out_index_big, [3], \"Failed to handle bigger shape case.\")\n",
      "AssertionError: Lists differ: [3, 0, 0] != [3]\n",
      "\n",
      "First list contains 2 additional elements.\n",
      "First extra element 1:\n",
      "0\n",
      "\n",
      "- [3, 0, 0]\n",
      "+ [3] : Failed to handle bigger shape case.\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_empty_shape (__main__.TestBroadcastIndex)\n",
      "Test case with an empty shape.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 56, in test_empty_shape\n",
      "    self.assertEqual(out_index_empty, [], \"Failed to handle empty shape.\")\n",
      "AssertionError: Lists differ: [0, 0, 0] != []\n",
      "\n",
      "First list contains 3 additional elements.\n",
      "First extra element 0:\n",
      "0\n",
      "\n",
      "- [0, 0, 0]\n",
      "+ [] : Failed to handle empty shape.\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_shape_with_multiple_ones (__main__.TestBroadcastIndex)\n",
      "Test case with multiple dimensions of size 1 in shape.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 72, in test_shape_with_multiple_ones\n",
      "    self.assertEqual(out_index_multiple_ones, [0, 2, 0], \"Failed to handle shape with multiple ones.\")\n",
      "AssertionError: Lists differ: [0, 2, 1] != [0, 2, 0]\n",
      "\n",
      "First differing element 2:\n",
      "1\n",
      "0\n",
      "\n",
      "- [0, 2, 1]\n",
      "?        ^\n",
      "\n",
      "+ [0, 2, 0]\n",
      "?        ^\n",
      " : Failed to handle shape with multiple ones.\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_shape_with_one_dimension (__main__.TestBroadcastIndex)\n",
      "Test case where shape contains a dimension of size 1.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 49, in test_shape_with_one_dimension\n",
      "    self.assertEqual(out_index_with_one, [0, 1], \"Failed to handle shape with one dimension.\")\n",
      "AssertionError: Lists differ: [2, 1, 0] != [0, 1]\n",
      "\n",
      "First differing element 0:\n",
      "2\n",
      "0\n",
      "\n",
      "First list contains 1 additional elements.\n",
      "First extra element 2:\n",
      "0\n",
      "\n",
      "- [2, 1, 0]\n",
      "+ [0, 1] : Failed to handle shape with one dimension.\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_standard_case (__main__.TestBroadcastIndex)\n",
      "Test standard broadcasting behavior.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 42, in test_standard_case\n",
      "    self.assertEqual(self.out_index, [2, 1], \"Failed to correctly broadcast standard case.\")\n",
      "AssertionError: Lists differ: [2, 1, 0] != [2, 1]\n",
      "\n",
      "First list contains 1 additional elements.\n",
      "First extra element 2:\n",
      "0\n",
      "\n",
      "- [2, 1, 0]\n",
      "?      ---\n",
      "\n",
      "+ [2, 1] : Failed to correctly broadcast standard case.\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.001s\n",
      "\n",
      "FAILED (failures=5)\n",
      "\n",
      "Process completed with return code: 1\n",
      "498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 180/214 [00:24<00:03,  8.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "499\n",
      "\n",
      "..FFF\n",
      "======================================================================\n",
      "FAIL: test_valid_float_weight (__main__.TestCleanPattern)\n",
      "Test case for valid float weight.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 29, in test_valid_float_weight\n",
      "    self.assertEqual(result, 15.75)\n",
      "AssertionError: '15.75 kg' != 15.75\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_valid_integer_weight (__main__.TestCleanPattern)\n",
      "Test case for valid integer weight.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 23, in test_valid_integer_weight\n",
      "    self.assertEqual(result, 25.0)\n",
      "AssertionError: '25 kg' != 25.0\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_weight_with_extra_text (__main__.TestCleanPattern)\n",
      "Test case for weight with additional text.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 47, in test_weight_with_extra_text\n",
      "    self.assertEqual(result, 45.3)\n",
      "AssertionError: '45.3 kg' != 45.3\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "FAILED (failures=3)\n",
      "\n",
      "Process completed with return code: 1\n",
      "500\n",
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 182/214 [00:24<00:03,  9.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "501\n",
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 184/214 [00:24<00:03,  9.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "506\n",
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "507\n",
      "\n",
      "......\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 187/214 [00:24<00:02,  9.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "510\n",
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "511\n",
      "\n",
      "..\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 189/214 [00:25<00:02,  9.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 191/214 [00:25<00:02,  9.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "514\n",
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 193/214 [00:25<00:02,  8.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.002s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "516\n",
      "\n",
      "...\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.006s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 195/214 [00:25<00:02,  8.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "...\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.007s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "518\n",
      "\n",
      "F....\n",
      "======================================================================\n",
      "FAIL: test_edge_cases (__main__.TestConvertCsvValues)\n",
      "Test edge cases with empty strings and negative numbers.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 49, in test_edge_cases\n",
      "    self.assertEqual(result, expected)\n",
      "AssertionError: {'value1': None, 'value2': '0.0', 'value3': '1.23'} != {'value1': None, 'value2': '0', 'value3': '1.23'}\n",
      "- {'value1': None, 'value2': '0.0', 'value3': '1.23'}\n",
      "?                             --\n",
      "\n",
      "+ {'value1': None, 'value2': '0', 'value3': '1.23'}\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.001s\n",
      "\n",
      "FAILED (failures=1)\n",
      "\n",
      "Process completed with return code: 1\n",
      "519\n",
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 198/214 [00:26<00:01,  9.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".FF.\n",
      "======================================================================\n",
      "FAIL: test_large_numbers (__main__.TestComputeOutputIndex)\n",
      "Test with large integer values.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 56, in test_large_numbers\n",
      "    self.assertEqual(result, expected)\n",
      "AssertionError: 3 != 3072\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_standard_case (__main__.TestComputeOutputIndex)\n",
      "Test with two standard positive integers.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 32, in test_standard_case\n",
      "    self.assertEqual(result, expected)\n",
      "AssertionError: 3 != 6\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.000s\n",
      "\n",
      "FAILED (failures=2)\n",
      "\n",
      "Process completed with return code: 1\n",
      "521\n",
      "\n",
      "FFF.\n",
      "======================================================================\n",
      "FAIL: test_basic_functionality (__main__.TestWordFilterCounter)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 26, in test_basic_functionality\n",
      "    self.assertEqual(word_filter_counter(text, filter_words), expected_output)\n",
      "AssertionError: {\"I'll\": 0, 'go': 2, 'to': 2, 'the': 2, 'school': 1, 'park': 1, 'play': 0} != {\"I'll\": 2, 'go': 2, 'to': 2, 'the': 2, 'school': 1, 'park': 1, 'play': 0}\n",
      "- {\"I'll\": 0, 'go': 2, 'park': 1, 'play': 0, 'school': 1, 'the': 2, 'to': 2}\n",
      "?          ^\n",
      "\n",
      "+ {\"I'll\": 2, 'go': 2, 'park': 1, 'play': 0, 'school': 1, 'the': 2, 'to': 2}\n",
      "?          ^\n",
      "\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_case_insensitivity (__main__.TestWordFilterCounter)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 40, in test_case_insensitivity\n",
      "    self.assertEqual(word_filter_counter(text, filter_words), expected_output)\n",
      "AssertionError: {\"I'll\": 0, 'go': 2, 'to': 2, 'the': 2, 'school': 1, 'park': 1, 'play': 0} != {\"I'll\": 2, 'go': 2, 'to': 2, 'the': 2, 'school': 1, 'park': 1, 'play': 0}\n",
      "- {\"I'll\": 0, 'go': 2, 'park': 1, 'play': 0, 'school': 1, 'the': 2, 'to': 2}\n",
      "?          ^\n",
      "\n",
      "+ {\"I'll\": 2, 'go': 2, 'park': 1, 'play': 0, 'school': 1, 'the': 2, 'to': 2}\n",
      "?          ^\n",
      "\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_filter_words_with_special_characters (__main__.TestWordFilterCounter)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 69, in test_filter_words_with_special_characters\n",
      "    self.assertEqual(word_filter_counter(text, filter_words), expected_output)\n",
      "AssertionError: {\"I'll\": 0, 'go': 1, 'to': 1, 'the': 1, \"school's\": 0, 'park': 1, 'play': 0} != {\"I'll\": 0, 'go': 1, 'to': 1, 'the': 1, \"school's\": 1, 'park': 1, 'play': 0}\n",
      "- {\"I'll\": 0, 'go': 1, 'park': 1, 'play': 0, \"school's\": 0, 'the': 1, 'to': 1}\n",
      "?                                                        ^\n",
      "\n",
      "+ {\"I'll\": 0, 'go': 1, 'park': 1, 'play': 0, \"school's\": 1, 'the': 1, 'to': 1}\n",
      "?                                                        ^\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.001s\n",
      "\n",
      "FAILED (failures=3)\n",
      "\n",
      "Process completed with return code: 1\n",
      "522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 200/214 [00:26<00:01,  7.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "...\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.005s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "523\n",
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.005s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 201/214 [00:26<00:01,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.006s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "525\n",
      "\n",
      "....F\n",
      "======================================================================\n",
      "FAIL: test_invalid_axis (__main__.TestFlipPointCloud)\n",
      "Test handling of an invalid axis.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 39, in test_invalid_axis\n",
      "    self.assertEqual(str(context.exception), \"Axis must be 0 (x-axis), 1 (y-axis), or 2 (z-axis).\")\n",
      "AssertionError: 'Axis must be 0, 1, or 2.' != 'Axis must be 0 (x-axis), 1 (y-axis), or 2 (z-axis).'\n",
      "- Axis must be 0, 1, or 2.\n",
      "+ Axis must be 0 (x-axis), 1 (y-axis), or 2 (z-axis).\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.006s\n",
      "\n",
      "FAILED (failures=1)\n",
      "\n",
      "Process completed with return code: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 203/214 [00:27<00:01,  6.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "526\n",
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 205/214 [00:27<00:01,  7.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "546\n",
      "\n",
      "..\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 207/214 [00:27<00:00,  8.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "......\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "548\n",
      "\n",
      ".EEE.\n",
      "======================================================================\n",
      "ERROR: test_file_not_found (__main__.TestReadTxtAddJsonBracket)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 1342, in patched\n",
      "    return func(*newargs, **newkeywargs)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 37, in test_file_not_found\n",
      "    result = read_txt_add_json_bracket(\"non_existent_file.txt\")\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 17, in read_txt_add_json_bracket\n",
      "    with open(filename, 'r') as file:\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 1075, in __call__\n",
      "    return self._mock_call(*args, **kwargs)\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 1079, in _mock_call\n",
      "    return self._execute_mock_call(*args, **kwargs)\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 1134, in _execute_mock_call\n",
      "    raise effect\n",
      "FileNotFoundError\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_invalid_json (__main__.TestReadTxtAddJsonBracket)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 1342, in patched\n",
      "    return func(*newargs, **newkeywargs)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 42, in test_invalid_json\n",
      "    result = read_txt_add_json_bracket(\"fakefile.txt\")\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 21, in read_txt_add_json_bracket\n",
      "    return json.loads(json_content)\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\json\\__init__.py\", line 357, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\json\\decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\json\\decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 10 (char 9)\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_invalid_json_missing_comma (__main__.TestReadTxtAddJsonBracket)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\unittest\\mock.py\", line 1342, in patched\n",
      "    return func(*newargs, **newkeywargs)\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 53, in test_invalid_json_missing_comma\n",
      "    result = read_txt_add_json_bracket(\"fakefile.txt\")\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 21, in read_txt_add_json_bracket\n",
      "    return json.loads(json_content)\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\json\\__init__.py\", line 357, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\json\\decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"D:\\sdk\\python\\py38\\lib\\json\\decoder.py\", line 353, in raw_decode\n",
      "    obj, end = self.scan_once(s, idx)\n",
      "json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 19 (char 18)\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.010s\n",
      "\n",
      "FAILED (errors=3)\n",
      "\n",
      "Process completed with return code: 1\n",
      "549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 209/214 [00:27<00:00,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".......\n",
      "----------------------------------------------------------------------\n",
      "Ran 7 tests in 0.002s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "550\n",
      "\n",
      ".......\n",
      "----------------------------------------------------------------------\n",
      "Ran 7 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 211/214 [00:28<00:00,  6.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".......\n",
      "----------------------------------------------------------------------\n",
      "Ran 7 tests in 0.005s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "552\n",
      "\n",
      "....F\n",
      "======================================================================\n",
      "FAIL: test_sets_with_negative_values (__main__.TestAreSetsEqual)\n",
      "Test with two sets containing negative floats.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\code\\code_back\\python_project\\RealisticEval-Data\\envs\\python\\temp\\temp.py\", line 38, in test_sets_with_negative_values\n",
      "    self.assertTrue(are_sets_equal(set1, set2, rtol=1e-5, atol=1e-6))\n",
      "AssertionError: False is not true\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.001s\n",
      "\n",
      "FAILED (failures=1)\n",
      "\n",
      "Process completed with return code: 1\n",
      "555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 213/214 [00:28<00:00,  7.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "557\n",
      "\n",
      ".......\n",
      "----------------------------------------------------------------------\n",
      "Ran 7 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 214/214 [00:28<00:00,  7.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".......\n",
      "----------------------------------------------------------------------\n",
      "Ran 7 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "Process completed with return code: 0\n",
      "Deleted: E:\\code\\code_back\\python_project\\RealisticEval-Data\\analysis\\alert_logs.txt\n",
      "Deleted: E:\\code\\code_back\\python_project\\RealisticEval-Data\\analysis\\critical_logs.txt\n",
      "Deleted: E:\\code\\code_back\\python_project\\RealisticEval-Data\\analysis\\dummy_path.md\n",
      "Deleted: E:\\code\\code_back\\python_project\\RealisticEval-Data\\analysis\\error_logs.txt\n",
      "Deleted: E:\\code\\code_back\\python_project\\RealisticEval-Data\\analysis\\test_exclude.csv\n",
      "Deleted: E:\\code\\code_back\\python_project\\RealisticEval-Data\\analysis\\test_file.txt\n",
      "Deleted: E:\\code\\code_back\\python_project\\RealisticEval-Data\\analysis\\test_log.log\n",
      "Deleted: E:\\code\\code_back\\python_project\\RealisticEval-Data\\analysis\\warning_logs.txt\n"
     ]
    }
   ],
   "source": [
    "from executor.java_executor import JavaExecutor\n",
    "from executor.ccpp_executor import CCPPExecutor\n",
    "from executor.typescript_executor import TypeScriptExecutor\n",
    "from executor.javascript_executor import JavaScriptExecutor\n",
    "from executor.python_executor import PythonExecutor\n",
    "\n",
    "\n",
    "def get_parser(language, model):\n",
    "    if language == \"python\":\n",
    "        return PythonExecutor(model)\n",
    "    elif language == \"javascript\":\n",
    "        return JavaScriptExecutor(model)\n",
    "    elif language == \"typescript\":\n",
    "        return TypeScriptExecutor(model)\n",
    "    elif language == \"c&cpp\":\n",
    "        return CCPPExecutor(model)\n",
    "    elif language == \"java\":\n",
    "        return JavaExecutor(model)\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "for task in TASK_LIST:\n",
    "    answer_path = f\"{ANSWER_PATH}\\\\{task['model']}\"\n",
    "    Path(f\"./model_answer_result/{task['model']}\").mkdir(exist_ok=True)\n",
    "    for language in task[\"language\"]:\n",
    "        try:\n",
    "            print(language)\n",
    "            parser = get_parser(language, task['model'])\n",
    "            file_path = f\"{ANSWER_PATH}\\\\{task['model']}_answer\\\\{language}_answer.json\"\n",
    "            parser.batch_run(file_path)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    delete_non_ipynb_files()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LLM回答数据统计"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TASK_LIST = [\n",
    "    {\n",
    "        \"model\": \"chatglm-6b\",\n",
    "        \"language\": [\"python\", \"javascript\", \"typescript\", \"c&cpp\"]\n",
    "    },\n",
    "    {\n",
    "        \"model\": \"codegeex4-all-9b\",\n",
    "        \"language\": [\"python\", \"javascript\", \"typescript\", \"c&cpp\"]\n",
    "    },\n",
    "    {\n",
    "        \"model\": \"codegen25-7b-instruct_P\",\n",
    "        \"language\": [\"python\",\"javascript\",\"typescript\",\"c&cpp\"]\n",
    "    },\n",
    "    {\n",
    "        \"model\": \"CodeLlama-7b-hf\",\n",
    "        \"language\": [\"python\", \"javascript\", \"typescript\", \"c&cpp\"]\n",
    "    },\n",
    "    {\n",
    "        \"model\": \"deepseek-coder-6.7b-instruct\",\n",
    "        \"language\": [\"python\", \"javascript\", \"typescript\", \"c&cpp\"]\n",
    "    },\n",
    "    {\n",
    "        \"model\": \"Meta-Llama-3.1-8B-Instruct\",\n",
    "        \"language\": [\"python\", \"javascript\", \"typescript\", \"c&cpp\"]\n",
    "    },\n",
    "    {\n",
    "        \"model\": \"Mistral-7B-Instruct-v0.3\",\n",
    "        \"language\": [\"python\", \"javascript\", \"typescript\", \"c&cpp\"]\n",
    "    },\n",
    "    {\n",
    "        \"model\": \"Phi-3-small-8k-instruct\",\n",
    "        \"language\": [\"python\", \"javascript\", \"typescript\", \"c&cpp\"]\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"model\": \"starcoder2-7b\",\n",
    "        \"language\": [\"python\", \"javascript\", \"typescript\", \"c&cpp\"]\n",
    "    },\n",
    "    {\n",
    "        \"model\": \"gpt-3.5-turbo\",\n",
    "        \"language\":[\"python\",\"javascript\",\"typescript\",\"c&cpp\"]\n",
    "    }\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result_list = []\n",
    "for task in TASK_LIST:\n",
    "    model_name = task[\"model\"]\n",
    "    language = task[\"language\"]\n",
    "    temp = {\n",
    "        \"model\": model_name\n",
    "    }\n",
    "    for l in language:\n",
    "        file_path = f\"./model_answer_result/{model_name}/{model_name}_{l}.xlsx\"\n",
    "        data = pd.read_excel(file_path)\n",
    "        pass_count = (data[\"result_return_code\"] == 0).sum()\n",
    "        failed_count = (data[\"result_return_code\"] != 0).sum()\n",
    "        pass_rate = (pass_count / len(data)) * 100\n",
    "        temp[f\"{l}_pass_count\"] = pass_count\n",
    "        temp[f\"{l}_failed_count\"] = failed_count\n",
    "        temp[f\"{l}_pass_rate\"] = f\"{pass_rate:.2f}%\"\n",
    "    result_list.append(temp)\n",
    "result_data = pd.DataFrame(result_list)\n",
    "result_data.to_excel(\"./model_answer_result.xlsx\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
